{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jn-z-L28UUd3"
   },
   "source": [
    "# Implementing and Comparing Activations functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPzS27cTUUd4"
   },
   "source": [
    "## Abstract\n",
    "\n",
    "Neural network activation functions are a crucial component of deep learning. Activation functions determine the output of a deep learning model, its accuracy, and also the computational efficiency of training a model—which can make or break a large scale neural network. Activation functions also have a major effect on the neural network’s ability to converge and the convergence speed.<br />\n",
    "<br />\n",
    "In this project, I have implemented various Activation functions like `sigmoid, tanH, ReLU, Leaky ReLU, Parametric ReLU, and Swish` etc. Compared their outputs, accuracy, loss along with the time taken by each function to converge. <br />\n",
    "<br />\n",
    "I have created `Convolutional Neural Network(CNN)` model that is used across all Activation functions to maintain consistency and validness. The CNN model is implemented using `TensorFlow` and the data is acquired from `Intel Image Classification` competition which held on Analyticsvidya.com. <br />\n",
    "<br />\n",
    "Aim of this project is to elaborate the importance of different activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9Kj27F1UUd4"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-blKoRCVUUd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "#Keras libraries\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn                        \n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from IPython.display import display \n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings,time, datetime\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Og-1OnpmUUd8"
   },
   "source": [
    "#### TensorFlow Version working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ayZ1IotCUUd9",
    "outputId": "310a5a82-aa8a-46ae-cb32-691bb9d69da8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBnYtHqAUUd_"
   },
   "source": [
    "#### Here's our 6 categories that we have to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnALIdhbUUeA"
   },
   "outputs": [],
   "source": [
    "class_names=['0','1','2','3','4', '5', '6','7', '8', '9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNO4TGveUUeG"
   },
   "source": [
    "### Loading Training and Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dNLR7urUUeJ"
   },
   "outputs": [],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TRWTiyAuUUeL",
    "outputId": "cd4eb53a-2187-43bb-f5de-b89c55cc9c64",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n",
      "Number of testing examples: 10000\n",
      "Each image is of size: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples: \" + str(train_labels.shape[0]))\n",
    "print (\"Number of testing examples: \" + str(eval_labels.shape[0]))\n",
    "print (\"Each image is of size: \" + str(train_data.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y12q2oHVUUeN"
   },
   "source": [
    "- Our image dataset contain 14034 Training and 3000 test images 150*150 size of 3 channel (i.e colored RGB images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMwp4VjRUUeO"
   },
   "source": [
    "#### Lets plot a pie chart of image distribution of 6 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "dASl9_JHUUeO",
    "outputId": "fa3a574f-8247-43eb-d393-d13ea961c203",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a pie chart\n",
    "sizes = np.bincount(train_labels)\n",
    "explode = (0, 0, 0, 0, 0, 0,0,0,0,0)  \n",
    "# explode = (0, 0)  \n",
    "plt.pie(sizes, explode=explode, labels=class_names,\n",
    "autopct='%1.2f%%', shadow=True, startangle=150)\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99NelqgdUUeQ"
   },
   "source": [
    "#### Its good practice to Normalize pixel values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "02iuGjZUUUeT",
    "outputId": "419b10b8-5c6c-44aa-c835-aae7c5c1ad65",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_images.shape = (60000, 28, 28)\n",
      "x_images.min/mean/std/max = 0.00/0.13/0.31/1.00\n",
      "\n",
      "y_images.shape = (10000, 28, 28)\n",
      "y_images.min/mean/std/max = 0.00/0.13/0.31/1.00\n"
     ]
    }
   ],
   "source": [
    "print('x_images.shape =', train_data.shape)\n",
    "print('x_images.min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(train_data.min(),\n",
    "                        train_data.mean(), train_data.std(), train_data.max()))\n",
    "print('')\n",
    "print('y_images.shape =', eval_data.shape)\n",
    "print('y_images.min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(eval_data.min(),\n",
    "                        eval_data.mean(), eval_data.std(), eval_data.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnK9A7_KUUeV"
   },
   "source": [
    "#### Plot some random images from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "colab_type": "code",
    "id": "5TID41mcUUeW",
    "outputId": "f87e509e-19a5-4369-ba45-245191803ac2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAsAAAKECAYAAABhDLOAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdebyW0/7/8fdHaSShMlTqGAshJ7NEiGNM5jkyHUM58jUPyRxCpmNMioZjynQkUelXkVIyJBw7Q2jSgJS0fn9cd8tal33v7t0e7j28no/HfvS+7mtd1/25995Xe99rr3Utc84JAAAAAABglbXyXQAAAAAAAKhY6CwAAAAAAAAROgsAAAAAAECEzgIAAAAAABChswAAAAAAAEToLAAAAAAAABE6CwCghMyss5mNNbM5ZrbUzGaZ2YtmdnC+a0PCzArM7Ml815FmZoeb2XQz+83MnJk1zNLuSTMrKOfyKp1ifD67mtmZWR53ZrZl2Veb9blbFvO4hmbWy8x2LpvKilXLxWbWJd91AABKB50FAFACZtZd0guSPpfUTdKhkm7K7O6Yr7pQ8ZlZTUlPS/pOUidJe0hakqX5jZKOKqfSKqVifj67SvpLZ0El1VDS9ZLy3lkg6WJJdBYAQBVRM98FAEAld6mkF51z3YLH3pL0qJnRIYuiNJW0rqRhzrmxRTV0zn1ZPiVVajl/PgEAwOrxiywAlMwGkn4obIdzbmW4bWa7mtmbZvazmf1iZqPMbNdUmyfN7Fsza2dm4zPTGj4zs0Mz+y/JDKlfbGbDzaxx6viaZnalmc0ws2VmNtvM7jKzOqt7Ibkca2Y3mdlyM9sleKx+psYJmb/uysx2MbNnM69l1Wu4xczqpp5ztJmNM7ODzWxqpu0HZrZbpp5bzOx7M1uQ+dzUD45tmRm2fb6Z9c1MA/nVzF7JZSi3mf3NzJ42s7mZ1zvVzI5KtdnazF7InPs3M/vazP6z6nUWce5NzOwpM5uXOfeHZnZKsL+XpILM5uOZ1zG6iPNF0xCC136emd1qZj+Y2RIzG2Rm9cxsSzMbkfle+8LMTk+db0szG2hmX2U+5/8zs4fMbP1CnrtH5nvuNzN7z8z2tEKmdVSWz2fm8Q6S9sq0K6xto8xrWZy5Dvqlr6HM5/n2zOdweebfqy2HTkIz29zMXs18v841s3sl1S6k3Qlm9lamzc+Za+P0YH9LSV9lNh8NXk/XzP5OZvZa5hr61cw+MrOeZlYj9TwnZc79s5ktsmQqx7mpNh0s+T9riSX/f40ws+2D/QWSWkg6OajjydV9LgAAFRcjCwCgZN6TdLqZ/U/ScOfczMIamdkOksZI+kTJEGgn6QpJY8xsd+fctKB5A0lPSbpT0mxJV0t6zswekLS1pAskbSTpHkkPSDouOHaQpMMl3S5pvKTWSoawt5R09GpeSy7H9lIyveIZM2vrnPs5U8PGkg52zq3ItNtM0lRJTyoZCr6dpOskbS7phNTzbinpDkk3S/pZUh9JL2U+amY+X60zbeZIuix1/JWZ5zpDUhNJt0h6w8y2c879XtgLNbPmkt7NnO9fkuZKOl7J57mzc+6lTNNXJC2U9E9J85T89foQFdHZbkmHxhhJ60u6StI3kk6RNNDM6jnnHpH0mKSPJP1HybSVVyUtznbOIlwpabSk0yVtq+Rzt1JSW0mPKvke+qek/mb2vnPu48xxm0r6Vsmw8Z+UfF2ukvSakuH7q17LWUq+zx7P1LqFpGeUDH0PX3Nl+nyer+R7vYakVW+I020HShqsZEj9Hkq+739SMtx/1ZSHEUo+5zdKmi5pd0nXKulA7FnE66klaaSkukqu5TmZOgobvr+5pGcl3abk67qPpMfMrK5z7t+Svs8c97ykW5VcM5L0ZXD8KEn3SfpNUrvMa2ms5P8fmdnemc9HP0n/p+Rr0UrB19iSzsrhSj6vqzppLpf0jpnt4Jz7Rsk0mdckTcs8h5R8HwAAKivnHB988MEHH2v4oeTN+4dK3vw7JW+ABkvqlGr3rJI3SQ2DxxpIWiDp+eCxJzPn2Sd4bIfMY59JqhE83lfS76sek9Q+0+601HOfnHl8pyJeR87HKuk8WChpgKQTM/tPKuLcpuRN/ylK3vBsGOwbnXkNmwePHZE555up8zwv6atUHU5JB8xaweN7ZR7vFjxWIOnJYPtxJW9kNkw9x0hJUzO5UeY8RxTze+LCzHH7ph5/U8kbw1Vfry0z7brmcM4nJRUU8trfKuRz5CSdEjy2vqQVkq4v4vw1Je2dObZt5rG1lLwxfy3VtkumXWX+fI6WNK6Qx7tmznFD6vFXJM0Mtk9V6jrNPH61pOWSmhTx3Gdnjt09eGwtSR9nHm+Z5bi1Ml+nRyVNK+R74azVvOZV1+HVSjo+1so8fqmkBas59gtJo1KPNVDy/909qetsUHG+vnzwwQcffFTcD6YhAEAJuGQkQVslw5pvVvIX7qMkjTCza4Km+0h6xTm3MDh2sZK/BHZInfYXF8+5npH5903n3B+px2tK2iSzfbCSNyrPWTKEv2bmL6BvBDVkk/OxzrkCSedJOk1Sf0lPOeeeCU9mZg0yQ7S/lLRMSYfAQCVvWLZKPfdM59z/Cnm9I1LtZkhqZmaWevxZF0z5cM79PyV/Nd9D2R2s5K+gi1Kvd4SkHc2sgaT5kv4n6TYzO9vM0nVns4+k75xzo1OPD1LyF91tczxPLv6b2v7L584595OSN9XNVz1mZrXM7CpLppwsVfL1eSeze5vMv80yH/9JPcdwJZ0Poary+Vzl1dT2dCWjZVY5WNIsSeMLuV7WVjLKIJs9JH3jnJu46oHM9++wdEMz28rMBpvZd0q+Rr9LOkt/fo2KlJm+8bCZzVJyff+uZORFQyWjcCRpkqT1LZnCcpilVpDIfJ22kPR06rX+KmmCiv5/BQBQidFZAAAl5Jz7wzk31jl3jXPuACVDf6dLut7+nAO+gZIhw2k/KPnLb2hhuOGcW56JP6XarXp81VzqJpJqKRnK/3vwMSezf8MiXkZxj31VyZu/2pLuLuR8/ZV0KPSTdKCkXZQMuQ7rXSXb6yrs8ZpKho+Hfizk+X9UMsQ9myZKOjt+T33ckdm/oXPOZWp/X8kQ75mWzO3/ZxHnlYr+Wq/aX1qK87kLP++3KhkqPkjJCh676s9h8KvareqEmhMcp0yH1bzU+avK53OVBantZYrvKdBEyfz89Ot9L7O/qGttE2X/nvXMbB0lIzN2VDJloL2S6+gJFXJ/g7TMvRNeknSYkg6Cjpnjb840qSNJzrkxko5V0pn0gqS5ltxbZYfgtUrJ6JH06z1sNa8VAFCJcc8CAChlzrnZZvaYpHuV/BX9PSVvPjYupPnG+usbkzU1X8m85PZZ9s8uxWMfUPKm/UtJj5jZXi5zf4DMjeCOlNTLOXfvqgPMrM1qX8Ga2SjLY1OLOGa+kr+k355l/2xJyox4OC0zmmFHJUPiHzSzAudc+q/6qyxQ4X/5XfX1n19EXeXlBCUjQlYt87nqzWlo1Rv0JuGDmZvjNUq1rW6fz/lKbix4XJb9BUUc+72Se3ikpb+P91DSIdHeOTdu1YO2mptBBrZQco+CU51zg4LjD083dM49K+nZzPfAvkq+jq+bWTP9+fm9UsnUj7TlhTwGAKgC6CwAgBIws+YuublXWqvMv6v++jlG0qFmtq5zbknm2HWV3FBwdCmV87qSm46t55wbVVbHmtlJSuZsH6dkWPkESb2VvJmQkr961lDyl8dQ12LWlKtjzKzXqqkIZraXkuHzE4o45nUlb8Y+ds4tXd0TZP4qPtXMLpHUTdL2+usUgFXGSDo204Hy/4LHT1LyV/pPV/d85aCe/vr1OSO1/W3m41glI0VW6ay//v5Q2T6fy5Qss7imXldy08+fnXMzVtc4ZYKkMzI3Np0o+VEA6Y6Hepl//dcpM1LpyFS7ZZl/66YeL+z4tZXch6RQLrlh6StmtrmSzs4NldwrpUDSds6524p8ZUkt6ToAAJUUnQUAUDIfmdnbSobvfqXkpl+HKBmCP8w593Wm3Y1KhuyOMrPbldyQ7HIlv9D3Lo1CnHOjzWywkr8Q9lUyomGlkhugHSLpcpdltYZcjzWzv0l6SNLjzrn/SJKZXa1kHvobzrm3nXOLzGyipJ5m9r2SIetnquhpASWxrqQXzexhJXPYb5X0uZIVJbK5TslrHGtm9yt5M7S+kjetmzvnzswMw75X0lAlN3iroaTDY4Wkt4o495OSekh6PvO5+VbJG7QDJZ2buu9EvryuZBWP6UpeWxdJe4YNnHMrzewGJUvyPabk3gWbKxkSv0jJ98cqle3z+Ymk883seCWjY5Y45z4rxvFPK+lcGWVmdylZAaCWkr/mHyGps3Pu1yzHDlDyOXzezK5S0uFxnpL/O0LjlazS8ICZXS+pvqRrlFxP6wXtflTy1/8TzOxDSb8o+b/oUyX3VbjZzP5Q0mnwr3QxZtZbyaiGt5WMAGkmqbuSG1POzbS5QNLwzEoOwzI1bKTke+Zr51zfzOk+kdTezA5T0lE6L3OPEwBAZZTvOyzywQcffFTmDyW/5L+k5Jfy35T8ov6BkuX9aqXa7qZkGO/PmXajJO2aavOkpG8LeR4n6abUY10zj28ZPLaWkjdW0zL1LMrkPkpGDRT1Woo8VkkH8wQlf2msHxxnSm7s9q0yd8NX0snwXyXLJs6RdL+SufHRXe1VyF3pleXu7krm2DtJNVPtzleyMsRcJTdde1XS31LHFii4e3/msWZKltz7TslQ6u+VzBE/JbO/iZI3djMz512g5K/cB+XwfbGJkhs6zlPy19YPFaxQkGlTGqshFPk5Sr3+QcF2I0lDlNzb4Cclb353KaweJcsrrvr+fl/Jqgk/Sbq7En8+N1ZyQ8YlmWNGZ7umws9r6rE6mcdnZGpaoORmgb3Sn/9Cnn/zzPP/mvm+vVfJ8onRaghK7jPwgaSlSjo1umeppbOSN+q/h58DSTtJGpd5nm+VdEyeFT6PkutyRObrtUzJChiPS9o09Rx7KFkV4qfM90JB5ntoj6BNKyXTUX5VasUMPvjggw8+Kt+HOecEAEBlY2YtlfwF9Wzn3GP5rab6MLNdlIwiOM05NzDf9QAAgLLBNAQAAFCozLSTC5T8tXixpNaSrlLSSfNcHksDAABljM4CAACQzVIl9x04Tck9CH5SMpXmCpd9Tj4AAKgCmIYAAAAAAAAia+W7AAAAAAAAULHQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNBZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgQmcBAAAAAACI0FkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNBZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgQmcBAAAAAACI0FkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNBZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgQmcBAAAAAACI0FkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNBZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgQmcBAAAAAACI0FkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNBZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgUrM4jRs1auRatmxZRqWgMAUFBZo3b57luw5UbFyb5Y9rE6vDdZkfkydPnueca5zvOlBxcW3mB9cmVodrMz+KujaL1VnQsmVLvf/++6VTFXLSrl27fJeASoBrs/xxbWJ1uC7zw8xm5bsGVGxcm/nBtYnV4drMj6KuTaYhAAAAAACACJ0FAAAAAAAgQmcBAAAAAACI0FkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIEJnAQAAAAAAiNTMdwEAsMrkyZOj7fvvv9/nAQMG+Hz66adH7S666CKfd9555zKqDgAAAKg+GFkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBSpe5Z8Mcff0TbixYtyum4cF70r7/+6vNnn30WtXvggQd8vvTSS30ePHhw1K5OnTo+X3HFFdG+66+/PqeagOpi6tSpPh9wwAHRvsWLF/tsZj4/9dRTUbvhw4f7vGDBgtIuEUAJjRo1yueTTz452jdmzBift9lmm3KrCagubrrppmj7uuuu89k55/Po0aOjdh06dCjTugBUfIwsAAAAAAAAEToLAAAAAABApMJOQ/j66699Xr58ebRv/PjxPo8bN87nhQsXRu2effbZEtXQvHnzaDtcnu2FF17wed11143a7bjjjj4zhAv4q/fee8/no48+2uf01KFw6kGDBg18rlWrVtRu3rx5Pk+YMMHnv//971G79HFARTN27Nhoe/78+T4fddRR5V1OqZk0aZLP7dq1y2MlQPXw5JNP+nzbbbdF+2rUqOFzOIU3/JkLABIjCwAAAAAAQAqdBQAAAAAAIFJhpiF88MEH0XbHjh19znVVg9IQDs1K3z22fv36Pod3c950002jduuvv77P3NkZ1VW4ssiUKVOifaeccorPs2fPzul8W221lc+XXXZZtO/444/3ea+99vI5fQ1fddVVOT0XkC/pu5F//vnnPle2aQgrV670+auvvvI5nGYoxXdjB1A6Zs2a5fOyZcvyWAlQdbz77rvR9sCBA30OpxF+9NFHWc9x1113+Zx+D/nOO+/4fOqpp/q82267Fb/YUsLIAgAAAAAAEKGzAAAAAAAAROgsAAAAAAAAkQpzz4IWLVpE240aNfK5NO5ZEM71CO8pIElvv/22z+HSauFcEQDFc+655/r8zDPPlPh8kydP9vnnn3+O9oVLlIZzvqdPn17i5wXK04ABA6LtPffcM0+VlNz333/v8yOPPOJz+mdrq1atyq0moCp78803fe7Xr1/WduE198orr/i80UYblU1hQCU2dOhQn3v06BHtmzt3rs/h/Xf23XffqF24xPell16a9bnCc4THDBkyJPeCSxkjCwAAAAAAQITOAgAAAAAAEKkw0xA22GCDaPuOO+7w+eWXX472tW3b1ufu3btnPedOO+3kczg0K1wCUYqXtyhq2BaAooVTBcKhjUUtjRYO1TrssMOifeFQrXB5mfD/ACmeWhROK2JJNlQ24XKDld1ZZ51V6OPhMqgA1ty4ceOi7a5du/q8ePHirMf93//9n8/pacBAdbRixYpoe9KkST6fffbZPv/yyy9Ru3Aa7LXXXuvz3nvvHbULly897rjjfB4xYkTWmtq1a7e6sssFIwsAAAAAAECEzgIAAAAAABChswAAAAAAAEQqzD0L0jp37uxzx44do33rrruuzx9++KHPjz32WNQunO+cvk9BaPvtt/c5XN4JQNGmTp0abR9wwAE+h/MlzSxqd8ghh/g8ePBgn8NlDyXp5ptv9jmc/9y4ceOo3Y477ljoc7366qtRuylTpvi88847C6gIwp9jP/74Yx4rKV0LFy4s9PEDDzywnCsBqqb0UquzZ88utF16GbfTTjutrEoCKqVBgwZF2926dSu0XadOnaLtcFnFBg0aZD1/2K6o+xQ0b97c59NPPz1ru/LEyAIAAAAAABChswAAAAAAAEQq7DSEUFHDOtZbb72s+8JpCSeccILPa61FHwmwpmbOnOlznz59on2LFi3yOZwqsMkmm0TtwqFV66yzjs/ppRPT28X166+/Rtt33nmnz88880yJzg2Ultdee83npUuX5rGSkklPoSgoKCi0XdOmTcuhGqBqmjdvns+PP/54tK9GjRo+N2zY0Odrrrmm7AsDKpnwurjllluifeGU1gsuuMDnm266KWpX1HvUUDittij9+vXzOT3lNl941wwAAAAAACJ0FgAAAAAAgEilmIZQlF69evk8efLkaF94Z/U333zT5/SdLAFkt2zZsmg7XGUkvdpAOBzrqaee8rldu3ZRu3wNtf7mm2/y8rxAUT777LOs+7bbbrtyrKRkwv8bJOmHH37weZtttvE5XNEIwOqFU3q6dOmS0zEXXXSRz+lVxYDqqHfv3tF2OPWgdu3a0b6DDjrI59tvv93nunXrZj3/b7/95vMbb7wR7Zs1a5bPzjmfr7322qjdkUcemfX8+cLIAgAAAAAAEKGzAAAAAAAAROgsAAAAAAAAkUp/z4L69ev7/Oijj0b7dt55Z5/PPvtsn/fbb7+oXTifOlweI1w2A6iupkyZEm2n71MQGj58uM8dOnQos5qA6mKXXXbJdwlavHhxtP3666/7PGjQIJ/TczRD4RJV4ZJuAFYvvOamT5+etd3+++/vc48ePcq0JqAyWLhwoc8PPvhgtC98nxfeo0CSXnzxxZzO/8UXX/h88skn+/z+++9nPebYY4/1+bLLLsvpefKJkQUAAAAAACBCZwEAAAAAAIhU+mkIoS222CLafvLJJ30+44wzfA6XdEtv//LLLz6fdtppUbtNNtmkNMoEKpVLLrkk2g6XfNl3332jfRVh6kFYX3H2ARXRggULin3MtGnTou2VK1f6PGrUKJ+//fbbqN3y5ct9fvrppws9XoqXjtptt918Ti899fvvv/ucXj4VQHbpIdBXXHFFoe3at28fbQ8YMMDn9dZbr/QLAyqZ8Ofa3Llzs7br169ftD1nzhyf+/fv73M43VaSPv74Y5+XLFnic3oq+1pr/fn3+VNOOcXncDp9RcXIAgAAAAAAEKGzAAAAAAAARKrUNIS0o446yuctt9zS5549e0bt3nzzTZ+vvPJKn2fNmhW1u/rqq31u2rRpqdUJVDSvvPKKz1OnTo32hUOrjjjiiHKrKVdhfelhYDvttFN5lwOsVjisP/09e+655/p8yy235HS+9DSEcPrN2muv7XO9evWidq1bt/b5zDPP9Pnvf/971C6cfrTRRhv53KxZs6jd0qVLfW7VqlUupQPVVkFBgc9dunTJ6ZjNN9882g6vRwBSrVq1fG7SpEm0L5xq0LJly2hfrivihe8HGzRo4PPs2bOjdo0aNfL58MMPz+ncFQUjCwAAAAAAQITOAgAAAAAAEKGzAAAAAAAARKr0PQtCbdq08XnYsGHRvpdfftnnrl27+vzvf/87avf555/7PHLkyFKuEKg4wrnG4bIzUjzn6/jjjy+3mkLLli2Ltnv16lVou/333z/avu2228qqJGCNPfjggz63aNEi2jd+/Phin2+zzTaLto888kift912W5933333Yp877ZFHHvE5nP8p/XU+NYDsbr/9dp9r1KiR0zHZllQEkGjYsKHP6SVJDzvsMJ/nz58f7QvvdRf+DA3fJ0rSBhts4PMJJ5zgc/qeBeG+yoaRBQAAAAAAIEJnAQAAAAAAiFSbaQihcEiKJJ166qk+n3XWWT7//vvvUbuxY8f6PHr0aJ/DZaSAqq5OnTo+b7LJJuX2vOHUg5tuuina16dPH5+bN2/uc3qZ1HXWWaeMqgNKx+WXX57vEopl1KhRWfcdc8wx5VgJUPmESxOPGDEip2PCJYu32WabUq8JqKp22223aHvu3LklPmf43nDMmDE+p5derMzT8hhZAAAAAAAAInQWAAAAAACASLWZhvDhhx/6/Oyzz0b7Jk2a5HN66kEovIv0PvvsU4rVAZVHOASyrIVDNMOpBkOHDo3ahXeqff7558u+MACr1blz53yXAFRonTp18vmnn37K2i4cPj1gwIAyrQlA7sLVw8KpB+lpCKyGAAAAAAAAqgw6CwAAAAAAQITOAgAAAAAAEKlS9yz47LPPou377rvP53Ae8w8//JDT+WrWjD894TJxa61FPwuqLudcoVmSXnzxRZ/vvffeUn3evn37Rts33nijz4sWLfL5lFNOido99dRTpVoHAABlbd68eT7XqFEja7sLLrjAZ5YABiqOgw46KN8llDne8QIAAAAAgAidBQAAAAAAIFIppyGE0wieeeYZn++///6oXUFBQbHPvcsuu/h89dVXR/vKc8k4IJ+KWv4lvP66d+8e7TvzzDN93nDDDX2eOHFi1G7gwIE+T5s2zedvvvkmateiRQufDz74YJ/PP//8ol8AgLz7/PPPfd5jjz3yWAlQMZxxxhnRdjjN748//sh63J577llmNQFYcyNGjMh3CWWOkQUAAAAAACBCZwEAAAAAAIhU2GkIP/74o88ff/xxtO/CCy/0ecaMGcU+92677RZtX3bZZT4feeSRPrPiAfBXK1as8PmBBx6I9j377LM+r7feej7PnDkzp3Onh1p27NjR5969exerTgD5tXLlynyXAOTd1KlTfR45cmS0L5zmV7t2bZ/TU+022mijMqoOQEl8+eWX+S6hzPFuGAAAAAAAROgsAAAAAAAAEToLAAAAAABAJK/3LFiwYIHP5557brQvnOO1pvNB9tprL5979uzp80EHHRS1q1u37hqdH6iqwmXOdt1112jfe++9l/W4cFnF8L4jaY0aNfL5hBNO8Pnee+8tVp0AKq4JEyb43LVr1/wVAuTRwoULfS7q5+Kmm27q81133VWmNQEoHe3bt/c5XAq1KmFkAQAAAAAAiNBZAAAAAAAAImU+DeHdd9+Ntvv06ePzpEmTfP7222/X6Pz16tXzuXv37tG+q6++2uf69euv0fmB6qhZs2Y+P//889G+hx9+2Ocbb7wxp/P16NEj2v7nP//p81ZbbbUmJQIAAAB506ZNG5/D32fTU+jD7caNG5d9YaWIkQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACJlfs+CF154ocjtbLbddlufDz/88GhfjRo1fL700kt9btiw4ZqUCKAIm2yySbTdq1evQjOA6ucf//iHz8OGDctjJUDF1KpVK5/33HPPaN8777xT3uUAKCNXXXWVz926dcu67/777y+nh6oAACAASURBVPc5fL9bUTGyAAAAAAAAROgsAAAAAAAAkTKfhnDbbbcVuQ0AACqnrl27FpoBJDbeeGOfx4wZk8dKAJSlLl26+DxkyJBo38iRI30Op/D2798/ale/fv2yKa4EGFkAAAAAAAAidBYAAAAAAIBImU9DAAAAAACgqmrQoIHP6dWBrr76ap8ffPBBn9OrilXE1REYWQAAAAAAACJ0FgAAAAAAgAidBQAAAAAAIMI9CwAAAAAAKAXh/Qsk6b777is0VwaMLAAAAAAAABE6CwAAAAAAQMScc7k3NpsraVbZlYNCtHDONc53EajYuDbzgmsTReK6zBuuTRSJazNvuDZRJK7NvMl6bRarswAAAAAAAFR9TEMAAAAAAAAROgsAAAAAAECkyncWmFmBmU03s6lm9n6+6wGQMLODzewzM/vCzK7Idz0A/mRmNczsAzN7Jd+1AJDM7Akzm2NmH+W7FgAxM+thZh+Z2cdmdnG+6ylNVb6zIGM/59xOzrl2+S4EQPJGRNIDkv4haVtJJ5rZtvmtCkCgh6RP810EAO9JSQfnuwgAMTPbXtLZknaVtKOkw8xsq/xWVXqqS2cBgIplV0lfOOf+55xbLmmIpCPzXBMASWbWTNKhkh7Ldy0AEs65sZIW5LsOAH/RWtJE59yvzrkVksZIOirPNZWa6tBZ4CS9YWaTzeycfBcDQJLUVNI3wfa3mccA5N89ki6TtDLfhQAAUMF9JGkfM9vQzOpJOkRS8zzXVGpq5ruAcrCXc262mTWRNNLMZmR6ZwHkjxXyGOu4AnlmZodJmuOcm2xm++a7HgAAKjLn3KdmdrukkZJ+ljRN0or8VlV6qvzIAufc7My/cyS9oGT4M4D8+lZxr2szSbPzVAuAP+0l6QgzK1AyPaijmQ3Kb0kAAFRczrnHnXM7O+f2UTJd6PN811RaqnRngZnVN7N1V2VJnZQMFQGQX5MkbWVmfzOzWpJOkPRSnmsCqj3n3JXOuWbOuZZKrsu3nHOn5LksAAAqrMwIdpnZZpK6SBqc34pKT1WfhrCRpBfMTEpe6zPOudfzWxIA59wKM7tQ0ghJNSQ94Zz7OM9lAQBQIZnZYEn7SmpkZt9Kut4593h+qwKQ8ZyZbSjpd0kXOOd+yndBpcWcY5owAAAAAAD4U5WehgAAAAAAAIqPzgIAAAAAABChswAAAAAAAEToLAAAAAAAABE6CwAAAAAAQITOAgAAAAAAEKlZnMaNGjVyLVu2LKNSUJiCggLNmzfP8l0HKjauzfLHtYnV4brMj8mTJ89zzjXOdx2ouLg284NrE6vDtZkfRV2bxeosaNmypd5///3SqQo5adeuXb5LQCXAtVn+uDaxOlyX+WFms/JdAyo2rs384NrE6nBt5kdR1ybTEAAAAAAAQITOAgAAAAAAEKGzAAAAAAAAROgsAAAAAAAAEToLAAAAAABAhM4CAAAAAAAQobMAAAAAAABE6CwAAAAAAAAROgsAAAAAAECEzgIAAAAAABCpme8CAFR9PXr0iLb79evn8/bbb+/zK6+8ErVr0aJF2RYGAAAAVCIdO3bMuu+tt94q1ediZAEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgEi1vGfBkiVLou2ff/7Z51dffdXnOXPmRO169uzpc+3atcuoOqBqKCgo8HngwIHRPjPz+ZNPPvF5xowZUTvuWQCUrpkzZ/q8fPnyaN8777zj8/nnn+9zeL2uqc6dO/s8ZMiQaF+tWrVKfH6gKvn999+j7fHjx/t85ZVXFvo4gKrrX//6V7Q9YcIEn0877bQyfW5GFgAAAAAAgAidBQAAAAAAIFKlpyF89dVXPvfp08fncOiGJE2fPj2n8/3www8+h0u/Afirxo0b+9yhQ4do3/Dhw8u7HKDa+Oijj6LtAQMG+Pyf//zH55UrV0btvvvuO5/DqQelMQ0hvObPO++8aN8999zjc4MGDUr8XEBlt2jRomh733339XnjjTf2Ofy9NL0PQOV2xRVX+Pzvf/872rf22mv7vP/++5dpHYwsAAAAAAAAEToLAAAAAABApNJPQwjvnh4OZZSkQYMG+bx06VKfnXNRu80228zndddd1+fwLu2SNGzYMJ/DO0W3atWquGUDVV79+vV9ZlUDoPxcddVV0Xa4yk9FEE6LkKQzzzzT57333ru8ywEqlXDqAdMQgKpr4sSJPqdXLwp/Vh533HFlWgcjCwAAAAAAQITOAgAAAAAAEKGzAAAAAAAARCrFPQvSS8hcfvnlPg8dOtTnxYsX53S+rbfeOtoeMWKEz+GckPS9CObOnevzvHnzcnouoLpauHChz9OmTctjJUD1cuCBB0bb2e5Z0KRJk2i7W7duPofLKq61Vva/K4wfP97nMWPGFKtOAAAqk7Fjx0bbN998s8+DBw/2eYMNNlij84fnmD59us9bbrll1O7OO+9co/OvCUYWAAAAAACACJ0FAAAAAAAgUimmIbzwwgvR9qOPPlrsc4TDN0aOHBnta968uc+ff/55sc8N4K9+/fVXn2fNmpXTMZMmTYq2w6lALL8I5Oaf//xntN25c+dC26299trR9posuxZO/9t+++2jfd99912hx6Tr2WWXXYr9vADiZcEBlL1zzjkn2p45c6bPn3zyic9rugxwOK1hwYIFPj/22GNRux133HGNzr8mGFkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBSKe5ZMGzYsJzatWzZMtreddddfb799tt9Du9RkDZjxoziFQegUJtuuqnPZ5xxRrTv+uuvL/SY9OMNGzb0+cILLyzF6oCqq2bN+Ed7UT/zSipcevinn37K6Zh0PbVr1y7VmoDqYvLkydH2HnvskadKgOqhbt260baZ+fzbb78V+3xTp06Ntr/++utSO3dpYWQBAAAAAACI0FkAAAAAAAAilWIaQnq5iEceecTnTp06+RwujyhJTZo0KfZz/fjjj8U+BkDRrr322mg72zQEABXfkCFDfA5/HofLpRald+/epV4TUJWkpxKFU/IWLlzo85dfflluNQHVVfg77EcffRTta926tc+5Lmf4yy+/+BxOk0/v23333X0+5phjciu2DDCyAAAAAAAAROgsAAAAAAAAkUoxDSG8q7ok9erVq8yea/z48WV2bgAJ51y+SwBQhEGDBvl82223RfvCoc/Lly/P6Xw77bSTz2uvvXYJqwOqtnDagSS1b9/e55dffrm8ywGqnW+++cbnRx991Of0FKEHHnjA58aNG+d07ksuucTn9Ip/TZs29bmivCdlZAEAAAAAAIjQWQAAAAAAACJ0FgAAAAAAgEiluGfBmurXr5/P4VIU6fnSZuZzekmM0F577eXzHnvsURolAtVSeM2FGUDJFRQURNsDBw70+c0338zpHO+8847PuV6jDRo0iLbDJaEOOeQQn+vWrZvT+QAAKA/Tp0+Ptrt06eLz3Llzfe7evXvUrkOHDjmd/8477/T5ySefzNru6quvzul85YmRBQAAAAAAIEJnAQAAAAAAiFTKaQi//vqrzx9//LHPvXv3jtq9+uqrhR5f1DSEUHrJxv79+/tco0aN3IoFAKCMhUMojzjiiGjf119/XS417LPPPtH2OeecUy7PC1RX8+fPz3cJQKWxYsWKaDtcIvjMM8+M9oXvFcP3iRMmTIja3XLLLT737NnT5wULFkTt/vOf/xR67tNPPz1qd+6552Z/AXnCyAIAAAAAABChswAAAAAAAEQq7DSE33//3ecPPvgg2nf00Uf7PHv2bJ/r1asXtQunEey5554+v/7661G7cKWE0B9//BFtP//88z736NHD51q1ahV6PAAA+ZaeeldWx7z88svR9muvveZzuBoCgNLx0ksv5bsEoNIYMmRItN2tWzefi1r1Z6uttvJ50qRJ0b5wO7wev/vuu6hd+H61SZMmPj/xxBOrKzvvGFkAAAAAAAAidBYAAAAAAIAInQUAAAAAACBSYe5ZsHz58mg7vK/AUUcdlfW4Xr16+bzffvtF+/bee2+fwyUsOnbsGLULl5wKzZkzJ9q+4oorfN5ss8187ty5c9Sudu3aWesFkPt86LFjx/p84YUXllU5QKXXpk0bn0ePHh3tGzhwoM8HH3ywz3Xq1Fmj53r88cd97tev3xqdA0Duwt9v0/cGAZDd0KFDfT7jjDOifeE95xo2bBjte+aZZ3xef/31fb7kkkuidmPGjPE5vH9B+vfc8J4I8+bN87l58+ZRu/Dn9xZbbKGKgJEFAAAAAAAgQmcBAAAAAACI5HUaQrg84vXXXx/t69OnT9bj/vGPf/h80UUX+ZweQjJ37lyfw2WbPvzww6hdOG3gsssu8zk9PWH48OE+n3TSST4feOCBUbvwHOHQlbS2bdtm3QdUZeFwrKKWq3nuued8/uSTT3zedttty6YwoApo0aJFtH3NNdeU6vnD6X9MQwDKXjj1NZSewjtr1iyf0/8PANXRww8/7HN6yH/4s/HMM8/M6Xz3339/tH3OOef4PGHChJzOsXLlSp/TU+grytSDECMLAAAAAABAhM4CAAAAAAAQKfdpCH/88YfP1157rc933HFH1G6dddbx+dZbb432nXjiiT6HUw/Cu1BK8RSFKVOm+Lz11ltH7R566CGfw+EgixcvjtqNHz/e56efftrnl156KWqXnpYQCoeSffXVV1nbAVXZeeed53M4RKwojzzyiM/33HNPqdcEIDcjRozIdwlAtVKzZuG/rqfvuL5s2bLyKAeoNI488kifu3TpEu1LT0vIRbiSgSR9/PHHhbYbMmRItL399tsX2q5Zs2bFrqG8MbIAAAAAAABE6CwAAAAAAAAROgsAAAAAAECk3O9ZEM47Du9TUL9+/ahdOI+5U6dO0b6JEyf63L9/f59fe+21qN3SpUt9DpdmPOOMM6J22easNGjQINo++OCDC82DBw+O2oX3M0i7++67s+4DqovWrVvnuwSg0gmXG07fN2D//ff3uW7duqX6vE888US0ffHFF5fq+QEULZx33apVK59nzJgRtQvv5/Pggw+WfWFABdejR48Sn2PRokU+Dxs2LOu+Lbfc0ufjjjuuxM9bUTCyAAAAAAAAROgsAAAAAAAAkXKfhtC7d+9CH1+xYkW03adPH5979eoV7fv8889zeq4bbrjB5yuvvNLnGjVq5HR8rsKlHAvbBhALlzW97777fP7iiy+yHnPvvfcWerwkbbHFFqVYHVBxvPPOOz7fcsstPr/xxhtRu4KCAp/XZDkoSVqwYIHP4bS+nj17Ru1++eWXQo+vV69etF3a0yEASAcddJDPs2fPjvb17du3vMsBqrxwSs9DDz0U7dtoo418fuutt8qtpvLEyAIAAAAAABChswAAAAAAAETKfRrCxhtv7POcOXN8XrZsWdRu2rRpWc9x6KGH+rzPPvv43Llz56hdy5YtfS7tqQcASsd2223n85dffpnHSoCKJ5xyM3369Kztwql766677ho918iRI32ePHmyz2aW9Zh9993X5/PPPz/at99++61RHQByk742a9WqladKgKpl1qxZPj/66KM+r7VW/Hf2c845x+dmzZqVfWF5wMgCAAAAAAAQobMAAAAAAABE6CwAAAAAAACRcr9nwdixY31+8cUXfZ4yZUrUrkmTJj6feeaZ0b7111/fZ+ZnAZVbON/rpZdeymMlQOUVLu1U2sKfx5J0xBFH+BwuaVqnTp0yqwHAXy1atCjaDn+v7tKlS3mXA1QZBx54oM/h/QtOPfXUqN0NN9xQbjXlCyMLAAAAAABAhM4CAAAAAAAQKfdpCOGSTuFQjvSwDgDVw7bbbltolqRPPvmkvMsBKpT+/fv7fN999/k8YMCAEp97yy23jLbr1avnc/v27X0+++yzo3Zt2rQp8XMDWDNDhw71OT31J/0zFMCa6dq1q8/XXnutz+E0vOqCkQUAAAAAACBCZwEAAAAAAIjQWQAAAAAAACLlfs8CAAi1aNHC5+nTp+exEqDiadu2rc8PPfSQz7vttlvU7pprrvF5wYIF0b7OnTv73KlTJ5+PPPLIqN3GG29csmIBlLkOHTr4/Omnn0b76tatW97lAFXSVVddVWiujhhZAAAAAAAAInQWAAAAAACACNMQAACoBGrXru3zueeeG+1LbwOomoYMGZLvEgBUI4wsAAAAAAAAEToLAAAAAABAhM4CAAAAAAAQobMAAAAAAABE6CwAAAAAAAAROgsAAAAAAECEzgIAAAAAABChswAAAAAAAEToLAAAAAAAABFzzuXe2GyupFllVw4K0cI51zjfRaBi49rMC65NFInrMm+4NlEkrs284dpEkbg28ybrtVmszgIAAAAAAFD1MQ0BAAAAAABE6CwAAAAAAACRKt1ZYGbNzextM/vUzD42sx75rgmAZGZPmNkcM/so37UA+JOZ1TGz98xsWubn5g35rgkAPzeBiszMapjZB2b2Sr5rKW1VurNA0gpJPZ1zrSXtLukCM9s2zzUBkJ6UdHC+iwDwF8skdXTO7ShpJ0kHm9nuea4JAD83gYqsh6RP811EWajSnQXOue+dc1MyeYmSL2LT/FYFwDk3VtKCfNcBIOYSP2c21858cCdkIM/4uQlUTGbWTNKhkh7Ldy1loUp3FoTMrKWktpLezW8lAABUXJnhlFMlzZE00jnHz00AAAp3j6TLJK3MdyFloVp0FpjZOpKek3Sxc25xvusBAKCics794ZzbSVIzSbua2fb5rgkAgIrGzA6TNMc5NznftZSVKt9ZYGZrK+koeNo593y+6wEAoDJwzi2UNFrMkwYAoDB7STrCzAokDZHU0cwG5bek0lWlOwvMzCQ9LulT51zffNcDAEBFZmaNzaxhJteVdICkGfmtCgCAisc5d6VzrplzrqWkEyS95Zw7Jc9llaoq3VmgpLfnVCW9PFMzH4fkuyigujOzwZImSNrGzL41s275rgmAJGkTSW+b2YeSJim5Z0GVWwoKqGz4uQkgH8w5bnIMAAAAAAD+VNVHFgAAAAAAgGKiswAAAAAAAEToLAAAAAAAABE6CwAAAAAAQITOAgAAAAAAEKGzAAAAAAAARGoWp3GjRo1cy5Yty6gUFKagoEDz5s2zfNeBio1rs/xxbWJ1uC7zY/LkyfOcc43zXQcqLq7N/ODaxOpwbeZHUddmsToLWrZsqffff790qkJO2rVrl+8SUAlwbZY/rk2sDtdlfpjZrHzXgIqNazM/uDaxOlyb+VHUtck0BAAAAAAAEKGzAAAAAAAAROgsAAAAAAAAEToLAAAAAABAhM4CAAAAAAAQKdZqCAAAAAAqnpkzZ/p80EEH+bxy5cqo3axZLEoAIDeMLAAAAAAAABE6CwAAAAAAQIRpCAAAAEAlc9FFF0XbQ4cO9Xn+/Pk+H3744eVWE4CqhZEFAAAAAAAgQmcBAAAAAACIVPppCJ988onPr7zySrTv4Ycf9nnXXXf1uW3btlnPd/HFF/tcq1at0igRAAAAWCM//vijz0cddZTPEydOjNqZmc9t2rTx+fHHHy/D6gBUZYwsAAAAAAAAEToLAAAAAABAhM4CAAAAAAAQqZT3LAjvRXDppZf6/PPPP2c95n//+5/PQ4YMydquXbt2Pnfs2HFNSwQAICfhz65w6TNJql27ts9TpkzxecmSJVG7QYMG+bzffvtF+5o2bVrsmjbeeGOfjzzyyGhf+HMSQOmbOXNmtB3+rvvuu+9mPe62227zObxON9xww1KsDqhenHM+n3jiidG+1157zefwPnrNmjUr+8LKCSMLAAAAAABAhM4CAAAAAAAQqZTTEI499lifr7vuOp+LmoaQq6OPPtrn9HDQTp06lfj8AACEevfu7fMdd9xR4vP997//LfE5Qrfccku0vd122/l8wgkn+Jwenvm3v/2tVOsAqov58+dH26+++mpOx4VDn9PTkQCsmaVLl/o8bty4aF84JfD111/3+ayzzir7wsoJIwsAAAAAAECEzgIAAAAAABCplNMQNthgA59vuOEGny+55JKoXThsZLPNNvP566+/znruhQsX+hwOJ5GYhgBUBrNmzfI5/D9AkgYPHuzzQw89lPUchx56qM/9+/cvxeqAv3ruueeKfUyjRo2i7TZt2hT7HK1atYq2Z8yY4XP4s/CDDz6I2k2fPr3QvMMOO0TtmIYA5C5cAeGkk06K9oV3Yw+98MIL0XZ65RIAJVevXj2ft95662jfd9995/OcOXPKrabyxMgCAAAAAAAQobMAAAAAAABE6CwAAAAAAACRSnnPgtB5553n87///e9o37Rp03xu0KBBsc994YUXrnlhAMrMm2++GW0///zzPof3JQjnXUuSmeV0/okTJ5agOqB43njjDZ8/++yzaN8222xT6DHhHEpJ2mSTTUq1pnA5qPT9EML7goRefvnlaPuwww4r1ZqAqmzgwIE+p++tFd5HJ/xdt2nTpmVfGADvggsuiLbffvttn8P7/lQljCwAAAAAAAAROgsAAAAAAECk0k9DCF1zzTXR9s033+zz1KlTi32+ZcuWlbgmAGuuW7duPn/00Uc+v/feezkdn55+dPLJJ/vcrl27aF+4VFWdOnWKVSdQEltssUWhOZ/CKQXZph1I8bVy1llnlWlNQFWzxx57+Bz+ntqyZcuoXd++fX1m6gGQP7vuumvWfcOGDfP59ttvj/aV9lTB8sTIAgAAAAAAEKGzAAAAAAAAROgsAAAAAAAAkSp1z4Jjjjkm2t5777197tSpk8/Tp0/P6XzpeyA899xzJagOQGHmz5/v85VXXhnte+KJJ3zeYIMNfE7fb+CKK67wefvtt/e5bt26UbvNNtusZMUCVcjy5cuj7e7du/s8YMCAnM4xfvx4n9u2bVs6hQFV1PDhw6Ptd9991+dwad/jjjsuapf+WQag4gnvdffSSy9F+84999zyLqfUMLIAAAAAAABE6CwAAAAAAACRKjUNYdCgQdH2hx9+6HOuUw9C7du3L3FNAIp24403+vzYY49F+8Jh0eFSqOuss07ZFwZUQW+99ZbP6Z+Z/fv3L/SYWrVqRdv9+vXzuXXr1qVYHVD1LFy40OexY8fmdMz6668fbTdr1qzYz3vvvff6/PXXX2dtd9dddxX73ACKlp7mV5kxsgAAAAAAAEToLAAAAAAAAJFKOQ1hxowZPh911FE+f/HFF1G7FStWlOh5jjjiiBIdD1Rnv/76q8+33357tO+pp57yORwqud9++0XtDjroIJ/r1KlT2iUC1cJ7773nc3hN5fozMrxLuyQ1b97c5xo1apSwOqBqC6+RKVOmRPucc4Ues88+++R07r59+0bb4bUaTheaNWtWTuf49ttvo31NmzbNqQ4AVRcjCwAAAAAAQITOAgAAAAAAEKGzAAAAAAAARCrlPQs+/fRTn7/66iufS3qPgrS777472r7vvvtK9fxAVXbTTTf5fNttt0X7jj/+eJ87derkM/clAErf0KFDfV6Tn5PLli2Ltg899FCfd9llF58PP/zwqF3nzp19btOmTbGfF6gKxowZ43N66cTwHgMtWrTwecMNN8x6vqlTp/o8bty4aN/w4cMLPSa93HB4L4LPPvvM52OOOSZqN2TIkELrA1B9MLIAAAAAAABE6CwAAAAAAACRSjkNIVwusU+fPj5ffvnlUbvffvutRM8ze/bsEh0PVGe33npr1n0nnniiz0w9AMrW0Ucf7XM4je/999+P2s2dO7fY5540aVKhWZJ69erl88UXX+xz+md1kyZNiv28QEW1ZMmSaDucLpu26aab+nzqqaf6vNVWW0XtZs6c6XP4e++LL74YtWvcuLHPBx54oM89e/aM2i1evNjncMnihQsXZq0VQPXEyAIAAAAAABChswAAAAAAAEQq5TSEUPfu3X1OD9vKNpwqfTfoCy+80OdwaBaANbfrrrv6nB6eHF5zdevW9TkcNgmgdOy5554+v/baaz5//fXXUbt58+b5/OOPP/r8/PPPR+0ef/xxn51zWZ935cqVPvft29fnKVOmRO1GjRrl81pr8TcMVG7pFQrCKThp55xzjs/XXXedz+H1J0mXXnqpz6+++qrPDRo0iNode+yxPt91110+f/7551G78847r9Bz7L///lE7VkAAwE9lAAAAAAAQobMAAAAAAABE6CwAAAAAAACRSn/PgtA//vGPnNql51h+8cUXPvfu3dvnqVOnRu1mzZrlM/O4UF29++67Prdt2zbaV6tWLZ//+9//+tyvX7+oXXidHXPMMT5PnDgxate6deuSFQsgq80226zI7VXSP1s7dOjg8/333+9z+H9DUUaPHh1t33nnnT5fdtllOZ0DqKg+/PDDnNuG9ykIhUuES9mvreHDh0fb4bU5YcIEn/fee++sNYT3VAjvcwBgze2www75LqHUMLIAAAAAAABE6CwAAAAAAACRKjUNIVfLly+PtsMh0aFwSLUk1ahRo8xqAiqS77//3udDDz002vfNN9/4fPfdd0f7TjnlFJ832GADn8OlEqX4mluyZInPP/300xpWDKC8hNf5CSec4PMBBxwQtRszZkxO5wunAgKVXXrZ7nDqa+fOnbMeF059LSgoyHqOcBnScNqBJM2cOdPnk046qdDj0+coamlHAGtmiy22yHcJpYaRBQAAAAAAIEJnAQAAAAAAiFTLaQjXXHNNTu26desWbTdr1qwsygEqnJ133tnnRYsWRfv69OnjczgcuSj33HNP1n0HHnigz9tvv32uJQKoAGrW/PPXiPD/DSn3aQhbb711qdYEVCRmVuxj0tNew3OEqy2kVzD57bfffP7b3/7m87hx46J26623XrFrAlA9MbIAAAAAAABE6CwAAAAAAAAROgsAAAAAAEAkr/csmD9/vs9nnHFGtC9cjilc/mVNhUvBPfLIIzkd06VLlxI/L1AZde/e3ecbb7wx2nfRRRcVmtPCecjhck6S1LJlS59vvfVWnxs0aFDsOOLDkgAAIABJREFUWgHEP+MeffTRaF+rVq18Pu6440r1ef/44w+fp02bltMxa6+9drS92267lWpNQD4dccQR0XZ4n5/hw4dH+yZMmOBzeP2ESwqnDRgwwOf0koiNGzf2+frrr/e5adOmqysbQClatmxZvksoNYwsAAAAAAAAEToLAAAAAABAJK/TEMIhzC+//HK0Lxy2nB4+FW5vueWWPk+ePDnrOcJhYIsXL85a0yWXXOLzpptumrUdUJVdeeWVPqeHDE+ZMsXnUaNGZT3HTz/95POhhx4a7bvrrrt8Dq9hALn54Ycfou2DDz7Y53BpNUlauHBhqT73jz/+6HPfvn19fuutt3I6vnXr1tF2+/btS6cwoAKoVatWtF2/fn2ff/nll2jfXnvt5fOaLLGYnrp37LHH+nzIIYcU+3wASsdrr70WbRc1bbeiY2QBAAAAAACI0FkAAAAAAAAiFWYawldffRXtmzhxos/77rtvtC+8k3o4nHHcuHFRu6LuJhsK7xTdu3dvn+vUqZPT8UBVdumll+a7BAApF198cbSdnnoQCn++brPNNj7XrVs36zFLly71OZzGJ8VTD4qa1hdad911fe7Xr19OxwCV0d///vdo+5lnnvE5vHYkafTo0Tmd8/TTT/d5hx128Llt27ZRuw4dOuRaJoA1sNFGG0Xb2223nc8ff/xxeZdTLhhZAAAAAAAAInQWAAAAAACACJ0FAAAAAAAgktd7Fuyxxx6FZkk67bTTfD7//POjfQUFBYXmXK2//vrR9qefflrscwAAkC/7779/tD106NCsbcN5zWFu2LBh1mPC5RY/+OCDNSkxuk/BCy+84DPzqlGdHHbYYYVmAJVPemnUbPf+GTlyZLTN0okAAAAAAKDKoLMAAID/396dR0lZnH0fvyrsoOyLuA4EwqIRRAJuR1GIMS6AKChGAz4CIqAIAgIRBIwYjRLFE40G2VQQBSXKIQqiIElAFkFkVeQdhCA6RARZBIV6/xi8UldneuwZpufu6f5+zsnJr7yr77nOc56yZyq1AAAAwIh0G0Io9jqZQ4cOad63b1/cz4XLI6dPnx63X5UqVTS//fbbhSkRAICU0K5dO9Pu2rWr5vy+Cwu7pSCeMmXKaI69zvG6667T3Lp16yL9uQAARK158+aaV6xYoTm/v11LGlYWAAAAAAAAg8kCAAAAAABgMFkAAAAAAACMlDmzIFa5cuU0Dx48OKHPTJs2LVnlAACQMurVq2fakyZN0ty+fXvz7J133tH8s5/9TPPrr78e9/2NGzeO++yyyy7T3KhRI83htYwAAKS73/3ud5rXrl2ruUuXLlGUkxSsLAAAAAAAAAaTBQAAAAAAwEjZbQgAACAx4da9G2+80TyLbf9g0KBBSa0JAIB0lpWVpXnJkiXRFZJErCwAAAAAAAAGkwUAAAAAAMBgsgAAAAAAABhMFgAAAAAAAIPJAgAAAAAAYDBZAAAAAAAADCYLAAAAAACAwWQBAAAAAAAwmCwAAAAAAACG894n3tm5HBHZmrxykIczvPe1oi4CqY2xGQnGJvLFuIwMYxP5YmxGhrGJfDE2IxN3bBZosgAAAAAAAKQ/tiEAAAAAAACDyQIAAAAAAGCk9WSBc668c26Zc+5D59w659zoqGsCkMs5l+2c+8g5t9o5tyLqegDwvQmkMudcVefcTOfcRufcBufc+VHXBGQ659xE59yXzrm1UdeSDGl9ZoFzzolIJe/9PudcGRH5h4j0994vjbg0IOM557JFpKX3flfUtQDIxfcmkLqcc1NEZLH3foJzrqyIVPTefx11XUAmc85dLCL7RGSq9/6sqOspaqWjLiCZfO5MyL5jzTLH/pO+syMAABwHvjeB1OScqywiF4tIdxER7/1hETkcZU0ARLz37znnsqKuI1nSehuCiIhzrpRzbrWIfCki873370ddEwARyf0DZJ5zbqVzrlfUxQDIxfcmkJLqi0iOiExyzq1yzk1wzlWKuigA6S3tJwu890e8981F5FQRaeWcS7vlIUAJdaH3voWI/FpE+h5bxgUgYnxvAimptIi0EJGnvffniMh+ERkabUkA0l3aTxb84NieroUickXEpQAQEe/9jmP//aWIvCYiraKtCECI700gpWwXke3BSp+Zkjt5AABJk9aTBc65Ws65qsdyBRFpJyIbo60KgHOuknPuxB+yiFwuIml5iixQkvC9CaQm7/1OEdnmnGt07B+1FZH1EZYEIAOk9QGHIlJXRKY450pJ7sTIy977ORHXBECkjoi8lnvwupQWkWne+zejLQmA8L0JpLI7ReTFYzchbBGRWyOuB8h4zrnpItJGRGo657aLyP3e++eiraropPXViQAAAAAAoODSehsCAAAAAAAoOCYLAAAAAACAwWQBAAAAAAAwmCwAAAAAAAAGkwUAAAAAAMBgsgAAAAAAABilC9K5Zs2aPisrK0mlIC/Z2dmya9cuF3UdSG2MzeLH2MSPYVxGY+XKlbu897WirgOpi7EZDcYmfgxjMxr5jc0CTRZkZWXJihUriqYqJKRly5ZRl4ASgLFZ/Bib+DGMy2g457ZGXQNSG2MzGoxN/BjGZjTyG5tsQwAAAAAAAAaTBQAAAAAAwGCyAAAAAAAAGEwWAAAAAAAAg8kCAAAAAABgMFkAAAAAAAAMJgsAAAAAAIBROuoCAAAAAByfLVu2aB42bJjm1157zfRbs2aN5saNGye/MAAlFisLAAAAAACAwWQBAAAAAAAw2IYAAAAAlDD/+te/TPuKK67QXLNmTc19+/Y1/erUqZPcwgCkDVYWAAAAAAAAg8kCAAAAAABgMFkAAAAAAAAMziwAkBTPP/+85rfeess8+/DDDzVv2rQp7jvOO+88zW+88YbmKlWqFEWJAJJo//79mtu0aaP53//+t+kX7rvOyspKdllAiTZnzhzNnTt3Ns969+6t+cEHH9RcsWLF5BcGIC2xsgAAAAAAABhMFgAAAAAAAINtCAAKbdeuXabdo0cPza+//rrmqlWrmn4XXHCB5jPOOEPzokWLTL/FixdrDrckbNiwoZAVAyioHTt2mHZOTk6e/apVq2ba7777ruYVK1Zobty4selXo0aN4y0RSGuffPKJ5i5dumi+5JJLTL/HHntM809+wv8eCOD48W8SAAAAAABgMFkAAAAAAACMjNyGEC7TEhE5fPiw5nB58wsvvBD3HeEyyvXr1xdhdUDJ8atf/cq0s7OzNd97772aBw8ebPpVr149z/dt3LjRtFu1aqX5448/1jxmzBjTb+TIkYkVDGS4jz76SPOTTz5pnm3dujXPz4RjL79+Q4cONe1424VOPvlk0w6/gwGIfPvtt6bds2dPzWeffbbml19+2fRj6wFQvL766ivNM2bM0Dx27FjTL/YWoB/8/ve/N+3hw4cXYXVFg3+rAAAAAAAAg8kCAAAAAABgMFkAAAAAAACMtDqzIPbatXBv5nvvvaf5tddeM/2OHj2a5/ucc3F/1ubNmzU3adLEPONaN6Sz+fPna161apV5dsMNN2h+6KGHCvzu2CvV7r77bs0PPPCA5kmTJpl+nFkAJCa8znDChAkJfaZcuXKmfcstt2hesGCB5j/84Q8Jve/WW281ba5OBKwRI0aY9vvvv685vEaxcuXKxVYTAJElS5aY9sCBAzWH4zT2b8h4f1PGjvVwfMf+rhsVVhYAAAAAAACDyQIAAAAAAGCk7DaEzz//XHPXrl3Nsy1btuT5mT179pj2vn37NHvvNbds2dL0W7lyZYHrO3LkiOYDBw4U+PNASfXdd99pbtiwoXl24403FunPuv766zWH2xBir5Xau3evZpZlAtaoUaM0P/LII3H7de/eXXOtWrU0Dxo0yPQLn61evVpz7FWqOTk5mmvXrq05HNcAch06dEhz7NXdbdq00XzqqacWV0kARGTXrl2ae/XqZZ6tX79ec/g917FjR9OvQ4cOmqdOnao59vrTpUuXag6vFS5btmxByy4yrCwAAAAAAAAGkwUAAAAAAMBgsgAAAAAAABgpc2bB22+/bdo9e/bU/Nlnnx33+8PrDGvWrGmehXtRduzYoTn2eqdt27bl+e6mTZsed31ASXHZZZdpjr06sWLFikX6s2KvbPvBzp07TXvatGmae/fuXaQ1ACXd/v37NR88eFBzVlaW6ffggw9qrlu3btz3hVcHjx07VvOXX35p+lWqVEnz/fffr7l8+fIJVA1klvA8kfDMLRE7NgEUr/bt22sOzygQsWf1zJ07N6H3NWjQQHPs37/bt2/XHP7t2qxZs8SKTQJWFgAAAAAAAIPJAgAAAAAAYKTMNoTY65wS3XoQLlOOfUfr1q01N2rUKO47atSoofmJJ57QHG/bgYhdvvn8888nVCuQDopzCXH9+vU1n3nmmZrXrVtn+n388cfFVhNQ0oRXFf7973/XHLuccujQoZqfeuopzbHXEg8cOFDznDlzNFevXt30u++++zT36dOnoGUDGWXevHmaL7zwQvOsRYsWxV0OgGMqVKgQ91l4JWJROPHEEzXHbpuPCisLAAAAAACAwWQBAAAAAAAwIt2GEC65Wrp0acKfO/300zWHWwAuuuii464pPIUyP+Gyk1RZJgKkmzJlyuSZASSuefPmms8//3zNsdsQFixYoHn+/PmaBwwYYPpt3bo1z58zatQo077zzjsLXCuQSRYvXqw5/D14zZo1hXrfwoULNYe/m5511lmFeh8AEe99nllEpFq1apq//fZbzeGtQSIiU6ZM0bxy5UrNJ510kukX3u51yimnFLLiosXKAgAAAAAAYDBZAAAAAAAADCYLAAAAAACAEemZBY899pjm/fv3x+0Xe4XM/fffr7kw5xTs3r3btMOrpN57772E6rjqqqsK/HMBFMyhQ4c0h3vBYlWuXLk4ygFKpPCK4fBaplg7duzQ3KlTJ82xezSdc5p79OihuWPHjsdVJ5BpXnzxRc1NmjTRHF4bHGvy5Mmaw2tMRezvt+E1x3/84x9Nv379+hW4ViBThef7hN9/IiLjxo3THP5du2LFirjvmzFjhubwauNUxcoCAAAAAABgMFkAAAAAAACMSLch9OrVS3NOTo55VrVqVc3hNRIi/3vNREH95S9/Me377rsvz36xV828/PLLRVYDgB+XnZ2teePGjXH7XXHFFQm9b9euXZo//PBD82zJkiWaO3furLlRo0YJvRsoCbKyso77HeE2vEGDBmk+7bTTjvvdQCaZOHGi5vB33XDrkIjI4cOHNY8ePVrzs88+a/r96le/0jx37lzN3bt3N/0aNGigOdHvTyBTVa9eXfPevXvNs+XLl2sOt+zFbleoVKmS5qZNmxZ1iUnFygIAAAAAAGAwWQAAAAAAAIxItyFcd911eeZkeOONNzSPGTMmbr8yZcpovv32280zth4ARS+88WD79u3m2T//+c+E3tG7d2/NLVq00Lxq1SrT76uvvtL82WefmWfhjQqbN2/WHJ48DZRER44c0bx48WLNsbccxHP11Vebdvh9CiBxa9euNe3vvvtOc+nS8X8l/+CDDzSH2wbyO0n9hhtu0PyPf/zDPHvooYfyfB+A/xXehrB06VLzLPy9tUuXLnHfEd4wxDYEAAAAAABQojFZAAAAAAAADCYLAAAAAACAEemZBcWpQ4cOmmOvswiNHz9ec3i1I4BcBw8e1Pzll1+aZytXrtT8/vvva37nnXcSet+6desKVVP4uT179sTt93//93+aw+vfRERq1KihuV69eoWqA0hFN954o+ZZs2Zpzu+7MJRoPwD5++KLL+I+y++a3jPPPFPz73//+wL/3DvuuMO0Y68GB5CY8847z7Q/+uijhD43fPjwZJRTLFhZAAAAAAAADCYLAAAAAACAkdbbEMIlH4leEXXJJZckqxygxAi3BowaNco8e/311zVv3LixUO+vUqWK5hNOOEFzeHWpiL1WKtSzZ0/Tjnd1IpApduzYoXnixInm2cyZMzWHWwrOPfdc0+/ss8/WPGnSJM2x240AFL1TTz017rMTTzwxae8GUHjhdaiJ/q1Z0rCyAAAAAAAAGEwWAAAAAAAAI622IRw+fNi0V61apTlcehl7svMTTzyhuWHDhkmqDig5OnbsqHnevHnmWfny5TVfffXV5ll4i0B4A0m5cuVMv6ysLM3h8sjGjRubfps2bdJcv359zePGjTP9wq0MQCZasGCB5pEjR8bt9+CDD2ru16+feTZ79mzN4TaEpk2bFkWJQMaLapnyokWLTLty5cqR1AGkmwoVKmgO/75s06aN6Ve2bNniKqnIsbIAAAAAAAAYTBYAAAAAAACDyQIAAAAAAGCU+DMLDhw4oPmFF14wz2L3Wv/gpptuMu2bb75Z809+wvwJEI6d8HwBEZFXX31V8znnnFOo93///fea7733Xs3bt283/erUqaP5lVde0cwZBch0CxcuNO277rorbt833nhDc7t27TTv3LnT9BszZkyen4/9dwCAwok9MyuZwquHn376afPslltuKbY6gHSyYcMG037uuec0165dW3OfPn1Mv5L8PcpfxgAAAAAAwGCyAAAAAAAAGCVyG8I333yjuWfPnprDZcqxHn/8cc2x10Wx9QCIr2rVqqb985//vMDv+Pbbb027c+fOmufMmaM5vJZRROSll17S3KJFiwL/XCBdxW6z+/rrrzXHXtkUXnEaLk0Ox56IyJ49ezSHV7zVrFnzuGoFkCv2GtK6detqDrfS3nHHHYV6fzi+e/furTk7O9v0mzp1aqHeD2Si8LvxiiuuMM/C7bOPPPKI5uuvvz75hRUT/koGAAAAAAAGkwUAAAAAAMAokdsQwiUf+W09aNCggeb8TooGYDVq1Ejz6tWrzbNevXpp/s9//mOeNWvWTHP9+vU1h0uzREQ2bdqk+bzzztP81FNPmX6FvW0BSHex2+fCU9ZjT1wPlybPnj1bc+z3YrVq1TSHW/xiT3UGUDjhtgMRkeHDh2seOHBg3M/95je/0fzpp59qXrNmjek3duxYzeG2vvnz55t+bC0CEjdkyBDNsbd2de3aVfM999xTbDUVJ1YWAAAAAAAAg8kCAAAAAABgMFkAAAAAAACMEnFmwcaNG0173Lhxefb72c9+Ztpvvvlm0moC0lk45kaMGGGePfroo5qPHj1qnsUbc+3btzftcAzHXkMD4Mfl5OTEfVarVi3T/uUvf6n5vffei/u5yZMna77mmmsKXxyAhMRe5f2D2PML+vbtm2e/ypUrm3Z4Dsl9992nuWzZsoUtEchIb7/9tubnn39ec8WKFU2/8CrwdMXKAgAAAAAAYDBZAAAAAAAAjBKxDWHMmDGmPWPGjDz73XnnnaZ9xhlnJK0mIFM88MAD+bYBFL8mTZrEfRZ7pbD3XnP16tU1xy6BbteuXRFVB6CgwvEYb3sCgOTIzs427S5duuTZb8qUKabdoUOHZJWUMlhZAAAAAAAADCYLAAAAAACAwWQBAAAAAAAwUvbMgrVr12r+5ptv4va7/fbbNbdt2zapNQEAkAq6detm2ocPH9Yce65Iy5YtNYfXmA4YMCBJ1QEAkNoOHjyoObwWXERkz549mq+//nrNnTp1Sn5hKYaVBQAAAAAAwGCyAAAAAAAAGCm7DeH555/XPHfuXPMsvBKxf//+mhs1apT8wgAAiFi1atVMe8iQIXlmAADwvyZNmqT5qaeeMs8uuOACzVOnTi22mlIRKwsAAAAAAIDBZAEAAAAAADBSdhvC5Zdfrjn2hMo//elPmtl6AAAAAACIZ9myZaY9duxYzSNGjDDPevbsqblcuXLJLSzFsbIAAAAAAAAYTBYAAAAAAACDyQIAAAAAAGCk7JkFbdu21XzkyJEIKwEAAAAAlFStWrUy7e3bt0dUScnCygIAAAAAAGAwWQAAAAAAAAznvU+8s3M5IrI1eeUgD2d472tFXQRSG2MzEoxN5ItxGRnGJvLF2IwMYxP5YmxGJu7YLNBkAQAAAAAASH9sQwAAAAAAAAaTBQAAAAAAwEjryQLnXCPn3OrgP3udc3dHXReQ6Zxzpznn3nXObXDOrXPO9Y+6JgC5nHMDjo3Ltc656c658lHXBEDEOVfVOTfTObfx2Pfn+VHXBEDEOdf/2HfmunT7WzNjzixwzpUSkX+LSGvvPQdnABFyztUVkbre+w+ccyeKyEoR6ei9Xx9xaUBGc86dIiL/EJGm3vuDzrmXRWSu935ytJUBcM5NEZHF3vsJzrmyIlLRe/911HUBmcw5d5aIvCQirUTksIi8KSJ3eO8/ibSwIpLWKwtitBWRT5koAKLnvf/ce//BsfyNiGwQkVOirQrAMaVFpIJzrrSIVBSRHRHXA2Q851xlEblYRJ4TEfHeH2aiAEgJTURkqff+gPf+exFZJCLXRlxTkcmkyYIbRWR61EUAsJxzWSJyjoi8H20lALz3/xaRR0XkMxH5XET2eO/nRVsVABGpLyI5IjLJObfKOTfBOVcp6qIAyFoRudg5V8M5V1FErhSR0yKuqchkxGTBsaVa7UXklahrAfBfzrkTRGSWiNztvd8bdT1ApnPOVRORDiJST0ROFpFKzrmbo60KgOSu+GkhIk97788Rkf0iMjTakgB47zeIyMMiMl9ytyB8KCLfR1pUEcqIyQIR+bWIfOC9/yLqQgDkcs6VkdyJghe9969GXQ8AERFpJyL/z3uf473/TkReFZELIq4JgMh2Ednuvf9hFd5MyZ08ABAx7/1z3vsW3vuLReQrEUmL8wpEMmeyoKuwBQFIGc45J7n7Ljd478dFXQ8A9ZmInOecq3hsnLaV3DNFAETIe79TRLY55xod+0dtRYRDgYEU4Jyrfey/TxeRTpJGf3em/W0Ix/aObBOR+t77PVHXA0DEOXeRiCwWkY9E5Oixfzzcez83uqoAiIg450aLyA2Su4xylYj08N4firYqAM655iIyQUTKisgWEbnVe7872qoAOOcWi0gNEflORAZ67xdEXFKRSfvJAgAAAAAAUDCZsg0BAAAAAAAkiMkCAAAAAABgMFkAAAAAAAAMJgsAAAAAAIDBZAEAAAAAADCYLAAAAAAAAEbpgnSuWbOmz8rKSlIpyEt2drbs2rXLRV0HUhtjs/gxNvFjGJfRWLly5S7vfa2o60DqYmxGg7GJH8PYjEZ+Y7NAkwVZWVmyYsWKoqkKCWnZsmXUJaAEYGwWP8YmfgzjMhrOua1R14DUxtiMBmMTP4axGY38xibbEAAAAAAAgMFkAQAAAAAAMJgsAAAAAAAABpMFAAAAAADAYLIAAAAAAAAYTBYAAAAAAACDyQIAAAAAAGAwWQAAAAAAAIzSURcAAAAAAEA66Nq1q2kvXbpU80svvaS5devWxVZTYbGyAAAAAAAAGEwWAAAAAAAAg20IMT7++GPNvXv3Ns9efPFFzXXr1i22mgCILFy4UPNll11mnnnv8+x3ySWXJLssAAAAQGVnZ8dt33zzzZrXr19v+pUpUyaZZRUKKwsAAAAAAIDBZAEAAAAAADCYLAAAAAAAAEZSziz45ptvNO/bt888q1KliuaKFSsm48cfl7lz52petGiReTZhwgTNw4YN01y6NEc/AMkwefJkzePHj9dcqlQp0+/IkSOaBwwYoLlbt26mX9++fTUzbgEAmeChhx4y7eHDh2u+9957Nf/hD38otpqAdLNt2zbNK1eujNtv8+bNmr///nvzjDMLAAAAAABAymOyAAAAAAAAGElZh/vwww9rjl369Oijj2oOlwuninPPPTfus1GjRmnu2rWr5gYNGiSzJCBjhNsORESmTp2q+aOPPkroHWG/QYMGmWcdO3bUfMYZZxSiQiDzbN261bT/9Kc/aX7qqac0f/fdd6Zf+D05bdq0JFUHIC/hluBwG5+IiHNO8+OPP665YcOGpt9tt92WpOqA9PP1119rjv0+DIW/i5YrVy6pNRUFVhYAAAAAAACDyQIAAAAAAGAU+3Hgo0eP1ly/fn3NHTp0KO5S8vTFF19EXQKQdsKlWSIiq1ev1nzrrbdqzsnJMf0OHTqU5/saN25s2uFtCJ988kmh6wSQa+LEiZpjtwyGW++eeeYZzeFJ0CJ2697IkSM1x45fAEUjPFn96aef1pzf77Z16tTRfP755yenMCBNhWMudut9PDfddJPmn/wk9f93+9SvEAAAAAAAFCsmCwAAAAAAgMFkAQAAAAAAMIr9zILwKpfu3btrnj9/vunXsmXL4ipJ9u3bp/mxxx5L6DMvv/yy5uHDhxd5TUBJN3v2bM3PPvuseRaO9/C8gVKlSiX07sGDB5v20aNHNffs2bNAdQKZ6vDhw6Ydfv+NGTNGc+yZBUOGDNFctWpVzR988IHpF55ZcOKJJx5XrQB+3JIlSzQPHTo0oc+EZxs0bdq0yGsC0ln4/Th9+vQIK0keVhYAAAAAAACDyQIAAAAAAGAkZRtCvXr1Euq3d+9ezeG1SiIiL774ouZq1aoVTWFxhFetLVu2LKk/C0hnL7zwgubf/va3CX3Ge6853JKQ6GdiJfoOINNNmjTJtH/3u99pfuKJJzTfeeedCb1v3rx5ph1eyXbKKacUpkQA+cjOzjbtu+66K6HPtWvXTvOll15alCUBae2vf/2raU+YMCGiSooPKwsAAAAAAIDBZAEAAAAAADCYLAAAAAAAAEZSziwIr0TcsWOHeRZepRR66623THvWrFmae/ToUWS15SXcV/nTn/5U86effhr3M126dElqTUBJEJ5RICLSv39/zeE1iOXLlzf9ateurTm8uvSrr76K+7PCd8Rewxaef5Lo9YtAJgrH2IgRI8yzzp07a77jjjsSet/WrVs1x+7lBJBc11xzjWmvW7cuz35VqlQx7fD64QoVKhR9YUAaCc/36devn3kWXkF8zjnnaF61alXyCysmrCwAAAAAAAAGkwUAAAAAAMBIyjaEcBlw7DUu4ZWI4ZWFsf785z9rvva1g7mMAAAMhUlEQVTaa82zGjVqHG+JxhdffKE5v60HAERmz56tOfZ6xHhbAFq1amXaCxYs0Dx58mTNPXv2jPtzx44dq7lTp07mWfgOANb333+v+cILL9QcbgcSEXn66ac1ly6d2K8HN998s+YtW7aYZ4MGDSpQnQAKZu3atabtnMuzX+y2ol/+8pdJqwlIJeFW19WrV5tnH3/8seZly5aZZzNmzND89ddfx33/+PHjNV955ZWaGzRoUPBiUxQrCwAAAAAAgMFkAQAAAAAAMJKyDSEUewLrBRdcoDm/bQhr1qzRvG3bNvMs0W0I4QmVzzzzTNx+r7zySkLvAzJR7BL/u+++O27f8MaCcOvBk08+mdDPOvvss007vFklv9PZr7/+es3PPvus5uXLlyf0c4F0NnPmTM2bNm3S/O6775p+1atXT+h906ZN07x06VLNsbeUsA0BKHoDBw5MqF+7du00jxw5MlnlACkt/BvytttuM8/CbQixwr9fwy2y4U0iIiL16tXTvH379kLXmcpYWQAAAAAAAAwmCwAAAAAAgMFkAQAAAAAAMJJ+ZkGs8MyCKVOmJPSZJUuWmHbz5s01/+tf/8ozi9jrMh544IEC1ZmXJk2aaK5Wrdpxvw8oCcaMGWPa+/fvj9t3+PDhmocNG5bQ+y+66CLNv/71r82zOnXqJPSOE044QXN4bgIA+13bqFEjzeH3cX527txp2gMGDNB85MgRzf369TP9Eh2/APLXp08fzeH1xbGaNWumObyqnO9FZKrwb7fwPDyR/M/Oq1y5subTTz+9SGvK7/foVMTKAgAAAAAAYDBZAAAAAAAAjGLfhtCjRw/NCxcu1BxexRSrb9+++bbj8d5rds4lWGF869ev1xwuA4u9igMo6VavXq053M4jYpcdHz169Lh/VoMGDY77HaFw3Ie1ApnqzTff1BxuyStTpkzcz+zdu1dzp06dzLOcnBzNvXv31jx06NDjqhNArmXLlpl2+Dtn7LagUK9evTTXqlWr6AsDSrBy5cqZ9llnnVWk7w+vDz7ppJPMs3Dc/u1vf9McXhGeqlhZAAAAAAAADCYLAAAAAACAUezbEEL33HOP5unTpyf1ZxXFNoTQ0qVLNbMNAelg7dq1msNlx7t37zb9SpUqVWw1JSrcKnHo0CHNqVgrkGwLFiyI+6xDhw5xn7311luab7/9ds1bt241/Ro2bKj5oYce0hyeHg2g8CZOnGjan3/+eZ79wpPeRfIf3wCSq0aNGpqzsrLMs3AbwqWXXlpcJRUJVhYAAAAAAACDyQIAAAAAAGAwWQAAAAAAAIxIzyxItnBfZXhmwZVXXmn6Va1aVfPo0aOTXxiQgu666y7N27Zti7CSgps5c6bm5cuXR1gJEL3atWubdvny5TV36dJFc+y1qOGViLFXTIXC64urVKlS6DoB/Nfjjz+u+bnnnjPP4p279fbbb5v2ySefXPSFAShSdevWjbqEAmFlAQAAAAAAMJgsAAAAAAAARonchhBeTXHaaadpHjRokOnXtWvXhN63atUqzWxDAPL3yCOPRF2CbNy40bSHDBmSZ7/Yq2vC5dhAuvr5z39u2s8884zmcHlz8+bNTb/wO7Nfv36azz33XNMvvFYRQOGFW/4mTJig+ciRI6Zf6dL//XW9R48emtl2AJQ8sVsFUx0rCwAAAAAAgMFkAQAAAAAAMCLdhvDTn/5Uc7du3cyzLVu2aG7SpIl51qdPH82xyy2Ly7x58zTv3r3bPKtWrVpxlwMUm3AbUHEKtx506NDBPNu1a5fmOnXqaA5vSYh9BmSK3/72t3lm773pd/fdd2v+4osvNM+aNcv0YzsPUDibN2827WuuuUbzpk2b4n5uwIABmh9++OGiLwyA8cknn2iO/TsvVKFCBc3h78f33HOP6Td48GDN4c1DYRYROXDggOb77rtPc+fOnU2/9u3bx62pqLGyAAAAAAAAGEwWAAAAAAAAg8kCAAAAAABgRHpmQeXKlTVPnDgxwkoKbvv27ZoPHz4cYSVA0Qj3L8de2xTq3r275nD/c1HYt2+faYfvnz17dtzPheefzJkzR3OjRo2KsDogvSxatMi0n3zySc3hXslf/OIXxVYTkM5ir/3N75yCUHi2AYDCif177dNPP9X817/+1Tz7y1/+ovngwYNx31m2bFnNlSpV0pzfOQfh+QO1atWKW+OePXs0n3TSSaYfZxYAAAAAAIDIMFkAAAAAAACMSLchpIqqVatqrlu3rubPP/88oc8PGzbMtJ999lnNpUvzf2KUDOGy4zVr1mjeu3dv3M9ceumlpu2c0xxebxi7HeCRRx7RHG5/OHTokOm3fPlyzeHyruHDh5t+nTp1ivuzAOSta9eupn3KKadoHjJkSHGXA6S9/JYmh9q0aWPaZ555ZhKqAdJfeA1w//79zbMZM2YU+H2x2wHC33vPOusszc2aNSvwu/PTrVu3In1fQbCyAAAAAAAAGEwWAAAAAAAAgzXyIlKvXj3Ns2bN0nzttdeafuFSltCUKVNMOzxRmm0IKCnatm2r+dVXX9UcLvEXsdsSYk9TL1WqlObFixcn9HPDmxfCz4uIXHzxxZrDJVhFfQsDkClWrFih+T//+Y95Nn78eM0nnHBCsdUEZIoRI0Yk1K9Pnz6mXa1atWSUA6S9adOmaS7ItoOrrrpK86BBgzRfeOGFpl+ZMmWOo7qSgZUFAAAAAADAYLIAAAAAAAAYTBYAAAAAAACDDfUxWrdurflvf/ubeXbNNddozsnJifuOcE/oJZdcUoTVAcUj/P/b8BpFEXs16AMPPHDcPyu8hiY8o0BE5JlnntFcpUqV4/5ZQCb69ttvNffs2VNzeFWiiMgtt9xSbDUBmWLt2rWa9+/fH7ffqFGjNF933XXJLAnIGOH5c5MmTTLPTj75ZM033HCDeXbrrbcmt7AShJUFAAAAAADAYLIAAAAAAAAYbEPIxy9+8QvTHjdunOY//vGPmq+++mrTr2XLlsktDChGsUuVR48erbl+/frmWTguNm3apLlx48am3+DBg/N8x0UXXXR8xQL4H+HSyw8//DDPLCJSqVKlYqsJyBTvv/++5m+++SZuv3Llyml2ziW1JiBTZGVlaY7dVovEsLIAAAAAAAAYTBYAAAAAAACDyQIAAAAAAGBwZkEB3HTTTXlmIFN169Yt3zaA6I0fP15zs2bNNDdp0iSKcoCMctttt2keM2aMeXbgwAHNl19+ebHVBACJYmUBAAAAAAAwmCwAAAAAAAAG2xAAAEhju3fv1jxy5EjNpUvzKwBQnLZu3Rp1CQBQIKwsAAAAAAAABpMFAAAAAADAYA0iAABpbOfOnVGXAAAASiBWFgAAAAAAAIPJAgAAAAAAYDBZAAAAAAAADCYLAAAAAACAwWQBAAAAAAAwmCwAAAAAAACG894n3tm5HBHZmrxykIczvPe1oi4CqY2xGQnGJvLFuIwMYxP5YmxGhrGJfDE2IxN3bBZosgAAAAAAAKQ/tiEAAAAAAACDyQIAAAAAAGBkxGSBc66Uc26Vc25O1LUAyOWcu8I5t8k5t9k5NzTqegDkcs71d86tdc6tc87dHXU9AESccxOdc18659ZGXQuA/0r3sZkRkwUi0l9ENkRdBIBczrlSIvJnEfm1iDQVka7OuabRVgXAOXeWiPQUkVYi0kxErnbONYy2KgAiMllEroi6CAD/Y7Kk8dhM+8kC59ypInKViEyIuhYAqpWIbPbeb/HeHxaRl0SkQ8Q1ARBpIiJLvfcHvPffi8giEbk24pqAjOe9f09Evoq6DgBWuo/NtJ8sEJHHRWSIiByNuhAA6hQR2Ra0tx/7ZwCitVZELnbO1XDOVRSRK0XktIhrAgAAEUjryQLn3NUi8qX3fmXUtQAwXB7/jHtcgYh57zeIyMMiMl9E3hSRD0Xk+0iLAgAAkUjryQIRuVBE2jvnsiV3mfNlzrkXoi0JgOSuJAj/18pTRWRHRLUACHjvn/Pet/DeXyy5Sys/ibomAABQ/NJ6ssB7P8x7f6r3PktEbhSRd7z3N0dcFgCR5SLS0DlXzzlXVnLH5+sR1wRARJxztY/99+ki0klEpkdbEQAAiEJaTxYASE3HDk7rJyJvSe5NJS9779dFWxWAY2Y559aLyBsi0td7vzvqgoBM55ybLiJLRKSRc267c+62qGsCkP5j03nPNmEAAAAAAPBfrCwAAAAAAAAGkwUAAAAAAMBgsgAAAAAAABhMFgAAAAAAAIPJAgAAAAAAYDBZAAAAAAAADCYLAAAAAACAwWQBAAAAAAAw/j/UKtAjXUzF+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_data[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pJ1IPVoUUeY"
   },
   "source": [
    "### Create global variable to set Activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WEd4Zk8QUUeZ",
    "outputId": "7fa17b40-5ed1-4e65-ee33-40e779866456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function relu at 0x0000021F62327438>\n",
      "is a Swish function:  False\n",
      "is a Swish Beta function:  False\n",
      "is a first function:  False\n",
      "batch size:  100\n"
     ]
    }
   ],
   "source": [
    "act_func_global = tf.nn.relu       #Here I set it default to relu so that our variable became of that type\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "print('is a Swish function: ',is_Swish)\n",
    "is_SwishBeta = False\n",
    "print('is a Swish Beta function: ',is_SwishBeta)\n",
    "is_First = True\n",
    "print('is a first function: ',is_Swish)\n",
    "b_size=100\n",
    "print('batch size: ',b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUVIJIqMxE5i"
   },
   "outputs": [],
   "source": [
    "#Model Execute Time\n",
    "def Execute_Time(model_start_time,model_end_time):\n",
    "  print('Model execution start Time:',round(model_start_time,0))\n",
    "  print('Model execution end Time:',round(model_end_time,0))\n",
    "  Execution_time= model_end_time - model_start_time\n",
    "  print('Model execution Time:',round(Execution_time/60,2),'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fbcHBCeUUeb"
   },
   "source": [
    "### Create CNN Model for different Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1ZSxxZ_UUec"
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # act_func=tf.nn.relu\n",
    "    \n",
    "    print('act_func_global: ',act_func_global)\n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])       #All of our images are of size 150*150\n",
    "    if is_First == True:\n",
    "        print('input layer shape: ',tf.shape(input_layer))\n",
    "        print(input_layer.get_shape())\n",
    "    \n",
    "    if is_Swish == True:\n",
    "        swish_1(input_layer)\n",
    "    if is_SwishBeta == True:\n",
    "        swish_beta(input_layer)\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=act_func_global)\n",
    "    if is_First == True:\n",
    "        print('con1 shape: ',tf.shape(conv1))\n",
    "        print(conv1.get_shape())\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    if is_First == True:\n",
    "        print('pool1 Layer shape: ',tf.shape(pool1))\n",
    "        print(pool1.get_shape())\n",
    "    \n",
    "    #local_response_normalization\n",
    "#     norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 3.0, beta=0.75, name='norm1')\n",
    "#     if is_First == True:\n",
    "#         print('local_response_normalization shape: ',tf.shape(norm1))\n",
    "#         print(norm1.get_shape())\n",
    "    \n",
    "    if is_Swish == True:\n",
    "        swish_1(pool1)\n",
    "    if is_SwishBeta == True:\n",
    "        swish_beta(pool1)\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"valid\",\n",
    "      activation=act_func_global)\n",
    "    if is_First == True:\n",
    "        print('con2 Layer shape: ',tf.shape(conv2))\n",
    "        print(conv2.get_shape())\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    if is_First == True:\n",
    "        print('pool2 Layer shape: ',tf.shape(pool2))\n",
    "        print(pool2.get_shape())\n",
    "    \n",
    "    \n",
    "    # We'll flatten our feature map (pool2) to shape [batch_size, features], so that our tensor has only two dimensions\n",
    "    # pool2_flat = tf.reshape(pool2, [-1, 37 * 37 * 64])\n",
    "    pool2_flat = tf.reshape(pool2, [-1, pool2.get_shape()[1] * pool2.get_shape()[2] * 64])\n",
    "    if is_First == True:\n",
    "        print('pool2_flat shape: ',tf.shape(pool2_flat))\n",
    "        print(pool2_flat.get_shape())\n",
    "    \n",
    "    if is_Swish == True:\n",
    "        swish_1(pool2_flat)        \n",
    "    if is_SwishBeta == True:\n",
    "        swish_beta(pool2_flat)\n",
    "    # Dense Layer\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=act_func_global)\n",
    "    if is_First == True:\n",
    "        print('dense Layer shape: ',tf.shape(dense))\n",
    "        print(dense.get_shape())\n",
    "    \n",
    "    # Drop the 10% of the input\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.2, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    if is_First == True:\n",
    "        print('dropout Regularizatin shape: ',tf.shape(dropout))\n",
    "        print(dropout.get_shape())\n",
    "    \n",
    "        \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10) # Here we have 6 Classes\n",
    "    if is_First == True:\n",
    "        print('logits Layer shape: ',tf.shape(logits))\n",
    "        print(logits.get_shape())\n",
    "    \n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    # loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits, weights=1.0)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        # optimizer = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.9, epsilon=0.5)\n",
    "        # print(\"Optimizer: \",optimizer)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        # print('train_op: ',train_op)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    print(' ')\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0ILb9G4UUee"
   },
   "source": [
    "<img src=\"/content/CNN-Model.jpeg\" width=\"1000\" align=\"Left\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuZ8CrIyUUef"
   },
   "source": [
    "#### Model Explanation:\n",
    "<span style=\"color:#096694\" >\n",
    "\n",
    "- A `cnn_model_fn` function takes features(i.e Input Image data), labels(i.e Image categorie), and mode(i.e Train, Test, Validate) as a input\n",
    "- I have created global variable `act_func_global` of type `tf.nn` and can be set each time for diffrent activation function\n",
    "- 1st layer is `input layer` which takes features and dimention as imput and outputs `4D-tensor` of size `(batch_size, 150 X 150 X 3)`\n",
    "- 2nd layer is Convolutional Layer- `conv1`, with `32` filters and kernel size `3X3` which ouputs 4D-tensor of size `(batch_size, 150 X 150 X 32)` and there is no dimension reduction since we are using `same` padding\n",
    "- 3rd layer is Pooling Layer- `pool1`, with pool size `2X2`, strides = `2` and which ouputs 4D-tensor of size `(batch_size, 75 X 75 X 32)` and there is dimension reduction\n",
    "- 4th layer is Normalization- `local_response_normalization`, Here the 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last dimension), and each vector is normalized independently.  Within a given vector, each component is divided by the weighted, squared sum of inputs within `depth_radius`\n",
    "- 5th layer is Convolutional Layer- `conv2`, with `64` filters and kernel size `3X3` which ouputs 4D-tensor of size `(batch_size, 75 X 75 X 64)` and there is no dimension reduction since we are using `same` padding\n",
    "- 6th layer is Pooling Layer- `pool2`, with pool size `2X2`, strides = `2` and which ouputs 4D-tensor of size `(batch_size, 37 X 37 X 64)` and there is dimension reduction\n",
    "- 7th layer is FLatten Layer- `pool2_flat`, which flatten our feature map (pool2) to shape [batch_size, features], so that our tensor has only two dimensions. The `2-D tensor` size became (batch_size, 87616)\n",
    "- 8th layer is Dense/Fully connected layer- `dense`, which implements the operation:`outputs = activation(inputs * kernel + bias)`. It outputs the tensor of size (batch_size, 1024)\n",
    "- 9th layer is Logits/Dense Layer- `logits`, Here we reduce the size of neurons to output as 6, since we have `6 classes/labels to predict`. The output size of this layer is (batch_size,6)\n",
    "- For predictions I am using `softmax` function on outputs from `tf.nn.softmax`.\n",
    "- To Calculate Loss (for both TRAIN and EVAL modes) I am using `sparse_softmax_cross_entropy` (i.e Cross-entropy loss). Here, `weights` acts as a coefficient for the loss. If a scalar is provided, then the loss is simply scaled by the given value. If weights is a tensor of shape `[batch_size]`, then the loss weights apply to each corresponding sample. \n",
    "- To `optimise` the predictions i am usning `GradientDescentOptimizer` with `learn rate 0.01` that can be tweak futher for better accuracy\n",
    "<br />\n",
    "<br />\n",
    "- In the reshape() operation above, the -1 signifies that the batch_size dimension will be dynamically calculated based on the number of examples in our input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw9BbNVnUUeg"
   },
   "source": [
    "### Create the Estimator\n",
    "Estimator (a TensorFlow class for performing high-level model training, evaluation, and inference) for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdYMZEEYUUeg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "def estimator_path(function_name):\n",
    "    actfn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, \n",
    "            model_dir=\"Estimator_\"+function_name+\"//actfn_convnet_model\")\n",
    "    return actfn_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EUvPyr5BUUej"
   },
   "source": [
    "- The model_fn argument specifies the model function to use for training, evaluation, and prediction; we pass it the actfn_classifier we created\n",
    "- The model_dir argument specifies the directory where model data (checkpoints) will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0GeRFeGUUek"
   },
   "source": [
    "### Set Up a Logging Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQ4Pq_WUUUel"
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LyDKOPeUUev"
   },
   "source": [
    "- Since CNNs can take a while to train, let's set up some logging so we can track progress during training\n",
    "- We set every_n_iter=50, which specifies that probabilities should be logged after every 50 steps of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bsek8HR8UUev"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-X7ROOVUUew"
   },
   "source": [
    "<img src=\"Presentation/sigmoid.png\" width=\"400\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42L07J7eUUex"
   },
   "source": [
    "`Smooth gradient`, preventing “jumps” in output values.<br />\n",
    "`Output values bound` between 0 and 1, normalizing the output of each neuron.<br />\n",
    "`Clear predictions`- For X above 2 or below -2, tends to bring the Y value (the prediction) to the edge of the curve, very close to 1 or 0. This enables clear predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UnHDKlPUUex"
   },
   "source": [
    "#### Set a activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yhk5fRqXwNfn"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "X3ginZ_yUUey",
    "outputId": "13c8ccb4-7772-4dd0-9f95-b900612e83fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:40:07.589185 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 19:40:07.591829 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_sigmoid//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1d9637438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function sigmoid at 0x7fc1f9181620>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.sigmoid\n",
    "actfn_classifier=estimator_path('sigmoid')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "is_First = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri7ZC0VWUUe0"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lFf9BstrUUe0",
    "outputId": "8b54fdd4-f28d-4e74-f878-1eb62edb3ad6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:40:07.649883 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "input layer shape:  Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "(500, 150, 150, 3)\n",
      "con1 shape:  Tensor(\"Shape_1:0\", shape=(4,), dtype=int32)\n",
      "(500, 150, 150, 32)\n",
      "pool1 Layer shape:  Tensor(\"Shape_2:0\", shape=(4,), dtype=int32)\n",
      "(500, 75, 75, 32)\n",
      "local_response_normalization shape:  Tensor(\"Shape_3:0\", shape=(4,), dtype=int32)\n",
      "(500, 75, 75, 32)\n",
      "con2 Layer shape:  Tensor(\"Shape_4:0\", shape=(4,), dtype=int32)\n",
      "(500, 73, 73, 64)\n",
      "pool2 Layer shape:  Tensor(\"Shape_5:0\", shape=(4,), dtype=int32)\n",
      "(500, 36, 36, 64)\n",
      "pool2_flat shape:  Tensor(\"Shape_6:0\", shape=(2,), dtype=int32)\n",
      "(500, 82944)\n",
      "dense Layer shape:  Tensor(\"Shape_7:0\", shape=(2,), dtype=int32)\n",
      "(500, 1024)\n",
      "logits Layer shape:  Tensor(\"Shape_8:0\", shape=(2,), dtype=int32)\n",
      "(500, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:40:07.932401 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 19:40:07.934955 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 19:40:08.053464 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 19:40:08.060331 140472255838080 saver.py:1280] Restoring parameters from Estimator_sigmoid//actfn_convnet_model/model.ckpt-1\n",
      "I0815 19:40:08.523868 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 19:40:08.530622 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 19:40:08.771333 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_sigmoid//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:40:12.812853 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.48359483 0.5164052 ]\n",
      " [0.47859338 0.5214066 ]\n",
      " [0.492985   0.507015  ]\n",
      " [0.49687976 0.5031203 ]\n",
      " [0.489917   0.51008296]\n",
      " [0.48156118 0.5184388 ]\n",
      " [0.49463364 0.5053664 ]\n",
      " [0.48429993 0.51570004]\n",
      " [0.4747026  0.52529734]\n",
      " [0.47624993 0.52375007]\n",
      " [0.4802812  0.51971877]\n",
      " [0.49057108 0.5094289 ]\n",
      " [0.4886283  0.51137173]\n",
      " [0.49767563 0.50232434]\n",
      " [0.49076942 0.5092306 ]\n",
      " [0.49541888 0.50458115]\n",
      " [0.48371604 0.5162839 ]\n",
      " [0.4755964  0.5244036 ]\n",
      " [0.47832847 0.52167153]\n",
      " [0.48814487 0.5118551 ]\n",
      " [0.48942208 0.5105779 ]\n",
      " [0.4884097  0.5115903 ]\n",
      " [0.48681194 0.51318806]\n",
      " [0.5000148  0.49998522]\n",
      " [0.47498244 0.52501756]\n",
      " [0.4942299  0.50577   ]\n",
      " [0.48168287 0.5183171 ]\n",
      " [0.48512083 0.51487917]\n",
      " [0.49696344 0.50303656]\n",
      " [0.4808049  0.51919514]\n",
      " [0.4841352  0.5158648 ]\n",
      " [0.47969767 0.5203023 ]\n",
      " [0.47910088 0.5208991 ]\n",
      " [0.4918954  0.5081046 ]\n",
      " [0.47633317 0.52366686]\n",
      " [0.49405342 0.5059466 ]\n",
      " [0.49259037 0.50740963]\n",
      " [0.47204295 0.527957  ]\n",
      " [0.48190168 0.5180983 ]\n",
      " [0.48311138 0.5168886 ]\n",
      " [0.4757086  0.5242914 ]\n",
      " [0.48359445 0.5164056 ]\n",
      " [0.4900077  0.5099923 ]\n",
      " [0.4876193  0.51238066]\n",
      " [0.48412633 0.5158737 ]\n",
      " [0.4971169  0.5028831 ]\n",
      " [0.4722336  0.52776635]\n",
      " [0.4818403  0.5181597 ]\n",
      " [0.4923105  0.50768954]\n",
      " [0.47811034 0.5218896 ]\n",
      " [0.48533267 0.51466733]\n",
      " [0.48748377 0.51251626]\n",
      " [0.47665137 0.5233486 ]\n",
      " [0.49368837 0.50631166]\n",
      " [0.48568735 0.5143126 ]\n",
      " [0.48323888 0.5167611 ]\n",
      " [0.47507292 0.5249271 ]\n",
      " [0.47300386 0.5269962 ]\n",
      " [0.48878846 0.5112115 ]\n",
      " [0.48082194 0.51917803]\n",
      " [0.48153132 0.5184686 ]\n",
      " [0.49771222 0.50228775]\n",
      " [0.47922277 0.52077717]\n",
      " [0.49334794 0.50665206]\n",
      " [0.4872008  0.5127992 ]\n",
      " [0.49160936 0.5083906 ]\n",
      " [0.48731995 0.51268005]\n",
      " [0.4828344  0.5171656 ]\n",
      " [0.48753974 0.5124603 ]\n",
      " [0.49380204 0.506198  ]\n",
      " [0.489007   0.510993  ]\n",
      " [0.48757705 0.5124229 ]\n",
      " [0.479804   0.520196  ]\n",
      " [0.470199   0.529801  ]\n",
      " [0.48585743 0.5141426 ]\n",
      " [0.47477278 0.52522725]\n",
      " [0.4898124  0.51018757]\n",
      " [0.49348778 0.5065122 ]\n",
      " [0.4922867  0.50771326]\n",
      " [0.493697   0.506303  ]\n",
      " [0.49556124 0.50443876]\n",
      " [0.49068496 0.509315  ]\n",
      " [0.4987376  0.50126237]\n",
      " [0.49032214 0.5096779 ]\n",
      " [0.50639194 0.49360806]\n",
      " [0.48722205 0.512778  ]\n",
      " [0.48067594 0.5193241 ]\n",
      " [0.49490756 0.5050924 ]\n",
      " [0.48100236 0.5189976 ]\n",
      " [0.4846301  0.5153699 ]\n",
      " [0.49433663 0.5056634 ]\n",
      " [0.49329025 0.5067098 ]\n",
      " [0.48001206 0.51998794]\n",
      " [0.49044085 0.5095592 ]\n",
      " [0.49433315 0.50566685]\n",
      " [0.48203203 0.517968  ]\n",
      " [0.48732427 0.5126757 ]\n",
      " [0.4922105  0.5077895 ]\n",
      " [0.48479503 0.51520497]\n",
      " [0.49214244 0.50785756]\n",
      " [0.49269626 0.5073037 ]\n",
      " [0.48536205 0.51463795]\n",
      " [0.4826418  0.51735824]\n",
      " [0.48277155 0.5172285 ]\n",
      " [0.4918053  0.5081947 ]\n",
      " [0.49532193 0.5046781 ]\n",
      " [0.47356448 0.52643555]\n",
      " [0.47716615 0.5228339 ]\n",
      " [0.47090927 0.5290907 ]\n",
      " [0.49278024 0.50721973]\n",
      " [0.47331753 0.52668244]\n",
      " [0.4880886  0.5119114 ]\n",
      " [0.48633826 0.51366174]\n",
      " [0.48781997 0.51218003]\n",
      " [0.4785711  0.52142894]\n",
      " [0.48418292 0.51581705]\n",
      " [0.47951517 0.5204848 ]\n",
      " [0.49945155 0.5005484 ]\n",
      " [0.4835737  0.51642627]\n",
      " [0.4885997  0.51140034]\n",
      " [0.49155638 0.50844365]\n",
      " [0.49389035 0.50610965]\n",
      " [0.47487327 0.5251267 ]\n",
      " [0.47489187 0.5251081 ]\n",
      " [0.4923197  0.5076803 ]\n",
      " [0.4854045  0.5145955 ]\n",
      " [0.48087725 0.5191228 ]\n",
      " [0.48246667 0.51753336]\n",
      " [0.5049404  0.49505958]\n",
      " [0.48751017 0.51248986]\n",
      " [0.49317807 0.506822  ]\n",
      " [0.49567205 0.50432795]\n",
      " [0.4789007  0.52109927]\n",
      " [0.471382   0.52861804]\n",
      " [0.48346332 0.5165367 ]\n",
      " [0.49190885 0.50809115]\n",
      " [0.48741704 0.51258296]\n",
      " [0.48318797 0.516812  ]\n",
      " [0.4839968  0.5160032 ]\n",
      " [0.49381804 0.50618196]\n",
      " [0.49695927 0.5030407 ]\n",
      " [0.48506075 0.51493925]\n",
      " [0.48898718 0.5110128 ]\n",
      " [0.48259744 0.5174026 ]\n",
      " [0.49368683 0.5063132 ]\n",
      " [0.47313526 0.5268647 ]\n",
      " [0.49428883 0.5057112 ]\n",
      " [0.48343468 0.5165653 ]\n",
      " [0.48731738 0.5126826 ]\n",
      " [0.48234734 0.5176527 ]\n",
      " [0.47942775 0.52057225]\n",
      " [0.49177665 0.5082233 ]\n",
      " [0.48961255 0.5103874 ]\n",
      " [0.4915586  0.5084414 ]\n",
      " [0.46332732 0.53667265]\n",
      " [0.49054098 0.50945896]\n",
      " [0.48219267 0.5178073 ]\n",
      " [0.4779298  0.5220702 ]\n",
      " [0.4772408  0.5227592 ]\n",
      " [0.48870775 0.5112923 ]\n",
      " [0.48805425 0.5119458 ]\n",
      " [0.48520648 0.51479346]\n",
      " [0.49687326 0.50312674]\n",
      " [0.49106106 0.50893897]\n",
      " [0.47379833 0.52620167]\n",
      " [0.4888619  0.51113814]\n",
      " [0.47621796 0.5237821 ]\n",
      " [0.48621783 0.5137822 ]\n",
      " [0.4822709  0.5177291 ]\n",
      " [0.48876795 0.511232  ]\n",
      " [0.48069456 0.51930547]\n",
      " [0.49338034 0.5066197 ]\n",
      " [0.4881043  0.51189566]\n",
      " [0.49308205 0.50691795]\n",
      " [0.48571134 0.5142886 ]\n",
      " [0.48157004 0.51843   ]\n",
      " [0.47989613 0.5201039 ]\n",
      " [0.47056663 0.52943337]\n",
      " [0.47674322 0.5232568 ]\n",
      " [0.48237413 0.51762587]\n",
      " [0.47986123 0.5201388 ]\n",
      " [0.48907048 0.51092947]\n",
      " [0.48696262 0.5130374 ]\n",
      " [0.4965703  0.5034297 ]\n",
      " [0.49263826 0.50736177]\n",
      " [0.49497843 0.5050216 ]\n",
      " [0.5027928  0.49720722]\n",
      " [0.49037987 0.50962013]\n",
      " [0.47204423 0.5279558 ]\n",
      " [0.48699686 0.5130032 ]\n",
      " [0.4809192  0.51908076]\n",
      " [0.4789625  0.5210375 ]\n",
      " [0.49006703 0.509933  ]\n",
      " [0.47425896 0.52574104]\n",
      " [0.47358063 0.5264194 ]\n",
      " [0.4825981  0.5174019 ]\n",
      " [0.4839642  0.5160358 ]\n",
      " [0.48757812 0.5124219 ]\n",
      " [0.50471616 0.49528384]\n",
      " [0.48356953 0.5164305 ]\n",
      " [0.49753076 0.5024693 ]\n",
      " [0.50049317 0.4995068 ]\n",
      " [0.47754794 0.52245206]\n",
      " [0.49788174 0.5021183 ]\n",
      " [0.4933956  0.50660443]\n",
      " [0.49449727 0.5055027 ]\n",
      " [0.4778608  0.5221392 ]\n",
      " [0.49836957 0.5016304 ]\n",
      " [0.47389796 0.52610207]\n",
      " [0.49362725 0.50637275]\n",
      " [0.49606085 0.50393915]\n",
      " [0.4849351  0.51506495]\n",
      " [0.480974   0.51902604]\n",
      " [0.4894557  0.51054436]\n",
      " [0.48327178 0.5167283 ]\n",
      " [0.49075446 0.5092456 ]\n",
      " [0.49702153 0.5029785 ]\n",
      " [0.48583832 0.5141617 ]\n",
      " [0.50206    0.49794003]\n",
      " [0.4843736  0.51562643]\n",
      " [0.48643577 0.5135642 ]\n",
      " [0.48207954 0.51792043]\n",
      " [0.48768908 0.5123109 ]\n",
      " [0.4789229  0.52107704]\n",
      " [0.48076212 0.5192379 ]\n",
      " [0.48102155 0.5189785 ]\n",
      " [0.4993853  0.5006147 ]\n",
      " [0.4926362  0.5073638 ]\n",
      " [0.49648872 0.5035113 ]\n",
      " [0.47245702 0.527543  ]\n",
      " [0.49066186 0.50933814]\n",
      " [0.48111525 0.5188847 ]\n",
      " [0.50133514 0.4986649 ]\n",
      " [0.4850973  0.51490265]\n",
      " [0.48847023 0.5115298 ]\n",
      " [0.48650274 0.5134973 ]\n",
      " [0.48339212 0.5166078 ]\n",
      " [0.47852555 0.5214744 ]\n",
      " [0.48894474 0.51105523]\n",
      " [0.49047637 0.50952363]\n",
      " [0.49346238 0.5065376 ]\n",
      " [0.48324117 0.5167588 ]\n",
      " [0.48162398 0.518376  ]\n",
      " [0.48727846 0.51272154]\n",
      " [0.48290738 0.5170926 ]\n",
      " [0.48919147 0.5108085 ]\n",
      " [0.47636724 0.5236328 ]\n",
      " [0.48153716 0.51846284]\n",
      " [0.4949106  0.5050894 ]\n",
      " [0.4967498  0.5032502 ]\n",
      " [0.50284994 0.49715003]\n",
      " [0.47827104 0.52172893]\n",
      " [0.4935508  0.50644916]\n",
      " [0.4835234  0.51647663]\n",
      " [0.48356634 0.5164337 ]\n",
      " [0.4799534  0.5200466 ]\n",
      " [0.4777827  0.5222173 ]\n",
      " [0.48600698 0.513993  ]\n",
      " [0.49078906 0.50921094]\n",
      " [0.48402232 0.5159777 ]\n",
      " [0.49954578 0.5004542 ]\n",
      " [0.48007903 0.519921  ]\n",
      " [0.47787338 0.5221266 ]\n",
      " [0.49034604 0.5096539 ]\n",
      " [0.48352322 0.51647675]\n",
      " [0.47092783 0.52907217]\n",
      " [0.48591438 0.5140856 ]\n",
      " [0.48988998 0.51011   ]\n",
      " [0.47515053 0.5248495 ]\n",
      " [0.47915748 0.52084255]\n",
      " [0.48447475 0.5155253 ]\n",
      " [0.49760154 0.5023985 ]\n",
      " [0.4843949  0.5156051 ]\n",
      " [0.4823424  0.51765764]\n",
      " [0.48981482 0.5101851 ]\n",
      " [0.48650253 0.5134974 ]\n",
      " [0.4988428  0.50115716]\n",
      " [0.48669183 0.51330817]\n",
      " [0.48488227 0.51511776]\n",
      " [0.48604217 0.51395786]\n",
      " [0.48454207 0.51545787]\n",
      " [0.48493    0.51506996]\n",
      " [0.4873504  0.5126496 ]\n",
      " [0.484369   0.515631  ]\n",
      " [0.4956699  0.5043301 ]\n",
      " [0.48191592 0.51808405]\n",
      " [0.47868827 0.5213117 ]\n",
      " [0.46895897 0.531041  ]\n",
      " [0.4836626  0.5163374 ]\n",
      " [0.4890259  0.5109741 ]\n",
      " [0.48100397 0.518996  ]\n",
      " [0.48199293 0.51800704]\n",
      " [0.48936385 0.51063615]\n",
      " [0.48843136 0.51156867]\n",
      " [0.49596134 0.50403863]\n",
      " [0.49079752 0.5092025 ]\n",
      " [0.477734   0.52226603]\n",
      " [0.49560863 0.5043913 ]\n",
      " [0.48882937 0.5111706 ]\n",
      " [0.48213202 0.517868  ]\n",
      " [0.481733   0.518267  ]\n",
      " [0.4806012  0.5193988 ]\n",
      " [0.48741204 0.51258796]\n",
      " [0.47423753 0.5257625 ]\n",
      " [0.4882639  0.5117361 ]\n",
      " [0.4784916  0.5215084 ]\n",
      " [0.48616064 0.5138393 ]\n",
      " [0.48175365 0.51824635]\n",
      " [0.4803718  0.51962817]\n",
      " [0.48496592 0.5150341 ]\n",
      " [0.4750799  0.5249201 ]\n",
      " [0.49445307 0.5055469 ]\n",
      " [0.47985384 0.52014613]\n",
      " [0.49031112 0.5096889 ]\n",
      " [0.49150753 0.50849247]\n",
      " [0.48726478 0.5127352 ]\n",
      " [0.49019572 0.50980425]\n",
      " [0.47984472 0.52015525]\n",
      " [0.49083927 0.50916076]\n",
      " [0.4846783  0.5153217 ]\n",
      " [0.48580778 0.5141922 ]\n",
      " [0.4866034  0.51339656]\n",
      " [0.498689   0.501311  ]\n",
      " [0.49304017 0.50695986]\n",
      " [0.49507663 0.50492334]\n",
      " [0.48981798 0.510182  ]\n",
      " [0.49137086 0.50862914]\n",
      " [0.4876986  0.51230145]\n",
      " [0.48751208 0.5124879 ]\n",
      " [0.4780251  0.5219749 ]\n",
      " [0.49015313 0.50984687]\n",
      " [0.4788506  0.52114946]\n",
      " [0.490046   0.50995404]\n",
      " [0.48940045 0.51059955]\n",
      " [0.48781377 0.5121862 ]\n",
      " [0.48729104 0.51270896]\n",
      " [0.48526916 0.5147308 ]\n",
      " [0.48784038 0.5121596 ]\n",
      " [0.46975118 0.5302489 ]\n",
      " [0.48790595 0.512094  ]\n",
      " [0.47170168 0.5282983 ]\n",
      " [0.4947621  0.50523794]\n",
      " [0.48994282 0.5100572 ]\n",
      " [0.49282828 0.5071717 ]\n",
      " [0.48318264 0.51681733]\n",
      " [0.48895425 0.51104575]\n",
      " [0.49365994 0.50634   ]\n",
      " [0.49222594 0.50777406]\n",
      " [0.4820812  0.51791877]\n",
      " [0.4889662  0.5110338 ]\n",
      " [0.4799484  0.5200516 ]\n",
      " [0.4819103  0.5180897 ]\n",
      " [0.4877654  0.5122346 ]\n",
      " [0.47729924 0.5227007 ]\n",
      " [0.48509052 0.5149095 ]\n",
      " [0.48901615 0.5109839 ]\n",
      " [0.47731954 0.52268046]\n",
      " [0.4842521  0.5157479 ]\n",
      " [0.4878388  0.5121612 ]\n",
      " [0.48756936 0.5124306 ]\n",
      " [0.49120182 0.5087982 ]\n",
      " [0.48004836 0.51995164]\n",
      " [0.47790796 0.5220921 ]\n",
      " [0.48526356 0.5147364 ]\n",
      " [0.48238954 0.5176105 ]\n",
      " [0.48912308 0.51087695]\n",
      " [0.4891001  0.5108999 ]\n",
      " [0.49110526 0.50889474]\n",
      " [0.48876035 0.51123965]\n",
      " [0.49733207 0.50266796]\n",
      " [0.48911557 0.51088446]\n",
      " [0.49661484 0.5033851 ]\n",
      " [0.47859243 0.5214076 ]\n",
      " [0.5005919  0.49940813]\n",
      " [0.48966983 0.5103302 ]\n",
      " [0.48932776 0.5106723 ]\n",
      " [0.48990735 0.5100926 ]\n",
      " [0.47708023 0.5229198 ]\n",
      " [0.49735746 0.5026426 ]\n",
      " [0.4761472  0.5238528 ]\n",
      " [0.49092263 0.50907737]\n",
      " [0.4861715  0.5138285 ]\n",
      " [0.4871416  0.5128584 ]\n",
      " [0.4822144  0.51778567]\n",
      " [0.48209965 0.51790035]\n",
      " [0.48154172 0.51845825]\n",
      " [0.4859971  0.5140029 ]\n",
      " [0.49108025 0.5089197 ]\n",
      " [0.47358605 0.526414  ]\n",
      " [0.47564766 0.5243523 ]\n",
      " [0.48692083 0.51307917]\n",
      " [0.4990395  0.50096047]\n",
      " [0.48665467 0.51334536]\n",
      " [0.48502266 0.51497734]\n",
      " [0.48950994 0.5104901 ]\n",
      " [0.48788667 0.51211333]\n",
      " [0.47913164 0.52086836]\n",
      " [0.47248298 0.5275171 ]\n",
      " [0.49395233 0.5060477 ]\n",
      " [0.49334928 0.50665075]\n",
      " [0.48145345 0.5185465 ]\n",
      " [0.47554174 0.5244582 ]\n",
      " [0.4841116  0.51588845]\n",
      " [0.47668514 0.52331483]\n",
      " [0.47765717 0.52234286]\n",
      " [0.4931745  0.5068255 ]\n",
      " [0.48657608 0.5134239 ]\n",
      " [0.47797298 0.522027  ]\n",
      " [0.4874866  0.5125134 ]\n",
      " [0.48755682 0.5124432 ]\n",
      " [0.4908581  0.50914186]\n",
      " [0.50213885 0.49786118]\n",
      " [0.4894434  0.51055664]\n",
      " [0.48199248 0.51800746]\n",
      " [0.4901632  0.5098368 ]\n",
      " [0.48941785 0.5105822 ]\n",
      " [0.47812498 0.521875  ]\n",
      " [0.47475758 0.52524245]\n",
      " [0.48728523 0.51271474]\n",
      " [0.48249528 0.5175047 ]\n",
      " [0.47834715 0.5216528 ]\n",
      " [0.47615537 0.52384466]\n",
      " [0.498312   0.50168794]\n",
      " [0.49209186 0.50790817]\n",
      " [0.48533523 0.5146647 ]\n",
      " [0.47317994 0.5268201 ]\n",
      " [0.48614815 0.5138519 ]\n",
      " [0.4976436  0.5023564 ]\n",
      " [0.48292413 0.51707584]\n",
      " [0.48685402 0.513146  ]\n",
      " [0.4780905  0.5219095 ]\n",
      " [0.48188707 0.51811296]\n",
      " [0.47240508 0.5275949 ]\n",
      " [0.48550716 0.5144928 ]\n",
      " [0.4935041  0.5064959 ]\n",
      " [0.48121095 0.51878905]\n",
      " [0.48371446 0.51628554]\n",
      " [0.48089132 0.5191087 ]\n",
      " [0.47169584 0.52830416]\n",
      " [0.4914498  0.50855017]\n",
      " [0.48716685 0.5128331 ]\n",
      " [0.48174858 0.5182514 ]\n",
      " [0.48649353 0.5135065 ]\n",
      " [0.4903657  0.5096343 ]\n",
      " [0.46980527 0.53019476]\n",
      " [0.49281377 0.5071862 ]\n",
      " [0.47888485 0.5211152 ]\n",
      " [0.48412815 0.5158718 ]\n",
      " [0.48582697 0.51417303]\n",
      " [0.48072195 0.51927805]\n",
      " [0.4902527  0.5097473 ]\n",
      " [0.50525284 0.4947472 ]\n",
      " [0.49355215 0.50644785]\n",
      " [0.48279038 0.51720965]\n",
      " [0.4856294  0.5143706 ]\n",
      " [0.48371536 0.5162847 ]\n",
      " [0.49161968 0.50838035]\n",
      " [0.49491504 0.505085  ]\n",
      " [0.4934703  0.5065297 ]\n",
      " [0.47827417 0.52172583]\n",
      " [0.48505133 0.5149486 ]\n",
      " [0.48702288 0.5129771 ]\n",
      " [0.48962006 0.51037997]\n",
      " [0.49298784 0.5070122 ]\n",
      " [0.49905017 0.50094986]\n",
      " [0.49456325 0.5054367 ]\n",
      " [0.48230827 0.51769173]\n",
      " [0.48577836 0.51422167]\n",
      " [0.48634732 0.5136527 ]\n",
      " [0.48883784 0.51116216]\n",
      " [0.47558454 0.52441543]\n",
      " [0.47991607 0.5200839 ]\n",
      " [0.49685675 0.50314325]\n",
      " [0.49100116 0.5089989 ]\n",
      " [0.494331   0.505669  ]\n",
      " [0.49167207 0.50832796]\n",
      " [0.47494328 0.52505666]\n",
      " [0.49007505 0.50992495]\n",
      " [0.4808836  0.5191164 ]\n",
      " [0.48934823 0.5106518 ]\n",
      " [0.47307178 0.5269282 ]\n",
      " [0.49283874 0.5071612 ]\n",
      " [0.4926888  0.5073112 ]\n",
      " [0.48611563 0.5138844 ]\n",
      " [0.47438937 0.5256106 ]\n",
      " [0.48776123 0.51223874]\n",
      " [0.4777947  0.5222053 ]\n",
      " [0.47882992 0.5211701 ]\n",
      " [0.4933718  0.50662816]\n",
      " [0.483166   0.516834  ]\n",
      " [0.4890109  0.51098907]\n",
      " [0.48242012 0.51757985]\n",
      " [0.4809452  0.5190548 ]\n",
      " [0.5008134  0.4991866 ]\n",
      " [0.48294494 0.5170551 ]\n",
      " [0.49051693 0.50948304]\n",
      " [0.47965294 0.52034706]\n",
      " [0.47545204 0.524548  ]\n",
      " [0.49072984 0.50927013]\n",
      " [0.47893256 0.52106744]]\n",
      "I0815 19:40:12.814857 140472255838080 basic_session_run_hooks.py:262] loss = 0.6958163, step = 1\n",
      "I0815 19:40:12.816555 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 2 into Estimator_sigmoid//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:40:15.650542 140472255838080 estimator.py:368] Loss for final step: 0.6958163.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d9637978>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    \n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o00SBQd1UUe3"
   },
   "source": [
    "#### Now—without logging each step—set steps=1000 to train the model longer, but in a reasonable time to run this example. Training CNNs is computationally intensive. To increase the accuracy of your model, increase the number of steps passed to train(), like 20,000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "im7rRnP8UUe4",
    "outputId": "adc41454-b449-40eb-8b09-bec23d11a0f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:40:15.692613 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "input layer shape:  Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "(500, 150, 150, 3)\n",
      "con1 shape:  Tensor(\"Shape_1:0\", shape=(4,), dtype=int32)\n",
      "(500, 150, 150, 32)\n",
      "pool1 Layer shape:  Tensor(\"Shape_2:0\", shape=(4,), dtype=int32)\n",
      "(500, 75, 75, 32)\n",
      "local_response_normalization shape:  Tensor(\"Shape_3:0\", shape=(4,), dtype=int32)\n",
      "(500, 75, 75, 32)\n",
      "con2 Layer shape:  Tensor(\"Shape_4:0\", shape=(4,), dtype=int32)\n",
      "(500, 73, 73, 64)\n",
      "pool2 Layer shape:  Tensor(\"Shape_5:0\", shape=(4,), dtype=int32)\n",
      "(500, 36, 36, 64)\n",
      "pool2_flat shape:  Tensor(\"Shape_6:0\", shape=(2,), dtype=int32)\n",
      "(500, 82944)\n",
      "dense Layer shape:  Tensor(\"Shape_7:0\", shape=(2,), dtype=int32)\n",
      "(500, 1024)\n",
      "logits Layer shape:  Tensor(\"Shape_8:0\", shape=(2,), dtype=int32)\n",
      "(500, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:40:15.980105 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 19:40:15.983613 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 19:40:16.423685 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 19:40:16.430855 140472255838080 saver.py:1280] Restoring parameters from Estimator_sigmoid//actfn_convnet_model/model.ckpt-2\n",
      "I0815 19:40:16.903770 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 19:40:16.912369 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 19:40:17.207148 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 2 into Estimator_sigmoid//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:40:20.798757 140472255838080 basic_session_run_hooks.py:262] loss = 0.743354, step = 2\n",
      "I0815 19:41:31.607897 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41224\n",
      "I0815 19:41:31.610481 140472255838080 basic_session_run_hooks.py:260] loss = 0.38864738, step = 102 (70.812 sec)\n",
      "I0815 19:42:41.835727 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42394\n",
      "I0815 19:42:41.838363 140472255838080 basic_session_run_hooks.py:260] loss = 0.19106069, step = 202 (70.228 sec)\n",
      "I0815 19:43:52.317656 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.4188\n",
      "I0815 19:43:52.319933 140472255838080 basic_session_run_hooks.py:260] loss = 0.1470185, step = 302 (70.482 sec)\n",
      "I0815 19:45:02.593007 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42298\n",
      "I0815 19:45:02.597100 140472255838080 basic_session_run_hooks.py:260] loss = 0.16956493, step = 402 (70.277 sec)\n",
      "I0815 19:46:12.792586 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42451\n",
      "I0815 19:46:12.795305 140472255838080 basic_session_run_hooks.py:260] loss = 0.14379616, step = 502 (70.198 sec)\n",
      "I0815 19:47:23.328442 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41772\n",
      "I0815 19:47:23.332396 140472255838080 basic_session_run_hooks.py:260] loss = 0.20005769, step = 602 (70.537 sec)\n",
      "I0815 19:48:33.486044 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42536\n",
      "I0815 19:48:33.488843 140472255838080 basic_session_run_hooks.py:260] loss = 0.14676191, step = 702 (70.156 sec)\n",
      "I0815 19:49:43.843385 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42131\n",
      "I0815 19:49:43.845889 140472255838080 basic_session_run_hooks.py:260] loss = 0.1793241, step = 802 (70.357 sec)\n",
      "I0815 19:50:20.396216 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 855 into Estimator_sigmoid//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:50:57.209912 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.36302\n",
      "I0815 19:50:57.212400 140472255838080 basic_session_run_hooks.py:260] loss = 0.14296916, step = 902 (73.366 sec)\n",
      "I0815 19:52:06.975847 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1002 into Estimator_sigmoid//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:52:09.747897 140472255838080 estimator.py:368] Loss for final step: 0.18097167.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d9637978>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYdvBQFrUUe6"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "RuabnvXKUUe6",
    "outputId": "c2de7d39-636f-406b-9bd1-d3b6c631cf36",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:09.782173 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 19:52:09.906130 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 19:52:09.930211 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T19:52:09Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "input layer shape:  Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "(?, 150, 150, 3)\n",
      "con1 shape:  Tensor(\"Shape_1:0\", shape=(4,), dtype=int32)\n",
      "(?, 150, 150, 32)\n",
      "pool1 Layer shape:  Tensor(\"Shape_2:0\", shape=(4,), dtype=int32)\n",
      "(?, 75, 75, 32)\n",
      "local_response_normalization shape:  Tensor(\"Shape_3:0\", shape=(4,), dtype=int32)\n",
      "(?, 75, 75, 32)\n",
      "con2 Layer shape:  Tensor(\"Shape_4:0\", shape=(4,), dtype=int32)\n",
      "(?, 73, 73, 64)\n",
      "pool2 Layer shape:  Tensor(\"Shape_5:0\", shape=(4,), dtype=int32)\n",
      "(?, 36, 36, 64)\n",
      "pool2_flat shape:  Tensor(\"Shape_6:0\", shape=(2,), dtype=int32)\n",
      "(?, 82944)\n",
      "dense Layer shape:  Tensor(\"Shape_7:0\", shape=(2,), dtype=int32)\n",
      "(?, 1024)\n",
      "logits Layer shape:  Tensor(\"Shape_8:0\", shape=(2,), dtype=int32)\n",
      "(?, 2)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:10.018117 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 19:52:10.024677 140472255838080 saver.py:1280] Restoring parameters from Estimator_sigmoid//actfn_convnet_model/model.ckpt-1002\n",
      "I0815 19:52:10.336477 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 19:52:10.347659 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 19:52:20.645629 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-19:52:20\n",
      "I0815 19:52:20.646719 140472255838080 estimator.py:2039] Saving dict for global step 1002: accuracy = 0.9593853, global_step = 1002, loss = 0.13093688\n",
      "I0815 19:52:20.684685 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1002: Estimator_sigmoid//actfn_convnet_model/model.ckpt-1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9593853, 'loss': 0.13093688, 'global_step': 1002}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=20,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ap2qFVdFUUe8",
    "outputId": "decdcd54-fc48-4984-f4e9-94fd21c88335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my_accuracy': {'accuracy': 0.9593853, 'loss': 0.13093688, 'global_step': 1002}}\n"
     ]
    }
   ],
   "source": [
    "eval_metric_ops={'my_accuracy': eval_results}\n",
    "print(eval_metric_ops)\n",
    "# tf.summary.scalar('accuracy', eval_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ix0wBc0zUUe9"
   },
   "source": [
    "- From our sigmoid function we are achieving 'accuracy': 0.9143798 'loss': 0.23210417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "B5hvSbJawuuM",
    "outputId": "863a7a53-4939-401c-d33e-e49d61aa9821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565898008.0\n",
      "Model execution end Time: 1565898741.0\n",
      "Model execution Time: 12.22 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUrBvFmXwyJK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjUNoxI8UUe-"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> tanH function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YrLJU9-UUe-"
   },
   "source": [
    "<img src=\"Presentation/tanH.png\" width=\"400\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6V-GpfoKUUe_"
   },
   "source": [
    "`Zero centered`- making it easier to model inputs that \n",
    "have strongly negative, neutral, and strongly positive values.\n",
    "Otherwise like the Sigmoid function.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqSG_CKUyAf9"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "cJgEYjTRUUe_",
    "outputId": "a269760f-3426-4957-ba55-f381835dd66e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:20.730225 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 19:52:20.732381 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_tanH//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0d2f17358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function tanh at 0x7fc1f94e2620>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.tanh\n",
    "actfn_classifier=estimator_path('tanH')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "is_SwishBeta = False\n",
    "is_First = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrYx6ooNUUfB"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZRPdA6FjUUfC",
    "outputId": "45d2a4e2-748d-442b-95c3-7e9354be14fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:20.769192 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function tanh at 0x7fc1f94e2620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:21.026094 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 19:52:21.028833 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 19:52:21.189995 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 19:52:22.393657 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 19:52:22.401119 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 19:52:22.671700 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 0 into Estimator_tanH//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:52:26.683527 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.77075785 0.22924212]\n",
      " [0.617568   0.38243195]\n",
      " [0.6713588  0.32864124]\n",
      " [0.5428684  0.45713162]\n",
      " [0.6740002  0.32599983]\n",
      " [0.33203655 0.6679635 ]\n",
      " [0.5884884  0.41151163]\n",
      " [0.64465344 0.3553466 ]\n",
      " [0.542609   0.45739105]\n",
      " [0.5493238  0.4506762 ]\n",
      " [0.77806705 0.2219329 ]\n",
      " [0.45677418 0.5432258 ]\n",
      " [0.58834577 0.41165426]\n",
      " [0.58564264 0.41435736]\n",
      " [0.7734132  0.22658683]\n",
      " [0.7437813  0.25621864]\n",
      " [0.51985943 0.4801406 ]\n",
      " [0.47997615 0.5200239 ]\n",
      " [0.3517627  0.6482373 ]\n",
      " [0.44377795 0.5562221 ]\n",
      " [0.8061236  0.19387637]\n",
      " [0.6023103  0.3976897 ]\n",
      " [0.51503664 0.4849634 ]\n",
      " [0.72559434 0.27440566]\n",
      " [0.49446538 0.50553465]\n",
      " [0.56353813 0.43646184]\n",
      " [0.49383873 0.5061613 ]\n",
      " [0.5964773  0.40352267]\n",
      " [0.54364336 0.4563567 ]\n",
      " [0.55212474 0.4478753 ]\n",
      " [0.54102755 0.45897245]\n",
      " [0.75349236 0.24650759]\n",
      " [0.46608403 0.533916  ]\n",
      " [0.6001119  0.39988813]\n",
      " [0.72998893 0.2700111 ]\n",
      " [0.49303934 0.50696063]\n",
      " [0.7564738  0.24352624]\n",
      " [0.43191525 0.5680847 ]\n",
      " [0.43902135 0.56097865]\n",
      " [0.49884602 0.501154  ]\n",
      " [0.5889709  0.41102904]\n",
      " [0.72079045 0.27920952]\n",
      " [0.6454199  0.35458013]\n",
      " [0.5019751  0.49802485]\n",
      " [0.6372973  0.36270276]\n",
      " [0.65835917 0.3416408 ]\n",
      " [0.5373299  0.46267006]\n",
      " [0.60854954 0.39145052]\n",
      " [0.75612444 0.2438756 ]\n",
      " [0.4996952  0.5003048 ]\n",
      " [0.6093487  0.39065126]\n",
      " [0.61561424 0.3843858 ]\n",
      " [0.538145   0.461855  ]\n",
      " [0.3929844  0.60701555]\n",
      " [0.6023659  0.3976341 ]\n",
      " [0.5165034  0.48349664]\n",
      " [0.58540577 0.41459426]\n",
      " [0.45013037 0.5498696 ]\n",
      " [0.49199504 0.50800496]\n",
      " [0.4410713  0.5589287 ]\n",
      " [0.6757121  0.32428786]\n",
      " [0.7970967  0.20290324]\n",
      " [0.27619603 0.723804  ]\n",
      " [0.4762426  0.52375734]\n",
      " [0.4897009  0.5102991 ]\n",
      " [0.75315285 0.24684718]\n",
      " [0.54749846 0.45250154]\n",
      " [0.72550523 0.27449474]\n",
      " [0.4877365  0.51226354]\n",
      " [0.5889307  0.41106924]\n",
      " [0.5438437  0.45615628]\n",
      " [0.70819473 0.2918052 ]\n",
      " [0.8010804  0.19891958]\n",
      " [0.41074848 0.5892515 ]\n",
      " [0.7069693  0.29303068]\n",
      " [0.7316983  0.26830176]\n",
      " [0.5167685  0.48323148]\n",
      " [0.5845977  0.4154023 ]\n",
      " [0.56616163 0.43383837]\n",
      " [0.39304507 0.606955  ]\n",
      " [0.42517415 0.5748258 ]\n",
      " [0.3368216  0.6631784 ]\n",
      " [0.69819367 0.3018063 ]\n",
      " [0.2848716  0.7151284 ]\n",
      " [0.54689986 0.45310014]\n",
      " [0.47776    0.52224004]\n",
      " [0.6365733  0.3634267 ]\n",
      " [0.31957868 0.6804213 ]\n",
      " [0.50622016 0.49377984]\n",
      " [0.74998856 0.25001138]\n",
      " [0.64878964 0.35121036]\n",
      " [0.44364735 0.5563527 ]\n",
      " [0.588845   0.411155  ]\n",
      " [0.5880465  0.41195354]\n",
      " [0.35184962 0.6481503 ]\n",
      " [0.48546696 0.51453304]\n",
      " [0.42672482 0.57327515]\n",
      " [0.73427767 0.26572233]\n",
      " [0.34256458 0.6574354 ]\n",
      " [0.48239267 0.51760733]\n",
      " [0.59961516 0.40038478]\n",
      " [0.58153725 0.41846275]\n",
      " [0.6650091  0.3349909 ]\n",
      " [0.5245267  0.4754733 ]\n",
      " [0.76450896 0.23549104]\n",
      " [0.5830528  0.41694716]\n",
      " [0.47568884 0.5243112 ]\n",
      " [0.6900464  0.30995357]\n",
      " [0.6181845  0.38181552]\n",
      " [0.61048037 0.38951966]\n",
      " [0.6048425  0.3951575 ]\n",
      " [0.37225392 0.62774605]\n",
      " [0.55910254 0.4408974 ]\n",
      " [0.7078672  0.2921328 ]\n",
      " [0.7054581  0.29454193]\n",
      " [0.6561644  0.34383562]\n",
      " [0.85111755 0.14888242]\n",
      " [0.5961704  0.40382954]\n",
      " [0.5198387  0.48016128]\n",
      " [0.5798499  0.4201501 ]\n",
      " [0.4760304  0.5239696 ]\n",
      " [0.36705428 0.6329457 ]\n",
      " [0.77431124 0.22568871]\n",
      " [0.5240384  0.47596163]\n",
      " [0.58364224 0.4163578 ]\n",
      " [0.5814948  0.4185052 ]\n",
      " [0.5887123  0.41128775]\n",
      " [0.63174903 0.36825097]\n",
      " [0.60322225 0.39677778]\n",
      " [0.67907643 0.32092357]\n",
      " [0.6869234  0.3130766 ]\n",
      " [0.57238394 0.42761606]\n",
      " [0.33892    0.66108   ]\n",
      " [0.50669664 0.4933034 ]\n",
      " [0.42888892 0.5711111 ]\n",
      " [0.52008307 0.47991696]\n",
      " [0.5948985  0.40510145]\n",
      " [0.5229485  0.4770515 ]\n",
      " [0.505626   0.494374  ]\n",
      " [0.5547668  0.44523323]\n",
      " [0.5157923  0.4842077 ]\n",
      " [0.567937   0.43206295]\n",
      " [0.33127874 0.66872126]\n",
      " [0.57042366 0.4295763 ]\n",
      " [0.63269156 0.36730844]\n",
      " [0.68458444 0.3154156 ]\n",
      " [0.650713   0.34928694]\n",
      " [0.37582198 0.624178  ]\n",
      " [0.5219752  0.4780248 ]\n",
      " [0.5321419  0.46785802]\n",
      " [0.5796529  0.4203471 ]\n",
      " [0.56028765 0.43971232]\n",
      " [0.6485543  0.35144562]\n",
      " [0.48103788 0.5189621 ]\n",
      " [0.6580469  0.34195307]\n",
      " [0.7051971  0.29480287]\n",
      " [0.5803371  0.41966292]\n",
      " [0.7478646  0.2521354 ]\n",
      " [0.5805944  0.41940555]\n",
      " [0.57636535 0.42363462]\n",
      " [0.5554279  0.44457206]\n",
      " [0.6361264  0.36387354]\n",
      " [0.5327172  0.46728274]\n",
      " [0.60897094 0.39102906]\n",
      " [0.64135695 0.358643  ]\n",
      " [0.75185823 0.24814174]\n",
      " [0.48000452 0.51999545]\n",
      " [0.6698973  0.33010268]\n",
      " [0.5455814  0.45441854]\n",
      " [0.581985   0.41801506]\n",
      " [0.5765735  0.4234265 ]\n",
      " [0.62096614 0.3790339 ]\n",
      " [0.71385396 0.286146  ]\n",
      " [0.5139794  0.4860206 ]\n",
      " [0.6896089  0.31039116]\n",
      " [0.49248213 0.5075179 ]\n",
      " [0.62980336 0.3701966 ]\n",
      " [0.61724    0.38275993]\n",
      " [0.44678366 0.55321634]\n",
      " [0.6201002  0.37989977]\n",
      " [0.48692113 0.5130788 ]\n",
      " [0.65999365 0.34000632]\n",
      " [0.5059211  0.49407887]\n",
      " [0.5687388  0.43126118]\n",
      " [0.35711718 0.6428828 ]\n",
      " [0.40499046 0.59500957]\n",
      " [0.35878122 0.64121884]\n",
      " [0.55725217 0.44274777]\n",
      " [0.6205035  0.37949646]\n",
      " [0.80537045 0.19462952]\n",
      " [0.6358534  0.36414656]\n",
      " [0.696302   0.30369794]\n",
      " [0.44117972 0.5588203 ]\n",
      " [0.56005704 0.439943  ]\n",
      " [0.5030344  0.4969656 ]\n",
      " [0.4583644  0.54163563]\n",
      " [0.590197   0.40980297]\n",
      " [0.77189755 0.22810248]\n",
      " [0.330738   0.669262  ]\n",
      " [0.5862684  0.41373155]\n",
      " [0.703225   0.29677498]\n",
      " [0.5868602  0.41313982]\n",
      " [0.7125185  0.28748152]\n",
      " [0.55346954 0.44653046]\n",
      " [0.67024875 0.32975122]\n",
      " [0.61998445 0.38001555]\n",
      " [0.48814815 0.51185185]\n",
      " [0.5283107  0.47168928]\n",
      " [0.67349434 0.3265057 ]\n",
      " [0.67678887 0.32321113]\n",
      " [0.69291776 0.30708227]\n",
      " [0.38173866 0.61826134]\n",
      " [0.51968807 0.48031193]\n",
      " [0.6588454  0.34115458]\n",
      " [0.58554846 0.41445157]\n",
      " [0.46902037 0.53097963]\n",
      " [0.4825074  0.5174926 ]\n",
      " [0.44926125 0.55073875]\n",
      " [0.6626368  0.3373632 ]\n",
      " [0.49086708 0.5091329 ]\n",
      " [0.49547842 0.50452155]\n",
      " [0.5741     0.42589995]\n",
      " [0.60519236 0.39480758]\n",
      " [0.5755316  0.42446843]\n",
      " [0.66200626 0.3379937 ]\n",
      " [0.5023907  0.49760935]\n",
      " [0.5117007  0.48829937]\n",
      " [0.4475689  0.5524311 ]\n",
      " [0.63042337 0.36957663]\n",
      " [0.5069157  0.49308428]\n",
      " [0.5623884  0.43761155]\n",
      " [0.7867855  0.21321446]\n",
      " [0.6819025  0.31809753]\n",
      " [0.5163484  0.4836516 ]\n",
      " [0.44347733 0.5565227 ]\n",
      " [0.55461913 0.44538084]\n",
      " [0.5261662  0.47383377]\n",
      " [0.5746284  0.42537156]\n",
      " [0.5223531  0.47764686]\n",
      " [0.34556627 0.6544338 ]\n",
      " [0.55811864 0.44188133]\n",
      " [0.84791875 0.15208125]\n",
      " [0.37210554 0.6278944 ]\n",
      " [0.6700412  0.32995874]\n",
      " [0.62844366 0.3715563 ]\n",
      " [0.42055663 0.5794434 ]\n",
      " [0.29263303 0.707367  ]\n",
      " [0.46501815 0.53498185]\n",
      " [0.7336004  0.26639962]\n",
      " [0.69782317 0.30217677]\n",
      " [0.39961684 0.60038316]\n",
      " [0.43978906 0.56021094]\n",
      " [0.6236785  0.3763215 ]\n",
      " [0.7905826  0.20941743]\n",
      " [0.5935853  0.4064147 ]\n",
      " [0.5705245  0.4294755 ]\n",
      " [0.43559486 0.56440514]\n",
      " [0.6915278  0.30847225]\n",
      " [0.74124414 0.25875583]\n",
      " [0.5544511  0.44554892]\n",
      " [0.5496614  0.45033857]\n",
      " [0.45825252 0.5417475 ]\n",
      " [0.6461412  0.35385886]\n",
      " [0.8597909  0.14020902]\n",
      " [0.3639525  0.6360475 ]\n",
      " [0.619531   0.38046902]\n",
      " [0.8156523  0.18434766]\n",
      " [0.59351    0.40649   ]\n",
      " [0.50457036 0.49542964]\n",
      " [0.49613386 0.5038662 ]\n",
      " [0.43189764 0.5681023 ]\n",
      " [0.60037744 0.39962256]\n",
      " [0.54847074 0.4515292 ]\n",
      " [0.51380837 0.48619166]\n",
      " [0.46602702 0.533973  ]\n",
      " [0.8044527  0.19554728]\n",
      " [0.55958    0.44041994]\n",
      " [0.24833927 0.7516607 ]\n",
      " [0.5084772  0.49152282]\n",
      " [0.419948   0.58005196]\n",
      " [0.4353738  0.5646262 ]\n",
      " [0.6073549  0.3926451 ]\n",
      " [0.5573635  0.44263655]\n",
      " [0.6322828  0.36771718]\n",
      " [0.6426331  0.35736692]\n",
      " [0.5801106  0.41988945]\n",
      " [0.5605891  0.43941095]\n",
      " [0.2940944  0.7059056 ]\n",
      " [0.7456075  0.25439253]\n",
      " [0.42931965 0.5706804 ]\n",
      " [0.4264335  0.57356656]\n",
      " [0.4258675  0.57413244]\n",
      " [0.5104351  0.48956487]\n",
      " [0.600455   0.39954504]\n",
      " [0.4977051  0.5022949 ]\n",
      " [0.47607744 0.52392256]\n",
      " [0.6750403  0.32495967]\n",
      " [0.52808684 0.47191316]\n",
      " [0.5225168  0.47748324]\n",
      " [0.5376956  0.46230438]\n",
      " [0.6135228  0.38647717]\n",
      " [0.6837608  0.31623918]\n",
      " [0.68263066 0.31736934]\n",
      " [0.4629341  0.53706586]\n",
      " [0.60359114 0.39640886]\n",
      " [0.45670325 0.54329675]\n",
      " [0.66719913 0.3328009 ]\n",
      " [0.5045784  0.4954216 ]\n",
      " [0.27010268 0.7298973 ]\n",
      " [0.41187224 0.58812773]\n",
      " [0.6343258  0.3656742 ]\n",
      " [0.54378265 0.45621735]\n",
      " [0.76609385 0.23390616]\n",
      " [0.7229319  0.27706805]\n",
      " [0.55918753 0.44081247]\n",
      " [0.6789908  0.32100925]\n",
      " [0.5440499  0.45595005]\n",
      " [0.4641269  0.5358731 ]\n",
      " [0.38110358 0.6188964 ]\n",
      " [0.55928373 0.4407163 ]\n",
      " [0.6874411  0.31255892]\n",
      " [0.6269729  0.37302712]\n",
      " [0.6570076  0.34299242]\n",
      " [0.69883543 0.30116454]\n",
      " [0.63309836 0.36690158]\n",
      " [0.629208   0.37079194]\n",
      " [0.59983987 0.40016013]\n",
      " [0.7705202  0.22947982]\n",
      " [0.840432   0.15956804]\n",
      " [0.39378706 0.606213  ]\n",
      " [0.500577   0.49942306]\n",
      " [0.46256277 0.53743726]\n",
      " [0.6885001  0.31149992]\n",
      " [0.69907755 0.30092248]\n",
      " [0.44449848 0.5555015 ]\n",
      " [0.4901861  0.5098139 ]\n",
      " [0.7828965  0.21710344]\n",
      " [0.51171    0.48829   ]\n",
      " [0.6122423  0.38775778]\n",
      " [0.48313272 0.5168673 ]\n",
      " [0.6609374  0.33906257]\n",
      " [0.47064358 0.5293565 ]\n",
      " [0.50705284 0.4929472 ]\n",
      " [0.424239   0.575761  ]\n",
      " [0.66759664 0.33240342]\n",
      " [0.7390016  0.2609984 ]\n",
      " [0.53372675 0.46627322]\n",
      " [0.37702927 0.6229707 ]\n",
      " [0.4268869  0.5731131 ]\n",
      " [0.34609923 0.6539008 ]\n",
      " [0.73978186 0.26021808]\n",
      " [0.6207593  0.3792407 ]\n",
      " [0.41495177 0.5850482 ]\n",
      " [0.73024005 0.26975998]\n",
      " [0.4941632  0.5058368 ]\n",
      " [0.48943052 0.51056945]\n",
      " [0.49279892 0.507201  ]\n",
      " [0.518563   0.481437  ]\n",
      " [0.6357307  0.36426932]\n",
      " [0.70429677 0.2957033 ]\n",
      " [0.655148   0.34485194]\n",
      " [0.66097206 0.33902788]\n",
      " [0.3613508  0.6386492 ]\n",
      " [0.39156654 0.6084334 ]\n",
      " [0.5391225  0.46087748]\n",
      " [0.65915215 0.34084788]\n",
      " [0.5405744  0.4594256 ]\n",
      " [0.25993183 0.74006814]\n",
      " [0.64132655 0.3586734 ]\n",
      " [0.5214429  0.4785571 ]\n",
      " [0.8309182  0.16908182]\n",
      " [0.5036143  0.4963857 ]\n",
      " [0.5332587  0.4667413 ]\n",
      " [0.6922737  0.30772638]\n",
      " [0.67450994 0.32549006]\n",
      " [0.59308934 0.40691063]\n",
      " [0.64734733 0.35265267]\n",
      " [0.42842788 0.5715722 ]\n",
      " [0.4552401  0.5447599 ]\n",
      " [0.60862035 0.3913797 ]\n",
      " [0.44743767 0.55256236]\n",
      " [0.4969317  0.50306827]\n",
      " [0.64715916 0.35284087]\n",
      " [0.5481059  0.4518941 ]\n",
      " [0.4379188  0.56208116]\n",
      " [0.68205625 0.31794375]\n",
      " [0.68217593 0.31782413]\n",
      " [0.6596948  0.34030524]\n",
      " [0.49058253 0.5094175 ]\n",
      " [0.77998155 0.22001849]\n",
      " [0.62474155 0.37525845]\n",
      " [0.5475205  0.45247945]\n",
      " [0.4553901  0.5446099 ]\n",
      " [0.6457979  0.3542021 ]\n",
      " [0.70949143 0.29050854]\n",
      " [0.49922803 0.50077194]\n",
      " [0.60114425 0.39885575]\n",
      " [0.5205146  0.47948542]\n",
      " [0.68595356 0.31404644]\n",
      " [0.8290677  0.17093231]\n",
      " [0.41072106 0.58927894]\n",
      " [0.6712207  0.32877922]\n",
      " [0.36478475 0.6352152 ]\n",
      " [0.6754491  0.3245509 ]\n",
      " [0.72870517 0.2712949 ]\n",
      " [0.66085345 0.33914655]\n",
      " [0.6685852  0.33141482]\n",
      " [0.60338014 0.39661992]\n",
      " [0.53695124 0.46304876]\n",
      " [0.6950209  0.30497912]\n",
      " [0.70654404 0.29345596]\n",
      " [0.4488921  0.55110794]\n",
      " [0.5414326  0.4585674 ]\n",
      " [0.59828186 0.40171814]\n",
      " [0.5056289  0.49437112]\n",
      " [0.6851581  0.31484193]\n",
      " [0.39071256 0.60928744]\n",
      " [0.40247753 0.59752244]\n",
      " [0.6142667  0.38573334]\n",
      " [0.7157505  0.28424948]\n",
      " [0.5316773  0.46832272]\n",
      " [0.645372   0.35462803]\n",
      " [0.5099045  0.4900955 ]\n",
      " [0.6744246  0.3255754 ]\n",
      " [0.60160404 0.398396  ]\n",
      " [0.8622952  0.1377048 ]\n",
      " [0.7381154  0.26188463]\n",
      " [0.3701881  0.62981194]\n",
      " [0.6596243  0.34037572]\n",
      " [0.45724627 0.54275376]\n",
      " [0.39170608 0.60829395]\n",
      " [0.23530126 0.7646988 ]\n",
      " [0.521198   0.47880203]\n",
      " [0.5933705  0.40662953]\n",
      " [0.7086318  0.2913682 ]\n",
      " [0.55117863 0.44882134]\n",
      " [0.3508719  0.6491281 ]\n",
      " [0.6128574  0.38714257]\n",
      " [0.6968631  0.30313691]\n",
      " [0.5225002  0.47749978]\n",
      " [0.3264226  0.67357737]\n",
      " [0.6319861  0.36801392]\n",
      " [0.54108095 0.45891905]\n",
      " [0.65544933 0.34455067]\n",
      " [0.45716456 0.5428355 ]\n",
      " [0.3476745  0.6523255 ]\n",
      " [0.6014874  0.39851263]\n",
      " [0.68632984 0.31367016]\n",
      " [0.48414004 0.51585996]\n",
      " [0.51425827 0.48574173]\n",
      " [0.7453117  0.25468835]\n",
      " [0.6976006  0.30239943]\n",
      " [0.38386104 0.616139  ]\n",
      " [0.6191937  0.3808063 ]\n",
      " [0.57902974 0.4209703 ]\n",
      " [0.55331767 0.44668236]\n",
      " [0.6267242  0.3732758 ]\n",
      " [0.6927467  0.30725333]\n",
      " [0.49231791 0.5076821 ]\n",
      " [0.60804623 0.3919538 ]\n",
      " [0.64231616 0.35768387]\n",
      " [0.44087008 0.55912995]\n",
      " [0.56896    0.43104   ]\n",
      " [0.3221388  0.6778612 ]\n",
      " [0.73070824 0.26929176]\n",
      " [0.66760284 0.33239713]\n",
      " [0.49536946 0.5046305 ]\n",
      " [0.5157434  0.48425663]\n",
      " [0.65347934 0.34652063]\n",
      " [0.64262676 0.3573733 ]\n",
      " [0.63581955 0.36418048]\n",
      " [0.58273727 0.41726276]\n",
      " [0.48745096 0.51254904]\n",
      " [0.6344723  0.36552766]\n",
      " [0.27005473 0.72994524]\n",
      " [0.5471789  0.45282108]\n",
      " [0.52759814 0.4724019 ]\n",
      " [0.53869104 0.461309  ]\n",
      " [0.38013184 0.61986816]\n",
      " [0.77522063 0.22477943]\n",
      " [0.5225643  0.4774357 ]\n",
      " [0.5283728  0.47162718]\n",
      " [0.5026333  0.49736667]\n",
      " [0.61319935 0.38680065]\n",
      " [0.4692521  0.5307479 ]\n",
      " [0.6099513  0.3900487 ]\n",
      " [0.46260282 0.5373972 ]\n",
      " [0.8035374  0.19646251]\n",
      " [0.5372468  0.4627532 ]\n",
      " [0.32004294 0.67995703]\n",
      " [0.60208946 0.39791048]\n",
      " [0.63049024 0.3695098 ]\n",
      " [0.63811386 0.36188617]\n",
      " [0.42671534 0.5732846 ]\n",
      " [0.48169324 0.51830673]\n",
      " [0.5238409  0.47615913]\n",
      " [0.63378924 0.36621076]\n",
      " [0.56634545 0.43365452]\n",
      " [0.74046147 0.25953856]\n",
      " [0.45466638 0.5453336 ]]\n",
      "I0815 19:52:26.685644 140472255838080 basic_session_run_hooks.py:262] loss = 0.73962283, step = 0\n",
      "I0815 19:52:26.687703 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_tanH//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:52:29.864829 140472255838080 estimator.py:368] Loss for final step: 0.73962283.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d953fba8>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tELDc8xgUUfD"
   },
   "source": [
    "#### Now—without logging each step—set steps=1000 to train the model longer, but in a reasonable time to run this example. Training CNNs is computationally intensive. To increase the accuracy of your model, increase the number of steps passed to train(), like 20,000 steps.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "g2xkc4THUUfE",
    "outputId": "8524d26f-8e11-430d-9459-58ddeea02af7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:29.900499 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function tanh at 0x7fc1f94e2620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 19:52:30.167276 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 19:52:30.170183 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 19:52:30.492761 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 19:52:30.498485 140472255838080 saver.py:1280] Restoring parameters from Estimator_tanH//actfn_convnet_model/model.ckpt-1\n",
      "I0815 19:52:30.903177 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 19:52:30.912039 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 19:52:31.193731 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_tanH//actfn_convnet_model/model.ckpt.\n",
      "I0815 19:52:34.984964 140472255838080 basic_session_run_hooks.py:262] loss = 0.98432213, step = 1\n",
      "I0815 19:53:46.589956 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.39654\n",
      "I0815 19:53:46.592578 140472255838080 basic_session_run_hooks.py:260] loss = 0.11576331, step = 101 (71.608 sec)\n",
      "I0815 19:54:57.164654 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41694\n",
      "I0815 19:54:57.167368 140472255838080 basic_session_run_hooks.py:260] loss = 0.058484204, step = 201 (70.575 sec)\n",
      "I0815 19:56:07.682290 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41808\n",
      "I0815 19:56:07.684732 140472255838080 basic_session_run_hooks.py:260] loss = 0.02163388, step = 301 (70.517 sec)\n",
      "I0815 19:57:19.070754 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.40079\n",
      "I0815 19:57:19.073822 140472255838080 basic_session_run_hooks.py:260] loss = 0.013691131, step = 401 (71.389 sec)\n",
      "I0815 19:58:29.808897 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41366\n",
      "I0815 19:58:29.811299 140472255838080 basic_session_run_hooks.py:260] loss = 0.0136468345, step = 501 (70.738 sec)\n",
      "I0815 19:59:40.582166 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41296\n",
      "I0815 19:59:40.584542 140472255838080 basic_session_run_hooks.py:260] loss = 0.0049441843, step = 601 (70.773 sec)\n",
      "I0815 20:00:51.573006 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.40863\n",
      "I0815 20:00:51.575559 140472255838080 basic_session_run_hooks.py:260] loss = 0.004673006, step = 701 (70.991 sec)\n",
      "I0815 20:02:02.739205 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.40516\n",
      "I0815 20:02:02.743237 140472255838080 basic_session_run_hooks.py:260] loss = 0.0033984766, step = 801 (71.168 sec)\n",
      "I0815 20:02:34.779532 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 847 into Estimator_tanH//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:03:16.508565 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.35557\n",
      "I0815 20:03:16.510928 140472255838080 basic_session_run_hooks.py:260] loss = 0.0028833067, step = 901 (73.768 sec)\n",
      "I0815 20:04:26.734930 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into Estimator_tanH//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:04:29.531437 140472255838080 estimator.py:368] Loss for final step: 0.0023906596.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d953fba8>"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4pRt-48UUfF"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "vi_UKs38UUfG",
    "outputId": "bfa4bd11-b7b1-4796-c817-9c094e672847"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:29.569345 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 20:04:29.682322 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:04:29.704535 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T20:04:29Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function tanh at 0x7fc1f94e2620>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:29.792001 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:04:29.797839 140472255838080 saver.py:1280] Restoring parameters from Estimator_tanH//actfn_convnet_model/model.ckpt-1001\n",
      "I0815 20:04:30.042852 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:04:30.054101 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:04:39.876192 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-20:04:39\n",
      "I0815 20:04:39.877460 140472255838080 estimator.py:2039] Saving dict for global step 1001: accuracy = 0.9791438, global_step = 1001, loss = 0.101240434\n",
      "I0815 20:04:39.916054 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1001: Estimator_tanH//actfn_convnet_model/model.ckpt-1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9791438, 'loss': 0.101240434, 'global_step': 1001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PEQG3C5KUUfH",
    "outputId": "73a51e0d-468d-410d-988e-fed2ff080dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565898741.0\n",
      "Model execution end Time: 1565899480.0\n",
      "Model execution Time: 12.32 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAj29UBuUUfJ"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> ReLU (Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KL2qW5XbUUfJ"
   },
   "source": [
    "<img src=\"Presentation/ReLU.png\" width=\"500\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cg_Mo11rUUfJ"
   },
   "source": [
    "`Computationally efficient`—allows the network to converge very quickly <br />\n",
    "`Non-linear`—although it looks like a linear function, ReLU has a derivative function and allows for backpropagation\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaG6WGlIyBy7"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "Ejgo3CkjUUfK",
    "outputId": "b8c18447-1424-4adb-c898-c6452444ba2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:39.946402 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 20:04:39.949764 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_relu//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1d95d8550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function relu at 0x7fc1f9253a60>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.relu\n",
    "actfn_classifier=estimator_path('relu')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "is_SwishBeta = False\n",
    "is_First = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mV7xStWuUUfM",
    "outputId": "39826a7f-46c6-4127-85e3-e4f3c7707d64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:39.986717 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function relu at 0x7fc1f9253a60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:40.243558 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:04:40.246085 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:04:40.404490 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:04:41.999868 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:04:42.007226 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:04:42.270831 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 0 into Estimator_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:04:46.162966 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.7098108  0.29018918]\n",
      " [0.8864209  0.11357911]\n",
      " [0.205215   0.794785  ]\n",
      " [0.9325028  0.06749715]\n",
      " [0.2657928  0.7342072 ]\n",
      " [0.15133816 0.84866184]\n",
      " [0.09492388 0.90507615]\n",
      " [0.988827   0.011173  ]\n",
      " [0.00915768 0.99084234]\n",
      " [0.6317893  0.36821064]\n",
      " [0.36453852 0.6354615 ]\n",
      " [0.6149601  0.38503996]\n",
      " [0.08825801 0.911742  ]\n",
      " [0.79981756 0.20018241]\n",
      " [0.94951165 0.05048836]\n",
      " [0.34456834 0.6554317 ]\n",
      " [0.97687453 0.0231255 ]\n",
      " [0.61529803 0.38470194]\n",
      " [0.48970357 0.51029646]\n",
      " [0.09360281 0.90639716]\n",
      " [0.9302187  0.06978134]\n",
      " [0.70655346 0.2934466 ]\n",
      " [0.99919015 0.00080983]\n",
      " [0.05072194 0.94927806]\n",
      " [0.34156534 0.6584347 ]\n",
      " [0.8834424  0.11655763]\n",
      " [0.9648595  0.0351405 ]\n",
      " [0.9752112  0.02478873]\n",
      " [0.97406626 0.02593379]\n",
      " [0.9966086  0.00339142]\n",
      " [0.9862785  0.01372156]\n",
      " [0.98868585 0.01131408]\n",
      " [0.5004802  0.49951982]\n",
      " [0.7392122  0.26078784]\n",
      " [0.62298924 0.37701076]\n",
      " [0.93755746 0.06244255]\n",
      " [0.7057684  0.2942316 ]\n",
      " [0.6898061  0.3101939 ]\n",
      " [0.9998597  0.00014032]\n",
      " [0.989017   0.01098293]\n",
      " [0.5084759  0.49152407]\n",
      " [0.6357237  0.36427632]\n",
      " [0.28693312 0.7130669 ]\n",
      " [0.19299227 0.80700773]\n",
      " [0.00224105 0.99775887]\n",
      " [0.00122232 0.9987777 ]\n",
      " [0.9769025  0.02309749]\n",
      " [0.01648746 0.9835126 ]\n",
      " [0.96585476 0.03414525]\n",
      " [0.9780148  0.02198524]\n",
      " [0.9394464  0.06055358]\n",
      " [0.40762582 0.59237415]\n",
      " [0.23312786 0.7668721 ]\n",
      " [0.18319684 0.8168031 ]\n",
      " [0.04571133 0.9542887 ]\n",
      " [0.8416099  0.15839009]\n",
      " [0.9990607  0.00093936]\n",
      " [0.56810373 0.43189633]\n",
      " [0.53841895 0.46158105]\n",
      " [0.91886884 0.08113115]\n",
      " [0.99854183 0.00145821]\n",
      " [0.98854107 0.01145896]\n",
      " [0.78519034 0.21480961]\n",
      " [0.8321037  0.16789626]\n",
      " [0.9901895  0.00981047]\n",
      " [0.9501601  0.04983995]\n",
      " [0.7795413  0.22045869]\n",
      " [0.9765514  0.02344858]\n",
      " [0.81946695 0.18053305]\n",
      " [0.98388517 0.01611487]\n",
      " [0.3080402  0.6919598 ]\n",
      " [0.65680015 0.34319982]\n",
      " [0.99302673 0.00697325]\n",
      " [0.92623055 0.07376948]\n",
      " [0.9608207  0.03917941]\n",
      " [0.8091337  0.19086625]\n",
      " [0.6798223  0.32017767]\n",
      " [0.6452978  0.35470214]\n",
      " [0.99814105 0.00185891]\n",
      " [0.06323515 0.93676484]\n",
      " [0.03058284 0.96941715]\n",
      " [0.61475015 0.38524985]\n",
      " [0.7357464  0.26425356]\n",
      " [0.8832069  0.11679313]\n",
      " [0.9967013  0.00329865]\n",
      " [0.34074047 0.6592595 ]\n",
      " [0.9682901  0.03170993]\n",
      " [0.9860218  0.01397822]\n",
      " [0.28315574 0.7168443 ]\n",
      " [0.01961889 0.9803811 ]\n",
      " [0.9926966  0.0073034 ]\n",
      " [0.3092394  0.6907606 ]\n",
      " [0.6855446  0.3144554 ]\n",
      " [0.81621206 0.18378797]\n",
      " [0.9818049  0.01819505]\n",
      " [0.9680568  0.03194324]\n",
      " [0.8229809  0.17701916]\n",
      " [0.474017   0.52598304]\n",
      " [0.94018155 0.05981845]\n",
      " [0.9993013  0.00069871]\n",
      " [0.92367536 0.07632468]\n",
      " [0.9562147  0.04378524]\n",
      " [0.9356193  0.06438075]\n",
      " [0.8721     0.12789994]\n",
      " [0.0011281  0.99887186]\n",
      " [0.5602823  0.43971774]\n",
      " [0.01865017 0.9813498 ]\n",
      " [0.9682539  0.03174606]\n",
      " [0.19507438 0.8049256 ]\n",
      " [0.1478516  0.8521484 ]\n",
      " [0.62824327 0.3717567 ]\n",
      " [0.98561317 0.01438681]\n",
      " [0.4968219  0.5031781 ]\n",
      " [0.965157   0.03484296]\n",
      " [0.5907753  0.40922472]\n",
      " [0.9755289  0.02447113]\n",
      " [0.9806908  0.0193092 ]\n",
      " [0.91868085 0.08131919]\n",
      " [0.9808168  0.01918327]\n",
      " [0.9749547  0.02504527]\n",
      " [0.9937535  0.00624656]\n",
      " [0.13188337 0.8681166 ]\n",
      " [0.02497098 0.97502905]\n",
      " [0.8246942  0.17530575]\n",
      " [0.5020447  0.49795532]\n",
      " [0.9530129  0.04698715]\n",
      " [0.98965454 0.01034549]\n",
      " [0.29774305 0.7022569 ]\n",
      " [0.09112491 0.9088751 ]\n",
      " [0.9916248  0.00837528]\n",
      " [0.81530464 0.18469541]\n",
      " [0.989687   0.01031298]\n",
      " [0.80613077 0.19386922]\n",
      " [0.996228   0.0037721 ]\n",
      " [0.79073715 0.20926288]\n",
      " [0.45258698 0.54741305]\n",
      " [0.7459401  0.25405997]\n",
      " [0.7780129  0.22198711]\n",
      " [0.3976407  0.60235924]\n",
      " [0.97093934 0.02906071]\n",
      " [0.00602514 0.99397486]\n",
      " [0.4540634  0.54593664]\n",
      " [0.9865819  0.01341813]\n",
      " [0.565467   0.43453303]\n",
      " [0.38248536 0.61751467]\n",
      " [0.96047467 0.03952529]\n",
      " [0.34140387 0.65859616]\n",
      " [0.99354905 0.00645094]\n",
      " [0.9870717  0.01292833]\n",
      " [0.999708   0.000292  ]\n",
      " [0.88443804 0.11556195]\n",
      " [0.9457037  0.05429634]\n",
      " [0.51739854 0.48260152]\n",
      " [0.5885192  0.41148078]\n",
      " [0.9966158  0.00338419]\n",
      " [0.8302559  0.16974403]\n",
      " [0.97648275 0.02351725]\n",
      " [0.9968149  0.00318516]\n",
      " [0.9426066  0.05739336]\n",
      " [0.90437186 0.09562812]\n",
      " [0.03785101 0.962149  ]\n",
      " [0.99310863 0.00689137]\n",
      " [0.9994019  0.00059804]\n",
      " [0.6974974  0.30250254]\n",
      " [0.6754962  0.32450372]\n",
      " [0.7377716  0.26222846]\n",
      " [0.46434098 0.535659  ]\n",
      " [0.99726224 0.00273777]\n",
      " [0.9383919  0.06160812]\n",
      " [0.654868   0.34513202]\n",
      " [0.00011379 0.99988616]\n",
      " [0.91972256 0.08027751]\n",
      " [0.92942816 0.07057185]\n",
      " [0.5688559  0.43114418]\n",
      " [0.40203097 0.59796906]\n",
      " [0.17212278 0.82787716]\n",
      " [0.83936954 0.1606305 ]\n",
      " [0.8392767  0.16072334]\n",
      " [0.9369523  0.06304769]\n",
      " [0.7335993  0.2664007 ]\n",
      " [0.57538927 0.4246107 ]\n",
      " [0.05490459 0.94509536]\n",
      " [0.88043827 0.11956175]\n",
      " [0.8139863  0.18601376]\n",
      " [0.18354946 0.81645054]\n",
      " [0.99741673 0.00258321]\n",
      " [0.225375   0.774625  ]\n",
      " [0.9884319  0.01156814]\n",
      " [0.97222304 0.02777689]\n",
      " [0.1702077  0.8297923 ]\n",
      " [0.99934024 0.00065977]\n",
      " [0.96069753 0.03930244]\n",
      " [0.72172195 0.27827805]\n",
      " [0.00870024 0.9912998 ]\n",
      " [0.02917338 0.9708266 ]\n",
      " [0.0479953  0.9520047 ]\n",
      " [0.0332272  0.96677274]\n",
      " [0.77017355 0.22982644]\n",
      " [0.01746988 0.98253006]\n",
      " [0.9986981  0.00130183]\n",
      " [0.01948505 0.9805149 ]\n",
      " [0.84678966 0.15321034]\n",
      " [0.83663917 0.16336082]\n",
      " [0.01032239 0.98967755]\n",
      " [0.06984007 0.9301599 ]\n",
      " [0.9976641  0.00233591]\n",
      " [0.8750272  0.12497285]\n",
      " [0.5210892  0.4789108 ]\n",
      " [0.98611546 0.01388459]\n",
      " [0.7167397  0.2832603 ]\n",
      " [0.94819057 0.05180945]\n",
      " [0.06677856 0.93322146]\n",
      " [0.97795576 0.02204422]\n",
      " [0.8852932  0.11470687]\n",
      " [0.8735716  0.12642843]\n",
      " [0.03612476 0.96387523]\n",
      " [0.1750074  0.8249926 ]\n",
      " [0.9407067  0.05929329]\n",
      " [0.20975803 0.79024196]\n",
      " [0.00629246 0.99370754]\n",
      " [0.8901769  0.10982309]\n",
      " [0.9790607  0.02093928]\n",
      " [0.9492132  0.05078677]\n",
      " [0.89762837 0.10237165]\n",
      " [0.9882824  0.01171757]\n",
      " [0.53883725 0.46116275]\n",
      " [0.6338327  0.36616734]\n",
      " [0.3387151  0.6612849 ]\n",
      " [0.999514   0.00048599]\n",
      " [0.03933093 0.96066904]\n",
      " [0.06547865 0.9345214 ]\n",
      " [0.8501105  0.1498895 ]\n",
      " [0.9999548  0.00004521]\n",
      " [0.06220229 0.9377977 ]\n",
      " [0.3887097  0.61129034]\n",
      " [0.9767138  0.02328617]\n",
      " [0.12459291 0.8754071 ]\n",
      " [0.6383268  0.36167315]\n",
      " [0.40802243 0.5919776 ]\n",
      " [0.93279356 0.06720637]\n",
      " [0.13880321 0.8611968 ]\n",
      " [0.9331578  0.06684218]\n",
      " [0.88431317 0.11568687]\n",
      " [0.38422653 0.61577344]\n",
      " [0.34798574 0.65201426]\n",
      " [0.87324035 0.12675962]\n",
      " [0.9999478  0.00005217]\n",
      " [0.8953244  0.10467558]\n",
      " [0.57805604 0.42194393]\n",
      " [0.838412   0.16158801]\n",
      " [0.8648128  0.13518725]\n",
      " [0.6087413  0.39125875]\n",
      " [0.04185706 0.9581429 ]\n",
      " [0.99886847 0.00113161]\n",
      " [0.5747662  0.42523375]\n",
      " [0.12203999 0.87796   ]\n",
      " [0.9481837  0.05181622]\n",
      " [0.9902733  0.00972673]\n",
      " [0.4614438  0.53855616]\n",
      " [0.02176037 0.9782396 ]\n",
      " [0.05801109 0.9419889 ]\n",
      " [0.00006564 0.9999343 ]\n",
      " [0.75318205 0.24681795]\n",
      " [0.990699   0.00930101]\n",
      " [0.9216728  0.07832716]\n",
      " [0.14240022 0.8575998 ]\n",
      " [0.6847307  0.3152693 ]\n",
      " [0.00113133 0.99886864]\n",
      " [0.53052294 0.469477  ]\n",
      " [0.66411203 0.335888  ]\n",
      " [0.04453427 0.95546573]\n",
      " [0.50627583 0.4937242 ]\n",
      " [0.6623291  0.3376709 ]\n",
      " [0.98503834 0.01496167]\n",
      " [0.85339355 0.14660648]\n",
      " [0.9514354  0.04856456]\n",
      " [0.462062   0.53793806]\n",
      " [0.46723184 0.5327682 ]\n",
      " [0.8475283  0.15247168]\n",
      " [0.00299504 0.9970049 ]\n",
      " [0.6289695  0.37103045]\n",
      " [0.9407798  0.05922025]\n",
      " [0.98389196 0.01610803]\n",
      " [0.92888033 0.07111961]\n",
      " [0.98111695 0.01888303]\n",
      " [0.9957372  0.00426276]\n",
      " [0.91466624 0.08533374]\n",
      " [0.9508871  0.04911286]\n",
      " [0.39447337 0.6055266 ]\n",
      " [0.99979347 0.00020661]\n",
      " [0.49139228 0.50860775]\n",
      " [0.9683081  0.03169194]\n",
      " [0.9856711  0.01432892]\n",
      " [0.9057488  0.09425122]\n",
      " [0.9384689  0.06153115]\n",
      " [0.08098648 0.9190135 ]\n",
      " [0.97603375 0.0239662 ]\n",
      " [0.21839005 0.7816099 ]\n",
      " [0.6766938  0.32330623]\n",
      " [0.7075606  0.29243937]\n",
      " [0.99866676 0.00133322]\n",
      " [0.9958177  0.0041823 ]\n",
      " [0.99877125 0.00122867]\n",
      " [0.9971324  0.00286756]\n",
      " [0.9997271  0.00027294]\n",
      " [0.9435425  0.05645748]\n",
      " [0.94744706 0.05255291]\n",
      " [0.67295665 0.32704335]\n",
      " [0.952123   0.047877  ]\n",
      " [0.10741461 0.89258534]\n",
      " [0.5982235  0.40177646]\n",
      " [0.08003282 0.91996723]\n",
      " [0.9926714  0.00732869]\n",
      " [0.5237398  0.4762602 ]\n",
      " [0.00002399 0.99997604]\n",
      " [0.86990315 0.13009685]\n",
      " [0.9991679  0.00083208]\n",
      " [0.2527931  0.7472069 ]\n",
      " [0.6188329  0.38116714]\n",
      " [0.03000365 0.96999633]\n",
      " [0.9999198  0.00008024]\n",
      " [0.9557451  0.0442549 ]\n",
      " [0.02540975 0.97459024]\n",
      " [0.6449642  0.35503575]\n",
      " [0.99926025 0.00073975]\n",
      " [0.9819724  0.01802757]\n",
      " [0.9507583  0.04924171]\n",
      " [0.01881971 0.9811803 ]\n",
      " [0.92793494 0.07206506]\n",
      " [0.01394351 0.98605645]\n",
      " [0.9999769  0.00002308]\n",
      " [0.23175308 0.76824695]\n",
      " [0.00817271 0.99182725]\n",
      " [0.6002414  0.39975855]\n",
      " [0.9209081  0.07909195]\n",
      " [0.00776162 0.99223834]\n",
      " [0.8986325  0.10136744]\n",
      " [0.9831724  0.01682758]\n",
      " [0.7764864  0.22351357]\n",
      " [0.99555945 0.00444049]\n",
      " [0.6312703  0.3687297 ]\n",
      " [0.9949175  0.00508256]\n",
      " [0.08070716 0.91929287]\n",
      " [0.09593885 0.90406114]\n",
      " [0.9667194  0.03328057]\n",
      " [0.7434555  0.2565445 ]\n",
      " [0.5731085  0.4268915 ]\n",
      " [0.9973973  0.00260268]\n",
      " [0.8017407  0.19825926]\n",
      " [0.90931684 0.0906831 ]\n",
      " [0.06001839 0.9399816 ]\n",
      " [0.45396242 0.54603755]\n",
      " [0.34697095 0.653029  ]\n",
      " [0.7676504  0.2323496 ]\n",
      " [0.5075582  0.49244174]\n",
      " [0.8291517  0.17084831]\n",
      " [0.68493307 0.31506693]\n",
      " [0.0001696  0.99983037]\n",
      " [0.91233945 0.08766058]\n",
      " [0.9999162  0.00008381]\n",
      " [0.99962354 0.00037647]\n",
      " [0.5017965  0.49820352]\n",
      " [0.9971705  0.00282954]\n",
      " [0.6105503  0.3894497 ]\n",
      " [0.6970147  0.30298528]\n",
      " [0.97667    0.02333003]\n",
      " [0.9631777  0.03682233]\n",
      " [0.00040773 0.99959224]\n",
      " [0.14429387 0.85570616]\n",
      " [0.94099015 0.05900992]\n",
      " [0.88758963 0.11241031]\n",
      " [0.7017079  0.29829213]\n",
      " [0.13507785 0.8649221 ]\n",
      " [0.99341005 0.00658994]\n",
      " [0.99033386 0.00966621]\n",
      " [0.9675941  0.03240597]\n",
      " [0.04686576 0.95313424]\n",
      " [0.45513144 0.5448686 ]\n",
      " [0.1589741  0.84102595]\n",
      " [0.00086962 0.9991304 ]\n",
      " [0.71815467 0.2818453 ]\n",
      " [0.6995269  0.30047312]\n",
      " [0.16288798 0.837112  ]\n",
      " [0.07124726 0.9287527 ]\n",
      " [0.9505983  0.04940166]\n",
      " [0.59137946 0.40862054]\n",
      " [0.00556377 0.99443626]\n",
      " [0.16943632 0.83056366]\n",
      " [0.6553466  0.34465346]\n",
      " [0.74150336 0.25849667]\n",
      " [0.0305839  0.96941614]\n",
      " [0.508444   0.49155602]\n",
      " [0.92325795 0.07674202]\n",
      " [0.99901867 0.00098135]\n",
      " [0.30458155 0.6954184 ]\n",
      " [0.9956514  0.00434855]\n",
      " [0.62634206 0.37365794]\n",
      " [0.4730453  0.5269547 ]\n",
      " [0.9988996  0.00110039]\n",
      " [0.7259563  0.2740437 ]\n",
      " [0.08769514 0.9123049 ]\n",
      " [0.99813926 0.00186071]\n",
      " [0.12290082 0.87709916]\n",
      " [0.9569063  0.04309371]\n",
      " [0.08596297 0.91403705]\n",
      " [0.5975079  0.4024921 ]\n",
      " [0.27309608 0.7269039 ]\n",
      " [0.94819486 0.05180512]\n",
      " [0.7549762  0.2450238 ]\n",
      " [0.98840886 0.01159116]\n",
      " [0.64802444 0.35197553]\n",
      " [0.43443415 0.5655659 ]\n",
      " [0.01035952 0.9896404 ]\n",
      " [0.76738054 0.2326195 ]\n",
      " [0.97213566 0.02786441]\n",
      " [0.7776018  0.22239816]\n",
      " [0.9654304  0.03456963]\n",
      " [0.19549671 0.80450326]\n",
      " [0.99924785 0.00075206]\n",
      " [0.03149537 0.9685046 ]\n",
      " [0.09314259 0.90685743]\n",
      " [0.9924372  0.00756278]\n",
      " [0.90527326 0.09472676]\n",
      " [0.9813223  0.01867766]\n",
      " [0.9753728  0.02462719]\n",
      " [0.06877092 0.93122905]\n",
      " [0.9817556  0.01824439]\n",
      " [0.84674126 0.15325874]\n",
      " [0.3783007  0.6216993 ]\n",
      " [0.13553785 0.8644622 ]\n",
      " [0.00490193 0.99509805]\n",
      " [0.9991447  0.00085537]\n",
      " [0.85905963 0.14094038]\n",
      " [0.852393   0.14760701]\n",
      " [0.5019145  0.4980855 ]\n",
      " [0.8744733  0.12552674]\n",
      " [0.04809584 0.9519042 ]\n",
      " [0.9999651  0.00003489]\n",
      " [0.8473759  0.15262407]\n",
      " [0.998801   0.00119901]\n",
      " [0.9919836  0.00801643]\n",
      " [0.30919847 0.6908015 ]\n",
      " [0.00044046 0.9995596 ]\n",
      " [0.9783967  0.0216033 ]\n",
      " [0.7560998  0.24390018]\n",
      " [0.19974843 0.80025154]\n",
      " [0.37076434 0.6292357 ]\n",
      " [0.7668285  0.23317152]\n",
      " [0.03536874 0.96463126]\n",
      " [0.99902475 0.0009753 ]\n",
      " [0.9736795  0.02632049]\n",
      " [0.18023893 0.81976104]\n",
      " [0.8732359  0.12676406]\n",
      " [0.902318   0.09768194]\n",
      " [0.9820387  0.01796133]\n",
      " [0.28396595 0.71603405]\n",
      " [0.89753747 0.10246246]\n",
      " [0.12151034 0.8784897 ]\n",
      " [0.0540059  0.9459941 ]\n",
      " [0.02115704 0.978843  ]\n",
      " [0.9975285  0.00247148]\n",
      " [0.9426021  0.05739793]\n",
      " [0.45347524 0.5465247 ]\n",
      " [0.38803935 0.6119606 ]\n",
      " [0.7889831  0.2110169 ]\n",
      " [0.95343876 0.04656117]\n",
      " [0.99041545 0.00958457]\n",
      " [0.37388206 0.62611794]\n",
      " [0.28390256 0.7160975 ]\n",
      " [0.9994368  0.00056322]\n",
      " [0.82547337 0.1745266 ]\n",
      " [0.9997675  0.0002325 ]\n",
      " [0.4024919  0.59750813]\n",
      " [0.318409   0.68159103]\n",
      " [0.6398589  0.36014107]\n",
      " [0.25435174 0.7456482 ]\n",
      " [0.991264   0.00873601]\n",
      " [0.35782364 0.64217633]\n",
      " [0.9778187  0.02218127]\n",
      " [0.8556173  0.14438269]\n",
      " [0.02332333 0.9766766 ]\n",
      " [0.10879142 0.8912086 ]\n",
      " [0.9967506  0.00324946]\n",
      " [0.9937941  0.00620591]\n",
      " [0.8861328  0.11386718]\n",
      " [0.3736392  0.6263608 ]\n",
      " [0.01072426 0.9892757 ]\n",
      " [0.9856835  0.01431656]\n",
      " [0.55173033 0.44826967]\n",
      " [0.22868845 0.7713115 ]\n",
      " [0.3767735  0.6232265 ]\n",
      " [0.56946594 0.43053403]\n",
      " [0.84050936 0.15949067]\n",
      " [0.29218528 0.7078147 ]\n",
      " [0.856287   0.14371303]\n",
      " [0.8657814  0.13421863]\n",
      " [0.93689054 0.0631094 ]\n",
      " [0.56623846 0.43376148]\n",
      " [0.12129885 0.8787011 ]\n",
      " [0.99828404 0.00171594]]\n",
      "I0815 20:04:46.165417 140472255838080 basic_session_run_hooks.py:262] loss = 2.0514731, step = 0\n",
      "I0815 20:04:46.167326 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:04:49.139617 140472255838080 estimator.py:368] Loss for final step: 2.0514731.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d9513588>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "R4PGdSEQUUfN",
    "outputId": "12cee338-935f-42f8-de1a-e45039fc18d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:49.180313 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function relu at 0x7fc1f9253a60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:04:49.448416 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:04:49.452155 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:04:49.812741 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:04:49.819644 140472255838080 saver.py:1280] Restoring parameters from Estimator_relu//actfn_convnet_model/model.ckpt-1\n",
      "I0815 20:04:50.220223 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:04:50.229897 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:04:50.543980 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:04:55.821373 140472255838080 basic_session_run_hooks.py:262] loss = 180.84117, step = 1\n",
      "I0815 20:06:05.978117 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42537\n",
      "I0815 20:06:05.981081 140472255838080 basic_session_run_hooks.py:260] loss = 0.13218378, step = 101 (70.160 sec)\n",
      "I0815 20:07:15.692560 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.43442\n",
      "I0815 20:07:15.695340 140472255838080 basic_session_run_hooks.py:260] loss = 0.682963, step = 201 (69.714 sec)\n",
      "I0815 20:08:25.296854 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.43669\n",
      "I0815 20:08:25.299584 140472255838080 basic_session_run_hooks.py:260] loss = 0.23888691, step = 301 (69.604 sec)\n",
      "I0815 20:09:34.976445 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.43514\n",
      "I0815 20:09:34.979635 140472255838080 basic_session_run_hooks.py:260] loss = 0.12683886, step = 401 (69.680 sec)\n",
      "I0815 20:10:44.982783 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42844\n",
      "I0815 20:10:44.985829 140472255838080 basic_session_run_hooks.py:260] loss = 0.0515176, step = 501 (70.006 sec)\n",
      "I0815 20:11:54.781322 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.43269\n",
      "I0815 20:11:54.783941 140472255838080 basic_session_run_hooks.py:260] loss = 0.010398556, step = 601 (69.798 sec)\n",
      "I0815 20:13:04.852994 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42711\n",
      "I0815 20:13:04.856710 140472255838080 basic_session_run_hooks.py:260] loss = 0.0028305603, step = 701 (70.073 sec)\n",
      "I0815 20:14:14.669769 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.43232\n",
      "I0815 20:14:14.672966 140472255838080 basic_session_run_hooks.py:260] loss = 0.0020476258, step = 801 (69.816 sec)\n",
      "I0815 20:14:55.211445 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 860 into Estimator_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:15:27.355874 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.37578\n",
      "I0815 20:15:27.358127 140472255838080 basic_session_run_hooks.py:260] loss = 0.0010884366, step = 901 (72.685 sec)\n",
      "I0815 20:16:37.022729 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into Estimator_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:16:40.444503 140472255838080 estimator.py:368] Loss for final step: 0.0012938146.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d9513588>"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fF25F1-8UUfO"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "vTF3QIbmUUfP",
    "outputId": "56705331-18fd-4d91-a91c-60bce19055c8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:16:40.474392 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 20:16:40.586391 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:16:40.607815 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T20:16:40Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function relu at 0x7fc1f9253a60>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:16:40.696057 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:16:40.701480 140472255838080 saver.py:1280] Restoring parameters from Estimator_relu//actfn_convnet_model/model.ckpt-1001\n",
      "I0815 20:16:40.928323 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:16:40.940791 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:17:29.701650 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-20:17:29\n",
      "I0815 20:17:29.702766 140472255838080 estimator.py:2039] Saving dict for global step 1001: accuracy = 0.94291985, global_step = 1001, loss = 0.22290945\n",
      "I0815 20:17:29.738748 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1001: Estimator_relu//actfn_convnet_model/model.ckpt-1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.94291985, 'loss': 0.22290945, 'global_step': 1001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=100,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "hjDW2YXwxr3i",
    "outputId": "902fec59-1e9c-4fd8-e4b7-cd2270f2662b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565899480.0\n",
      "Model execution end Time: 1565900250.0\n",
      "Model execution Time: 12.83 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tVCmYVpUUfQ"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kai6NWC3UUfR"
   },
   "source": [
    "<img src=\"Presentation/leaky_ReLU.png\" width=\"500\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLu-jDIRUUfS"
   },
   "source": [
    "`Prevents dying ReLU problem`- this variation of ReLU has a small positive slope in the negative area, so it does enable `backpropagation`, even for negative input values. \n",
    "Otherwise Like a ReLU![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVfwvHzCyC6w"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "xl5DOGyxUUfT",
    "outputId": "20c4cf57-7df8-442d-e41a-a2b6393bcb19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:58:54.963681 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 20:58:54.966074 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_leaky_relu//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0d3708da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function leaky_relu at 0x7fc1f85410d0>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.leaky_relu\n",
    "actfn_classifier=estimator_path('leaky_relu')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "is_SwishBeta = False\n",
    "is_First = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2k4zXepUUfW"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t9y5qddlUUfW",
    "outputId": "b066991a-f090-4b2e-b54f-d4acbb44677c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:58:56.013961 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function leaky_relu at 0x7fc1f85410d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:58:56.269741 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:58:56.272531 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:58:56.387693 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:58:57.982886 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:58:57.994767 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:58:58.253130 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 0 into Estimator_leaky_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:59:02.271442 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.9998574  0.00014252]\n",
      " [0.00908848 0.99091154]\n",
      " [0.96503353 0.03496648]\n",
      " [0.9750894  0.02491063]\n",
      " [0.97663146 0.02336859]\n",
      " [0.6811492  0.31885082]\n",
      " [0.9583988  0.04160122]\n",
      " [0.9465351  0.05346483]\n",
      " [0.9882188  0.01178123]\n",
      " [0.5333266  0.46667337]\n",
      " [0.48082745 0.5191726 ]\n",
      " [0.9464323  0.05356767]\n",
      " [0.93733007 0.06266995]\n",
      " [0.05546663 0.9445334 ]\n",
      " [0.8842451  0.11575489]\n",
      " [0.99999726 0.00000273]\n",
      " [0.9910657  0.00893426]\n",
      " [0.0005315  0.9994685 ]\n",
      " [0.90019804 0.09980198]\n",
      " [0.99998295 0.00001699]\n",
      " [0.9995466  0.00045339]\n",
      " [0.9939553  0.00604468]\n",
      " [0.99999964 0.0000003 ]\n",
      " [0.5260224  0.4739776 ]\n",
      " [0.9969875  0.00301247]\n",
      " [0.997821   0.00217906]\n",
      " [0.997491   0.00250904]\n",
      " [0.82308966 0.17691033]\n",
      " [0.99699116 0.00300888]\n",
      " [0.47397345 0.5260266 ]\n",
      " [0.7671106  0.23288943]\n",
      " [0.9999968  0.00000319]\n",
      " [0.9999968  0.00000317]\n",
      " [0.98622406 0.01377595]\n",
      " [0.84671825 0.15328175]\n",
      " [0.9907588  0.00924123]\n",
      " [0.9877878  0.01221224]\n",
      " [0.9958157  0.00418431]\n",
      " [0.9434954  0.05650462]\n",
      " [0.9901832  0.0098168 ]\n",
      " [0.99513394 0.0048661 ]\n",
      " [0.9754254  0.02457453]\n",
      " [0.93719995 0.06279998]\n",
      " [0.9999993  0.00000071]\n",
      " [0.9972276  0.00277232]\n",
      " [0.77233636 0.22766365]\n",
      " [0.07234326 0.92765677]\n",
      " [0.99975115 0.00024883]\n",
      " [0.987437   0.01256299]\n",
      " [0.5001794  0.4998206 ]\n",
      " [0.8085906  0.19140942]\n",
      " [0.9892457  0.0107543 ]\n",
      " [0.9897943  0.01020564]\n",
      " [0.98176676 0.01823327]\n",
      " [0.99958867 0.00041134]\n",
      " [0.9583641  0.04163587]\n",
      " [0.9999896  0.00001035]\n",
      " [0.99597365 0.00402638]\n",
      " [0.96524864 0.03475133]\n",
      " [0.99999213 0.00000784]\n",
      " [0.00207269 0.9979273 ]\n",
      " [0.5765571  0.4234429 ]\n",
      " [0.5321331  0.4678669 ]\n",
      " [0.99167365 0.00832641]\n",
      " [0.93673277 0.06326725]\n",
      " [0.9999949  0.00000512]\n",
      " [0.3228603  0.67713964]\n",
      " [0.01279438 0.9872056 ]\n",
      " [0.99846953 0.00153047]\n",
      " [0.98476875 0.01523128]\n",
      " [0.9984597  0.00154026]\n",
      " [0.9981358  0.00186419]\n",
      " [0.9575878  0.04241223]\n",
      " [0.93482965 0.06517033]\n",
      " [0.9924672  0.00753273]\n",
      " [0.9999964  0.00000363]\n",
      " [0.95033395 0.04966602]\n",
      " [0.999895   0.00010507]\n",
      " [0.96937066 0.03062937]\n",
      " [0.42690435 0.5730957 ]\n",
      " [0.9983261  0.00167385]\n",
      " [0.9347724  0.06522767]\n",
      " [0.40166223 0.59833777]\n",
      " [0.1241905  0.87580955]\n",
      " [0.44041544 0.55958456]\n",
      " [0.99918514 0.00081485]\n",
      " [0.99978465 0.00021542]\n",
      " [0.9925845  0.00741549]\n",
      " [0.5031488  0.49685127]\n",
      " [0.7906355  0.20936453]\n",
      " [0.9940994  0.00590062]\n",
      " [0.9999987  0.0000013 ]\n",
      " [0.9999981  0.0000019 ]\n",
      " [0.9970931  0.00290696]\n",
      " [0.991655   0.00834496]\n",
      " [0.5406366  0.45936343]\n",
      " [0.99999833 0.00000169]\n",
      " [0.99999595 0.00000402]\n",
      " [0.9999653  0.00003472]\n",
      " [0.01436146 0.98563856]\n",
      " [0.99883753 0.00116252]\n",
      " [0.9973417  0.00265835]\n",
      " [0.9968425  0.00315756]\n",
      " [0.9820827  0.01791731]\n",
      " [0.9784802  0.02151973]\n",
      " [0.94637614 0.05362388]\n",
      " [0.8027211  0.19727887]\n",
      " [0.5372405  0.46275944]\n",
      " [0.9789964  0.0210036 ]\n",
      " [0.90529984 0.0947001 ]\n",
      " [0.46223217 0.5377678 ]\n",
      " [0.5943432  0.4056568 ]\n",
      " [0.9986083  0.00139179]\n",
      " [0.9999889  0.00001109]\n",
      " [0.7681763  0.23182373]\n",
      " [0.98096645 0.01903353]\n",
      " [0.9284576  0.0715424 ]\n",
      " [0.9839295  0.01607047]\n",
      " [0.9997546  0.00024542]\n",
      " [0.9344421  0.06555793]\n",
      " [0.9823298  0.0176702 ]\n",
      " [0.0189936  0.9810064 ]\n",
      " [0.15193637 0.84806365]\n",
      " [0.91335654 0.08664346]\n",
      " [0.9995065  0.00049356]\n",
      " [0.7647515  0.23524854]\n",
      " [0.2987656  0.70123434]\n",
      " [0.9999219  0.00007807]\n",
      " [0.8525187  0.1474813 ]\n",
      " [0.99305785 0.0069421 ]\n",
      " [0.99309444 0.00690552]\n",
      " [0.9982412  0.0017588 ]\n",
      " [0.9912977  0.0087023 ]\n",
      " [0.91754776 0.08245221]\n",
      " [0.99606496 0.00393508]\n",
      " [0.9999691  0.00003082]\n",
      " [0.9990613  0.00093874]\n",
      " [0.9998455  0.00015442]\n",
      " [0.59544986 0.40455016]\n",
      " [0.8758912  0.12410884]\n",
      " [0.12053764 0.8794623 ]\n",
      " [0.9855783  0.01442172]\n",
      " [0.9974891  0.00251094]\n",
      " [0.99996316 0.0000368 ]\n",
      " [0.45095128 0.5490487 ]\n",
      " [0.994175   0.00582496]\n",
      " [0.9292305  0.07076953]\n",
      " [0.95327866 0.04672141]\n",
      " [0.00790478 0.9920953 ]\n",
      " [0.9078873  0.09211275]\n",
      " [0.80951864 0.19048133]\n",
      " [0.94251376 0.05748631]\n",
      " [0.9999776  0.00002236]\n",
      " [0.98188144 0.0181186 ]\n",
      " [0.9971698  0.00283022]\n",
      " [0.998607   0.00139303]\n",
      " [0.87172353 0.12827645]\n",
      " [0.3608686  0.6391314 ]\n",
      " [0.99076414 0.00923587]\n",
      " [0.00092346 0.9990765 ]\n",
      " [0.533101   0.466899  ]\n",
      " [0.9157879  0.08421215]\n",
      " [0.8490829  0.15091711]\n",
      " [0.99998164 0.00001835]\n",
      " [0.99943584 0.00056411]\n",
      " [0.9968754  0.00312463]\n",
      " [0.9059181  0.09408184]\n",
      " [0.9685481  0.03145182]\n",
      " [0.9979367  0.00206333]\n",
      " [0.9944296  0.00557047]\n",
      " [0.81990117 0.18009885]\n",
      " [0.9994691  0.00053097]\n",
      " [0.9970649  0.00293507]\n",
      " [0.85704464 0.14295536]\n",
      " [0.9637666  0.0362334 ]\n",
      " [0.38465497 0.615345  ]\n",
      " [0.99862325 0.00137674]\n",
      " [0.96003133 0.03996862]\n",
      " [0.14434204 0.85565794]\n",
      " [0.9875408  0.01245923]\n",
      " [0.3231333  0.6768667 ]\n",
      " [0.9932643  0.0067356 ]\n",
      " [0.9998411  0.00015886]\n",
      " [0.3579306  0.6420694 ]\n",
      " [0.99997556 0.00002438]\n",
      " [0.01544741 0.9845526 ]\n",
      " [0.86999273 0.13000731]\n",
      " [0.9793305  0.02066955]\n",
      " [0.8773115  0.12268848]\n",
      " [0.9127767  0.08722332]\n",
      " [0.999892   0.00010797]\n",
      " [0.9697062  0.03029379]\n",
      " [0.13079004 0.86920995]\n",
      " [0.997124   0.00287595]\n",
      " [0.9993569  0.00064309]\n",
      " [0.98758787 0.01241207]\n",
      " [0.9593309  0.04066911]\n",
      " [0.9948775  0.00512251]\n",
      " [0.7101753  0.28982472]\n",
      " [0.99950993 0.00049003]\n",
      " [0.99992156 0.00007841]\n",
      " [0.9989869  0.00101307]\n",
      " [0.94502807 0.05497194]\n",
      " [0.97965884 0.02034121]\n",
      " [0.9155839  0.08441614]\n",
      " [0.9476226  0.0523774 ]\n",
      " [0.4919145  0.5080855 ]\n",
      " [0.9646971  0.03530285]\n",
      " [0.9997886  0.00021149]\n",
      " [0.99999607 0.00000395]\n",
      " [0.9989311  0.00106892]\n",
      " [0.99998724 0.00001273]\n",
      " [0.99988437 0.00011564]\n",
      " [0.8049551  0.1950449 ]\n",
      " [0.7978878  0.20211218]\n",
      " [0.931578   0.06842209]\n",
      " [0.9987943  0.00120564]\n",
      " [0.9930314  0.00696861]\n",
      " [0.99998283 0.00001717]\n",
      " [0.0000401  0.99995995]\n",
      " [0.9986326  0.00136735]\n",
      " [0.9513428  0.04865719]\n",
      " [0.99408156 0.0059184 ]\n",
      " [0.992347   0.00765294]\n",
      " [1.         0.00000004]\n",
      " [0.99996006 0.00003993]\n",
      " [0.9998735  0.00012645]\n",
      " [0.9160021  0.08399789]\n",
      " [0.9816171  0.01838296]\n",
      " [0.9995679  0.00043203]\n",
      " [0.98763824 0.01236182]\n",
      " [0.92685944 0.07314056]\n",
      " [0.9777672  0.02223276]\n",
      " [0.99786454 0.00213544]\n",
      " [0.8975443  0.10245571]\n",
      " [0.0002399  0.9997601 ]\n",
      " [0.99997604 0.00002395]\n",
      " [0.00047679 0.9995233 ]\n",
      " [0.28974643 0.7102536 ]\n",
      " [0.7413938  0.2586062 ]\n",
      " [0.9999987  0.00000129]\n",
      " [0.9998011  0.00019889]\n",
      " [0.9998374  0.00016263]\n",
      " [0.9977774  0.00222256]\n",
      " [0.9769107  0.02308926]\n",
      " [0.99998283 0.00001714]\n",
      " [0.1122817  0.8877183 ]\n",
      " [0.99974245 0.00025752]\n",
      " [0.99716336 0.00283664]\n",
      " [0.9999211  0.00007888]\n",
      " [0.99999297 0.00000704]\n",
      " [0.9982822  0.00171778]\n",
      " [0.98632693 0.01367302]\n",
      " [0.98912525 0.01087479]\n",
      " [0.51197803 0.488022  ]\n",
      " [0.9887861  0.01121391]\n",
      " [0.9999994  0.00000056]\n",
      " [0.9384386  0.06156138]\n",
      " [0.9988938  0.00110623]\n",
      " [0.96203756 0.03796237]\n",
      " [0.652563   0.347437  ]\n",
      " [0.6905815  0.30941847]\n",
      " [0.9978575  0.00214247]\n",
      " [0.98071057 0.01928938]\n",
      " [0.9983797  0.00162028]\n",
      " [0.8608427  0.13915733]\n",
      " [0.9964336  0.00356642]\n",
      " [0.98680544 0.01319457]\n",
      " [0.9990263  0.00097371]\n",
      " [0.9879161  0.01208395]\n",
      " [0.549715   0.45028505]\n",
      " [0.01052523 0.9894748 ]\n",
      " [0.98498255 0.01501741]\n",
      " [0.38827163 0.61172837]\n",
      " [0.7858792  0.21412084]\n",
      " [0.7566683  0.24333167]\n",
      " [0.63624    0.36376   ]\n",
      " [0.9995121  0.00048791]\n",
      " [0.9446271  0.05537294]\n",
      " [0.9977028  0.00229729]\n",
      " [0.00271021 0.9972898 ]\n",
      " [0.9021588  0.09784117]\n",
      " [0.9585541  0.04144584]\n",
      " [0.98909634 0.01090365]\n",
      " [0.9999628  0.00003713]\n",
      " [0.7133392  0.28666082]\n",
      " [0.6607079  0.33929208]\n",
      " [0.99973804 0.00026199]\n",
      " [0.9987576  0.00124236]\n",
      " [0.99058414 0.0094159 ]\n",
      " [0.99773514 0.00226483]\n",
      " [0.9957241  0.00427586]\n",
      " [0.00635817 0.9936418 ]\n",
      " [0.99997973 0.00002029]\n",
      " [0.99720865 0.00279138]\n",
      " [0.9987741  0.00122591]\n",
      " [0.9739343  0.02606573]\n",
      " [0.00939589 0.9906041 ]\n",
      " [0.988836   0.01116403]\n",
      " [0.8814326  0.11856736]\n",
      " [0.9995659  0.00043411]\n",
      " [0.9867294  0.01327059]\n",
      " [0.6690719  0.33092806]\n",
      " [0.40503865 0.5949613 ]\n",
      " [0.979051   0.02094896]\n",
      " [0.9994479  0.0005521 ]\n",
      " [0.9958274  0.00417264]\n",
      " [0.85093784 0.1490622 ]\n",
      " [0.8603044  0.1396956 ]\n",
      " [0.9321063  0.06789368]\n",
      " [0.9455573  0.05444265]\n",
      " [0.9976572  0.00234282]\n",
      " [0.99983    0.00016991]\n",
      " [0.99996126 0.00003878]\n",
      " [0.3100713  0.6899287 ]\n",
      " [0.9766376  0.02336243]\n",
      " [0.9968045  0.00319551]\n",
      " [0.08578292 0.91421705]\n",
      " [0.9536239  0.04637605]\n",
      " [0.9502772  0.04972284]\n",
      " [0.92212325 0.07787668]\n",
      " [0.9999151  0.00008487]\n",
      " [0.9987532  0.00124682]\n",
      " [0.19840203 0.80159795]\n",
      " [0.9659561  0.03404396]\n",
      " [0.9782588  0.02174122]\n",
      " [0.01630258 0.9836975 ]\n",
      " [0.9954614  0.00453853]\n",
      " [0.9998405  0.00015943]\n",
      " [0.00539383 0.9946062 ]\n",
      " [0.9994337  0.00056633]\n",
      " [0.27024102 0.729759  ]\n",
      " [0.99985266 0.00014737]\n",
      " [0.9975013  0.00249873]\n",
      " [0.00000003 1.        ]\n",
      " [0.97813976 0.02186023]\n",
      " [0.99996746 0.00003259]\n",
      " [0.00776984 0.9922301 ]\n",
      " [0.3252417  0.6747583 ]\n",
      " [0.99817073 0.0018293 ]\n",
      " [0.99891937 0.00108061]\n",
      " [0.9999989  0.00000112]\n",
      " [0.99997795 0.0000221 ]\n",
      " [0.9996526  0.00034738]\n",
      " [0.92636186 0.07363816]\n",
      " [0.07913204 0.920868  ]\n",
      " [0.99908876 0.00091127]\n",
      " [0.96087086 0.03912914]\n",
      " [0.9983639  0.00163611]\n",
      " [0.99986124 0.00013879]\n",
      " [0.9994005  0.00059948]\n",
      " [0.7961287  0.20387131]\n",
      " [0.05779358 0.94220644]\n",
      " [0.99875736 0.00124264]\n",
      " [0.98826075 0.01173933]\n",
      " [0.8959664  0.10403363]\n",
      " [0.80136687 0.19863312]\n",
      " [0.95152336 0.04847659]\n",
      " [0.92585146 0.07414851]\n",
      " [0.97468567 0.0253143 ]\n",
      " [0.9950352  0.00496489]\n",
      " [0.99793065 0.00206938]\n",
      " [0.7313096  0.26869044]\n",
      " [0.59826106 0.4017389 ]\n",
      " [0.992855   0.00714504]\n",
      " [0.9999894  0.00001059]\n",
      " [0.9991841  0.00081586]\n",
      " [0.99987984 0.00012018]\n",
      " [0.9129349  0.08706513]\n",
      " [0.9999975  0.00000245]\n",
      " [0.43426564 0.5657343 ]\n",
      " [0.9330286  0.06697138]\n",
      " [0.9999653  0.00003472]\n",
      " [0.9554387  0.04456134]\n",
      " [0.9984308  0.00156918]\n",
      " [0.9929482  0.00705185]\n",
      " [0.8762667  0.12373325]\n",
      " [0.9999864  0.00001358]\n",
      " [0.964352   0.03564795]\n",
      " [0.9886397  0.01136023]\n",
      " [0.9998987  0.00010128]\n",
      " [0.9950917  0.00490827]\n",
      " [0.9999999  0.00000009]\n",
      " [0.01163309 0.9883669 ]\n",
      " [0.0153614  0.98463863]\n",
      " [0.98472244 0.01527758]\n",
      " [0.8739664  0.12603359]\n",
      " [0.9989255  0.00107444]\n",
      " [0.97009474 0.02990522]\n",
      " [0.9912608  0.00873916]\n",
      " [0.09363866 0.90636134]\n",
      " [0.9996592  0.00034082]\n",
      " [0.86648685 0.13351317]\n",
      " [0.9983581  0.00164189]\n",
      " [0.99990547 0.00009457]\n",
      " [0.99994993 0.00005008]\n",
      " [0.99552816 0.00447183]\n",
      " [0.01706653 0.98293346]\n",
      " [0.9993579  0.00064215]\n",
      " [0.9989754  0.00102468]\n",
      " [0.75768393 0.24231611]\n",
      " [0.8691158  0.13088417]\n",
      " [0.975606   0.02439395]\n",
      " [0.08378571 0.9162143 ]\n",
      " [0.97335106 0.02664893]\n",
      " [0.9991653  0.00083478]\n",
      " [0.8065071  0.19349286]\n",
      " [0.99988306 0.00011688]\n",
      " [0.9986015  0.00139846]\n",
      " [0.99917513 0.00082486]\n",
      " [0.9995283  0.00047167]\n",
      " [0.94659054 0.05340948]\n",
      " [0.99987423 0.00012572]\n",
      " [0.90636605 0.09363396]\n",
      " [0.9998945  0.0001055 ]\n",
      " [0.976829   0.02317102]\n",
      " [0.98133653 0.01866341]\n",
      " [0.324781   0.675219  ]\n",
      " [0.99997497 0.00002501]\n",
      " [0.00242022 0.99757975]\n",
      " [0.9851444  0.0148556 ]\n",
      " [0.99886703 0.00113301]\n",
      " [0.99518615 0.00481384]\n",
      " [0.9576242  0.04237584]\n",
      " [0.97399706 0.02600292]\n",
      " [0.46486565 0.5351344 ]\n",
      " [0.79171914 0.2082808 ]\n",
      " [0.98796964 0.01203036]\n",
      " [0.9990559  0.00094405]\n",
      " [0.9968172  0.00318284]\n",
      " [0.9903476  0.00965238]\n",
      " [0.9999937  0.00000629]\n",
      " [0.99014425 0.00985578]\n",
      " [0.9905821  0.00941784]\n",
      " [0.9947802  0.00521981]\n",
      " [0.97620547 0.02379453]\n",
      " [0.9930583  0.00694165]\n",
      " [0.994618   0.00538198]\n",
      " [0.99999726 0.00000279]\n",
      " [0.96622777 0.03377225]\n",
      " [0.9999696  0.00003038]\n",
      " [0.04156173 0.9584382 ]\n",
      " [0.998801   0.00119896]\n",
      " [0.96556735 0.0344326 ]\n",
      " [0.44218832 0.5578116 ]\n",
      " [0.99998486 0.00001509]\n",
      " [0.9230631  0.07693696]\n",
      " [0.9949562  0.0050438 ]\n",
      " [0.99892503 0.00107494]\n",
      " [0.98821276 0.01178721]\n",
      " [0.9974375  0.00256249]\n",
      " [0.9751285  0.02487151]\n",
      " [0.09001312 0.90998685]\n",
      " [0.9998915  0.00010843]\n",
      " [0.08879425 0.9112058 ]\n",
      " [0.46497142 0.5350286 ]\n",
      " [0.9957255  0.0042745 ]\n",
      " [0.99724066 0.00275936]\n",
      " [0.7911897  0.20881033]\n",
      " [0.95622355 0.04377639]\n",
      " [0.9451147  0.05488537]\n",
      " [0.37549835 0.62450165]\n",
      " [0.99998224 0.00001777]\n",
      " [0.9772922  0.02270786]\n",
      " [0.978878   0.02112195]\n",
      " [0.99997973 0.00002022]\n",
      " [0.9998772  0.0001228 ]\n",
      " [0.8545695  0.14543046]\n",
      " [0.9859772  0.01402278]\n",
      " [0.98847276 0.01152719]\n",
      " [0.99135923 0.00864076]\n",
      " [0.99923813 0.00076184]\n",
      " [0.9931252  0.00687473]\n",
      " [0.99986815 0.0001318 ]\n",
      " [0.99794704 0.00205294]\n",
      " [0.9994197  0.00058038]\n",
      " [0.9956944  0.00430554]\n",
      " [0.9652664  0.03473363]\n",
      " [0.4976145  0.5023855 ]\n",
      " [0.9966564  0.00334353]\n",
      " [0.99996555 0.00003449]\n",
      " [0.96285075 0.03714921]\n",
      " [0.99999964 0.0000003 ]\n",
      " [0.04755162 0.95244837]\n",
      " [0.999985   0.00001501]\n",
      " [0.0096222  0.9903778 ]\n",
      " [0.00819869 0.9918013 ]\n",
      " [0.3159969  0.6840032 ]\n",
      " [0.9848326  0.01516742]\n",
      " [0.9969867  0.00301333]\n",
      " [0.99996245 0.00003758]\n",
      " [0.09924551 0.9007545 ]\n",
      " [0.9367329  0.06326705]\n",
      " [0.4083546  0.59164536]\n",
      " [0.7365409  0.2634591 ]\n",
      " [0.97401446 0.02598559]\n",
      " [0.97617394 0.02382611]\n",
      " [0.5931959  0.40680408]\n",
      " [0.9991518  0.00084821]\n",
      " [0.9078748  0.09212518]]\n",
      "I0815 20:59:02.273494 140472255838080 basic_session_run_hooks.py:262] loss = 2.2799206, step = 0\n",
      "I0815 20:59:02.277202 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_leaky_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:59:05.373041 140472255838080 estimator.py:368] Loss for final step: 2.2799206.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc0d37086a0>"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "0SNsfZknUUfX",
    "outputId": "3377c37c-df13-4054-f165-065c636c7d3a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:59:05.417356 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function leaky_relu at 0x7fc1f85410d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:59:05.704169 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:59:05.707478 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:59:06.125417 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:59:06.134488 140472255838080 saver.py:1280] Restoring parameters from Estimator_leaky_relu//actfn_convnet_model/model.ckpt-1\n",
      "I0815 20:59:06.623960 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:59:06.633556 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:59:06.928501 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_leaky_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:59:10.910145 140472255838080 basic_session_run_hooks.py:262] loss = 428.59488, step = 1\n",
      "I0815 21:00:31.183509 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24573\n",
      "I0815 21:00:31.186510 140472255838080 basic_session_run_hooks.py:260] loss = 0.22784072, step = 101 (80.276 sec)\n",
      "I0815 21:01:50.943049 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.25377\n",
      "I0815 21:01:50.945177 140472255838080 basic_session_run_hooks.py:260] loss = 0.14341003, step = 201 (79.759 sec)\n",
      "I0815 21:03:10.952761 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24985\n",
      "I0815 21:03:10.956686 140472255838080 basic_session_run_hooks.py:260] loss = 0.07377256, step = 301 (80.011 sec)\n",
      "I0815 21:04:30.989077 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24943\n",
      "I0815 21:04:30.991893 140472255838080 basic_session_run_hooks.py:260] loss = 0.09939466, step = 401 (80.035 sec)\n",
      "I0815 21:05:51.041154 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24919\n",
      "I0815 21:05:51.044076 140472255838080 basic_session_run_hooks.py:260] loss = 0.07676975, step = 501 (80.052 sec)\n",
      "I0815 21:07:11.062001 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24967\n",
      "I0815 21:07:11.066283 140472255838080 basic_session_run_hooks.py:260] loss = 0.013311924, step = 601 (80.022 sec)\n",
      "I0815 21:08:31.025770 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.25057\n",
      "I0815 21:08:31.028684 140472255838080 basic_session_run_hooks.py:260] loss = 0.005774758, step = 701 (79.962 sec)\n",
      "I0815 21:09:10.789254 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 752 into Estimator_leaky_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 21:09:53.598542 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.21105\n",
      "I0815 21:09:53.601016 140472255838080 basic_session_run_hooks.py:260] loss = 0.0064223525, step = 801 (82.572 sec)\n",
      "I0815 21:11:13.601582 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.24995\n",
      "I0815 21:11:13.603935 140472255838080 basic_session_run_hooks.py:260] loss = 0.0022968377, step = 901 (80.003 sec)\n",
      "I0815 21:12:32.485725 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into Estimator_leaky_relu//actfn_convnet_model/model.ckpt.\n",
      "I0815 21:12:35.346903 140472255838080 estimator.py:368] Loss for final step: 0.0015164035.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc0d37086a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnbbi_uDUUfZ"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "eggyNRzqUUfZ",
    "outputId": "633336a5-ef08-4dcb-cc69-98b6e0c8d052"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 21:12:35.380955 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 21:12:35.502951 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 21:12:35.530355 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T21:12:35Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function leaky_relu at 0x7fc1f85410d0>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 21:12:35.628586 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 21:12:35.634493 140472255838080 saver.py:1280] Restoring parameters from Estimator_leaky_relu//actfn_convnet_model/model.ckpt-1001\n",
      "I0815 21:12:35.926163 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 21:12:35.937235 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 21:13:34.618780 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-21:13:34\n",
      "I0815 21:13:34.619926 140472255838080 estimator.py:2039] Saving dict for global step 1001: accuracy = 0.96597147, global_step = 1001, loss = 0.18424875\n",
      "I0815 21:13:34.659703 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1001: Estimator_leaky_relu//actfn_convnet_model/model.ckpt-1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.96597147, 'loss': 0.18424875, 'global_step': 1001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8d2yrtRIxzdU",
    "outputId": "42a59bf2-5194-49a3-9bc7-80a5e7a96d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565902734.0\n",
      "Model execution end Time: 1565903615.0\n",
      "Model execution Time: 14.67 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hM38irP-UUfa"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> Swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_jP5syeUUfb"
   },
   "source": [
    "<img src=\"Presentation/swish.png\" width=\"500\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQV9cdI3UUfb"
   },
   "source": [
    "`Swish` is a new, self-gated activation function discovered by researchers at Google.<br />\n",
    "Swish mathematical expression: `f(x) = x * σ(x)` <br />\n",
    "where `σ(x)= sigmoid function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zBQdk6byEge"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rb2SlC3IUUfc"
   },
   "source": [
    "#### Set a activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "A8CSPzQ3UUfc",
    "outputId": "72a2bc57-d783-414c-f8d3-f0dc0ce5ccce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:26:35.365203 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 20:26:35.367195 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_swish//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1d96ebd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function sigmoid at 0x7fc1f9181620>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.sigmoid\n",
    "actfn_classifier=estimator_path('swish')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = True\n",
    "is_SwishBeta = False\n",
    "is_First = False\n",
    "\n",
    "def swish_1(x):\n",
    "    act_func_global = x*tf.nn.sigmoid(x)\n",
    "    return act_func_global\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiryPMkZUUff"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8ySq23SOUUff",
    "outputId": "a5e02daf-4e76-475b-f548-d59d655d7867"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:26:35.404439 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:26:35.673922 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:26:35.676960 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:26:35.835513 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:26:37.429821 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:26:37.437773 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:26:37.714705 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 0 into Estimator_swish//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:26:41.690376 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.4952211  0.5047789 ]\n",
      " [0.4896268  0.5103732 ]\n",
      " [0.4873885  0.51261157]\n",
      " [0.4898176  0.51018244]\n",
      " [0.4923146  0.5076854 ]\n",
      " [0.48709807 0.5129019 ]\n",
      " [0.49185365 0.50814635]\n",
      " [0.49295315 0.5070468 ]\n",
      " [0.49189568 0.5081043 ]\n",
      " [0.5012437  0.4987563 ]\n",
      " [0.49609822 0.5039018 ]\n",
      " [0.48388505 0.51611495]\n",
      " [0.48335508 0.5166449 ]\n",
      " [0.48716757 0.51283246]\n",
      " [0.48455027 0.5154497 ]\n",
      " [0.49126682 0.5087332 ]\n",
      " [0.48726994 0.51273006]\n",
      " [0.4837753  0.5162247 ]\n",
      " [0.49191734 0.5080826 ]\n",
      " [0.48759302 0.512407  ]\n",
      " [0.48761556 0.5123845 ]\n",
      " [0.48898968 0.51101035]\n",
      " [0.48705482 0.5129452 ]\n",
      " [0.4942053  0.5057947 ]\n",
      " [0.48603037 0.51396966]\n",
      " [0.4928816  0.50711834]\n",
      " [0.4915897  0.50841033]\n",
      " [0.49047723 0.5095228 ]\n",
      " [0.47985756 0.5201424 ]\n",
      " [0.49810252 0.50189745]\n",
      " [0.4939099  0.5060901 ]\n",
      " [0.4859473  0.5140527 ]\n",
      " [0.4897908  0.5102092 ]\n",
      " [0.49379194 0.50620806]\n",
      " [0.4910229  0.50897706]\n",
      " [0.49768817 0.5023118 ]\n",
      " [0.4872508  0.5127492 ]\n",
      " [0.48817697 0.511823  ]\n",
      " [0.48504037 0.51495963]\n",
      " [0.48198166 0.51801836]\n",
      " [0.49538186 0.50461817]\n",
      " [0.4932586  0.5067414 ]\n",
      " [0.49414676 0.5058532 ]\n",
      " [0.484498   0.51550204]\n",
      " [0.49228266 0.5077174 ]\n",
      " [0.4985828  0.5014172 ]\n",
      " [0.48575434 0.5142457 ]\n",
      " [0.4929861  0.50701386]\n",
      " [0.49229127 0.5077087 ]\n",
      " [0.47682455 0.5231754 ]\n",
      " [0.48938033 0.51061964]\n",
      " [0.4773751  0.5226249 ]\n",
      " [0.48733905 0.5126609 ]\n",
      " [0.48764628 0.51235366]\n",
      " [0.48911446 0.5108855 ]\n",
      " [0.48772797 0.512272  ]\n",
      " [0.48295417 0.51704586]\n",
      " [0.48436505 0.51563495]\n",
      " [0.49092665 0.5090734 ]\n",
      " [0.48636106 0.513639  ]\n",
      " [0.4885987  0.51140136]\n",
      " [0.4938332  0.5061668 ]\n",
      " [0.49234504 0.50765496]\n",
      " [0.485367   0.51463306]\n",
      " [0.48058262 0.51941735]\n",
      " [0.48242614 0.51757383]\n",
      " [0.5061112  0.4938888 ]\n",
      " [0.4906813  0.50931865]\n",
      " [0.49007455 0.5099254 ]\n",
      " [0.48341298 0.516587  ]\n",
      " [0.4928705  0.5071295 ]\n",
      " [0.49226704 0.507733  ]\n",
      " [0.49085858 0.50914145]\n",
      " [0.48450503 0.515495  ]\n",
      " [0.49432832 0.5056717 ]\n",
      " [0.4923105  0.5076895 ]\n",
      " [0.4931306  0.5068694 ]\n",
      " [0.4834839  0.5165161 ]\n",
      " [0.48993352 0.51006645]\n",
      " [0.49963382 0.50036615]\n",
      " [0.5030252  0.49697483]\n",
      " [0.49635383 0.50364614]\n",
      " [0.485299   0.514701  ]\n",
      " [0.49694118 0.50305885]\n",
      " [0.4911599  0.50884014]\n",
      " [0.4964402  0.5035598 ]\n",
      " [0.49642    0.50358   ]\n",
      " [0.48849276 0.5115073 ]\n",
      " [0.49149743 0.5085026 ]\n",
      " [0.49166492 0.50833505]\n",
      " [0.47870523 0.5212948 ]\n",
      " [0.4891477  0.5108523 ]\n",
      " [0.49171513 0.50828487]\n",
      " [0.49392584 0.5060742 ]\n",
      " [0.49631488 0.5036851 ]\n",
      " [0.48789102 0.512109  ]\n",
      " [0.48515734 0.5148426 ]\n",
      " [0.4819201  0.51807994]\n",
      " [0.49132827 0.5086717 ]\n",
      " [0.4936904  0.5063096 ]\n",
      " [0.4898096  0.51019037]\n",
      " [0.49253923 0.5074608 ]\n",
      " [0.485012   0.514988  ]\n",
      " [0.49271894 0.50728106]\n",
      " [0.4878251  0.5121749 ]\n",
      " [0.4964601  0.5035399 ]\n",
      " [0.48476577 0.51523423]\n",
      " [0.48507518 0.5149248 ]\n",
      " [0.4874646  0.51253545]\n",
      " [0.48611876 0.5138812 ]\n",
      " [0.47924975 0.5207502 ]\n",
      " [0.49258545 0.5074146 ]\n",
      " [0.4868163  0.5131837 ]\n",
      " [0.49090755 0.50909245]\n",
      " [0.48766312 0.5123369 ]\n",
      " [0.48832315 0.51167685]\n",
      " [0.4910592  0.5089408 ]\n",
      " [0.48294848 0.5170515 ]\n",
      " [0.49907815 0.50092185]\n",
      " [0.4981832  0.50181675]\n",
      " [0.5035577  0.49644238]\n",
      " [0.49462512 0.5053749 ]\n",
      " [0.48691717 0.51308286]\n",
      " [0.48662403 0.513376  ]\n",
      " [0.49376255 0.50623745]\n",
      " [0.48739815 0.5126019 ]\n",
      " [0.49573275 0.5042673 ]\n",
      " [0.48927018 0.5107298 ]\n",
      " [0.48863223 0.5113678 ]\n",
      " [0.4941861  0.5058139 ]\n",
      " [0.48207265 0.51792735]\n",
      " [0.4994047  0.5005953 ]\n",
      " [0.48870006 0.5112999 ]\n",
      " [0.49380416 0.5061958 ]\n",
      " [0.48970518 0.5102948 ]\n",
      " [0.49855414 0.5014459 ]\n",
      " [0.49254423 0.50745577]\n",
      " [0.49727383 0.5027262 ]\n",
      " [0.48997986 0.51002014]\n",
      " [0.49200168 0.5079983 ]\n",
      " [0.49605557 0.5039444 ]\n",
      " [0.48664448 0.5133555 ]\n",
      " [0.4864565  0.5135435 ]\n",
      " [0.4892775  0.5107225 ]\n",
      " [0.4918743  0.50812566]\n",
      " [0.4967261  0.5032739 ]\n",
      " [0.4775323  0.5224677 ]\n",
      " [0.4792246  0.5207754 ]\n",
      " [0.4984983  0.5015017 ]\n",
      " [0.48505944 0.5149406 ]\n",
      " [0.48067915 0.51932085]\n",
      " [0.49165764 0.5083423 ]\n",
      " [0.48281807 0.51718193]\n",
      " [0.49622098 0.50377905]\n",
      " [0.49499148 0.5050085 ]\n",
      " [0.4860636  0.5139364 ]\n",
      " [0.48535556 0.51464444]\n",
      " [0.49805605 0.50194395]\n",
      " [0.49639136 0.50360864]\n",
      " [0.49417722 0.5058228 ]\n",
      " [0.49362636 0.50637364]\n",
      " [0.49348208 0.5065179 ]\n",
      " [0.49426627 0.5057337 ]\n",
      " [0.48725352 0.51274645]\n",
      " [0.49644914 0.5035509 ]\n",
      " [0.48836893 0.5116311 ]\n",
      " [0.49395612 0.50604385]\n",
      " [0.48649028 0.51350975]\n",
      " [0.4911945  0.5088056 ]\n",
      " [0.486466   0.513534  ]\n",
      " [0.49818152 0.5018185 ]\n",
      " [0.48178375 0.51821625]\n",
      " [0.47678986 0.5232101 ]\n",
      " [0.4783767  0.5216234 ]\n",
      " [0.48556224 0.5144378 ]\n",
      " [0.48199797 0.51800203]\n",
      " [0.4951983  0.5048017 ]\n",
      " [0.48468313 0.51531684]\n",
      " [0.4873573  0.51264274]\n",
      " [0.48974073 0.5102593 ]\n",
      " [0.48815048 0.5118495 ]\n",
      " [0.48554614 0.5144539 ]\n",
      " [0.49077103 0.50922894]\n",
      " [0.49508426 0.5049157 ]\n",
      " [0.4848199  0.51518005]\n",
      " [0.4831538  0.5168462 ]\n",
      " [0.49634898 0.503651  ]\n",
      " [0.4945388  0.50546116]\n",
      " [0.48964033 0.51035964]\n",
      " [0.4958455  0.50415444]\n",
      " [0.49011204 0.50988793]\n",
      " [0.48474422 0.51525575]\n",
      " [0.4926644  0.50733566]\n",
      " [0.48811173 0.51188827]\n",
      " [0.48620602 0.513794  ]\n",
      " [0.49113885 0.5088611 ]\n",
      " [0.49332786 0.50667214]\n",
      " [0.49200085 0.5079991 ]\n",
      " [0.48874652 0.5112535 ]\n",
      " [0.4879726  0.5120274 ]\n",
      " [0.4855295  0.5144705 ]\n",
      " [0.49649134 0.5035086 ]\n",
      " [0.4902341  0.5097659 ]\n",
      " [0.49769002 0.50231   ]\n",
      " [0.48121753 0.51878244]\n",
      " [0.49110138 0.5088987 ]\n",
      " [0.48639968 0.51360035]\n",
      " [0.49040028 0.5095997 ]\n",
      " [0.49533534 0.5046646 ]\n",
      " [0.49715403 0.50284594]\n",
      " [0.49316403 0.506836  ]\n",
      " [0.49229974 0.5077002 ]\n",
      " [0.48829392 0.51170605]\n",
      " [0.48768502 0.512315  ]\n",
      " [0.4877198  0.5122802 ]\n",
      " [0.4929668  0.50703317]\n",
      " [0.48229867 0.5177013 ]\n",
      " [0.4917325  0.5082675 ]\n",
      " [0.48346823 0.51653177]\n",
      " [0.48215777 0.51784223]\n",
      " [0.49085885 0.50914115]\n",
      " [0.48091784 0.5190821 ]\n",
      " [0.49579218 0.50420785]\n",
      " [0.48532072 0.51467925]\n",
      " [0.4982185  0.50178146]\n",
      " [0.49151987 0.50848013]\n",
      " [0.49139905 0.50860095]\n",
      " [0.49491352 0.5050865 ]\n",
      " [0.49846077 0.50153923]\n",
      " [0.494086   0.505914  ]\n",
      " [0.49401686 0.5059831 ]\n",
      " [0.47123697 0.52876306]\n",
      " [0.4966137  0.5033863 ]\n",
      " [0.4893917  0.5106083 ]\n",
      " [0.48799646 0.51200354]\n",
      " [0.4988144  0.5011856 ]\n",
      " [0.49199948 0.5080005 ]\n",
      " [0.48978835 0.51021165]\n",
      " [0.49249437 0.5075056 ]\n",
      " [0.4781848  0.5218152 ]\n",
      " [0.49621147 0.50378853]\n",
      " [0.49298316 0.50701684]\n",
      " [0.47523758 0.52476245]\n",
      " [0.48754013 0.5124599 ]\n",
      " [0.49385265 0.5061474 ]\n",
      " [0.49055645 0.5094435 ]\n",
      " [0.48775908 0.51224095]\n",
      " [0.48388693 0.51611304]\n",
      " [0.49355817 0.5064419 ]\n",
      " [0.4954741  0.5045259 ]\n",
      " [0.49257836 0.5074216 ]\n",
      " [0.48105758 0.5189424 ]\n",
      " [0.48356253 0.5164374 ]\n",
      " [0.48991522 0.51008475]\n",
      " [0.483234   0.516766  ]\n",
      " [0.48658827 0.5134117 ]\n",
      " [0.49080977 0.5091902 ]\n",
      " [0.48478502 0.515215  ]\n",
      " [0.49350184 0.50649816]\n",
      " [0.49148226 0.5085178 ]\n",
      " [0.48413432 0.51586574]\n",
      " [0.49560633 0.5043937 ]\n",
      " [0.4989228  0.50107723]\n",
      " [0.49548522 0.50451475]\n",
      " [0.48324266 0.51675737]\n",
      " [0.49568874 0.50431126]\n",
      " [0.48653254 0.51346743]\n",
      " [0.4941471  0.50585294]\n",
      " [0.48834243 0.51165754]\n",
      " [0.4892501  0.5107499 ]\n",
      " [0.49603844 0.50396156]\n",
      " [0.49917063 0.5008294 ]\n",
      " [0.49512213 0.50487787]\n",
      " [0.49571645 0.50428355]\n",
      " [0.4832887  0.51671135]\n",
      " [0.49492848 0.5050715 ]\n",
      " [0.49290448 0.5070955 ]\n",
      " [0.48401007 0.5159899 ]\n",
      " [0.4909715  0.50902855]\n",
      " [0.49212968 0.5078703 ]\n",
      " [0.48068905 0.51931095]\n",
      " [0.48832363 0.5116764 ]\n",
      " [0.48500553 0.5149945 ]\n",
      " [0.4848068  0.5151932 ]\n",
      " [0.47967455 0.5203255 ]\n",
      " [0.48178548 0.5182145 ]\n",
      " [0.48810408 0.5118959 ]\n",
      " [0.4794112  0.52058876]\n",
      " [0.48749995 0.51250005]\n",
      " [0.49505588 0.50494415]\n",
      " [0.49900144 0.5009985 ]\n",
      " [0.49398458 0.5060154 ]\n",
      " [0.48950103 0.510499  ]\n",
      " [0.49854016 0.50145984]\n",
      " [0.4883806  0.5116194 ]\n",
      " [0.4945379  0.5054621 ]\n",
      " [0.47935688 0.5206431 ]\n",
      " [0.48809275 0.5119073 ]\n",
      " [0.49366006 0.5063399 ]\n",
      " [0.4860399  0.5139601 ]\n",
      " [0.48274487 0.5172551 ]\n",
      " [0.48456907 0.5154309 ]\n",
      " [0.48811635 0.5118837 ]\n",
      " [0.48649725 0.5135027 ]\n",
      " [0.4762672  0.52373284]\n",
      " [0.48695627 0.5130437 ]\n",
      " [0.4923083  0.50769174]\n",
      " [0.48426053 0.51573944]\n",
      " [0.48922348 0.5107766 ]\n",
      " [0.4958772  0.5041228 ]\n",
      " [0.4874391  0.5125609 ]\n",
      " [0.48437664 0.5156234 ]\n",
      " [0.49886727 0.5011327 ]\n",
      " [0.495324   0.50467604]\n",
      " [0.4888768  0.51112324]\n",
      " [0.48351547 0.5164845 ]\n",
      " [0.49371326 0.5062868 ]\n",
      " [0.4885162  0.5114838 ]\n",
      " [0.49214217 0.50785786]\n",
      " [0.4895982  0.5104018 ]\n",
      " [0.48244822 0.5175518 ]\n",
      " [0.4916786  0.5083214 ]\n",
      " [0.49406216 0.5059379 ]\n",
      " [0.48576766 0.5142324 ]\n",
      " [0.4988046  0.5011954 ]\n",
      " [0.49784166 0.50215834]\n",
      " [0.4863988  0.5136012 ]\n",
      " [0.4869514  0.5130486 ]\n",
      " [0.49563187 0.5043681 ]\n",
      " [0.48839116 0.51160884]\n",
      " [0.4924382  0.5075618 ]\n",
      " [0.48913974 0.51086026]\n",
      " [0.48833245 0.51166755]\n",
      " [0.49132273 0.50867724]\n",
      " [0.50365376 0.49634627]\n",
      " [0.5002172  0.4997828 ]\n",
      " [0.4861084  0.51389164]\n",
      " [0.48811764 0.5118824 ]\n",
      " [0.49054858 0.50945145]\n",
      " [0.49064687 0.5093531 ]\n",
      " [0.4855753  0.5144247 ]\n",
      " [0.49011827 0.50988173]\n",
      " [0.4913277  0.5086723 ]\n",
      " [0.4789722  0.5210278 ]\n",
      " [0.49191672 0.50808334]\n",
      " [0.49421036 0.50578964]\n",
      " [0.48795894 0.5120411 ]\n",
      " [0.4867659  0.5132341 ]\n",
      " [0.480743   0.51925707]\n",
      " [0.48871946 0.51128054]\n",
      " [0.48646733 0.51353264]\n",
      " [0.49051976 0.50948024]\n",
      " [0.48732564 0.5126744 ]\n",
      " [0.49216124 0.5078387 ]\n",
      " [0.49296433 0.5070357 ]\n",
      " [0.49170077 0.50829923]\n",
      " [0.48984814 0.5101518 ]\n",
      " [0.48967937 0.51032066]\n",
      " [0.48967043 0.51032954]\n",
      " [0.49392456 0.50607544]\n",
      " [0.49336204 0.506638  ]\n",
      " [0.48567283 0.51432717]\n",
      " [0.4843419  0.5156581 ]\n",
      " [0.48994213 0.51005787]\n",
      " [0.5041617  0.49583828]\n",
      " [0.4969187  0.5030813 ]\n",
      " [0.4948694  0.5051306 ]\n",
      " [0.48686272 0.5131373 ]\n",
      " [0.47986376 0.52013624]\n",
      " [0.49120954 0.5087905 ]\n",
      " [0.49580488 0.50419515]\n",
      " [0.48846123 0.51153874]\n",
      " [0.4881613  0.51183873]\n",
      " [0.5003258  0.49967426]\n",
      " [0.49480933 0.5051907 ]\n",
      " [0.4853185  0.51468146]\n",
      " [0.48923612 0.5107639 ]\n",
      " [0.49867636 0.50132364]\n",
      " [0.49030796 0.509692  ]\n",
      " [0.48720515 0.51279485]\n",
      " [0.49161127 0.5083887 ]\n",
      " [0.4943048  0.5056952 ]\n",
      " [0.4794813  0.52051866]\n",
      " [0.4806374  0.5193626 ]\n",
      " [0.48587808 0.51412195]\n",
      " [0.48427323 0.5157268 ]\n",
      " [0.48843133 0.51156867]\n",
      " [0.50246316 0.4975369 ]\n",
      " [0.48480195 0.51519805]\n",
      " [0.4848493  0.5151507 ]\n",
      " [0.480238   0.51976204]\n",
      " [0.49621305 0.503787  ]\n",
      " [0.485958   0.51404196]\n",
      " [0.48435774 0.5156422 ]\n",
      " [0.48173696 0.51826304]\n",
      " [0.49171796 0.50828207]\n",
      " [0.495506   0.5044941 ]\n",
      " [0.48858523 0.5114147 ]\n",
      " [0.4897737  0.5102263 ]\n",
      " [0.48476458 0.5152354 ]\n",
      " [0.49528265 0.50471735]\n",
      " [0.4911357  0.50886434]\n",
      " [0.4832246  0.51677537]\n",
      " [0.48667258 0.5133274 ]\n",
      " [0.489089   0.5109109 ]\n",
      " [0.4937458  0.5062542 ]\n",
      " [0.479043   0.520957  ]\n",
      " [0.49842247 0.50157756]\n",
      " [0.485247   0.514753  ]\n",
      " [0.48979107 0.51020896]\n",
      " [0.4888233  0.5111767 ]\n",
      " [0.49364716 0.50635284]\n",
      " [0.49824402 0.50175595]\n",
      " [0.48510313 0.51489687]\n",
      " [0.48186898 0.5181311 ]\n",
      " [0.4898119  0.5101881 ]\n",
      " [0.4973666  0.5026334 ]\n",
      " [0.4884321  0.5115679 ]\n",
      " [0.48523715 0.5147628 ]\n",
      " [0.49861857 0.50138146]\n",
      " [0.48643818 0.5135618 ]\n",
      " [0.48910347 0.5108965 ]\n",
      " [0.48471108 0.51528895]\n",
      " [0.49033087 0.5096691 ]\n",
      " [0.49510992 0.50489014]\n",
      " [0.4858792  0.5141208 ]\n",
      " [0.49329352 0.5067065 ]\n",
      " [0.50265193 0.49734807]\n",
      " [0.48637757 0.51362246]\n",
      " [0.48131898 0.51868105]\n",
      " [0.4993118  0.5006882 ]\n",
      " [0.489552   0.51044804]\n",
      " [0.48317504 0.51682496]\n",
      " [0.4827457  0.5172543 ]\n",
      " [0.49095342 0.50904655]\n",
      " [0.48478445 0.5152156 ]\n",
      " [0.49639696 0.50360304]\n",
      " [0.48295692 0.51704305]\n",
      " [0.49250174 0.50749826]\n",
      " [0.4867726  0.51322734]\n",
      " [0.49258646 0.50741357]\n",
      " [0.48941377 0.5105862 ]\n",
      " [0.5006904  0.49930963]\n",
      " [0.49257064 0.50742936]\n",
      " [0.48735663 0.5126434 ]\n",
      " [0.4920157  0.5079843 ]\n",
      " [0.4885705  0.5114295 ]\n",
      " [0.49466956 0.50533044]\n",
      " [0.48355472 0.5164453 ]\n",
      " [0.48304054 0.5169594 ]\n",
      " [0.4856381  0.5143619 ]\n",
      " [0.48829576 0.5117042 ]\n",
      " [0.49792796 0.502072  ]\n",
      " [0.48808149 0.5119185 ]\n",
      " [0.49781552 0.50218445]\n",
      " [0.48610687 0.5138931 ]\n",
      " [0.48800254 0.51199746]\n",
      " [0.48734155 0.5126584 ]\n",
      " [0.5056736  0.49432638]\n",
      " [0.4881479  0.511852  ]\n",
      " [0.49298558 0.5070144 ]\n",
      " [0.48963255 0.5103674 ]\n",
      " [0.48866034 0.51133966]\n",
      " [0.49460128 0.50539875]\n",
      " [0.48761508 0.5123849 ]\n",
      " [0.49313262 0.5068674 ]\n",
      " [0.48525095 0.51474905]\n",
      " [0.48523113 0.51476884]\n",
      " [0.4906319  0.5093681 ]\n",
      " [0.49114293 0.508857  ]\n",
      " [0.48787186 0.5121282 ]\n",
      " [0.49971136 0.5002886 ]\n",
      " [0.4926225  0.5073775 ]\n",
      " [0.4774529  0.52254707]\n",
      " [0.47876874 0.5212313 ]\n",
      " [0.4840133  0.5159867 ]\n",
      " [0.4901381  0.5098619 ]\n",
      " [0.49178153 0.5082185 ]\n",
      " [0.48886487 0.51113516]\n",
      " [0.4986479  0.5013521 ]\n",
      " [0.49062884 0.5093711 ]\n",
      " [0.48105514 0.5189448 ]\n",
      " [0.48493025 0.5150697 ]\n",
      " [0.48404908 0.51595086]\n",
      " [0.48673773 0.5132622 ]\n",
      " [0.4915047  0.50849533]\n",
      " [0.48981372 0.51018625]\n",
      " [0.494973   0.50502706]\n",
      " [0.4870539  0.5129461 ]\n",
      " [0.49400532 0.5059947 ]\n",
      " [0.49217007 0.5078299 ]\n",
      " [0.4896117  0.5103883 ]\n",
      " [0.49660614 0.5033938 ]\n",
      " [0.48580152 0.51419854]\n",
      " [0.48556432 0.5144357 ]\n",
      " [0.4894904  0.5105096 ]\n",
      " [0.480717   0.519283  ]\n",
      " [0.48283476 0.5171652 ]\n",
      " [0.4927509  0.50724906]\n",
      " [0.48281863 0.5171814 ]]\n",
      "I0815 20:26:41.692402 140472255838080 basic_session_run_hooks.py:262] loss = 0.6929238, step = 0\n",
      "I0815 20:26:41.694056 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_swish//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:26:45.064971 140472255838080 estimator.py:368] Loss for final step: 0.6929238.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d95aad30>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "4A38mcu4UUfi",
    "outputId": "26fa6019-cf6a-487d-9d67-eb8313204735"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:26:45.109322 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:26:45.632650 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:26:45.635480 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:26:45.763068 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:26:45.770044 140472255838080 saver.py:1280] Restoring parameters from Estimator_swish//actfn_convnet_model/model.ckpt-1\n",
      "I0815 20:26:46.261293 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:26:46.271850 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:26:46.566060 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_swish//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:26:50.366558 140472255838080 basic_session_run_hooks.py:262] loss = 0.6920908, step = 1\n",
      "I0815 20:28:01.149566 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41276\n",
      "I0815 20:28:01.155618 140472255838080 basic_session_run_hooks.py:260] loss = 0.37689593, step = 101 (70.789 sec)\n",
      "I0815 20:29:11.537983 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42069\n",
      "I0815 20:29:11.540846 140472255838080 basic_session_run_hooks.py:260] loss = 0.21729633, step = 201 (70.385 sec)\n",
      "I0815 20:30:22.015400 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41889\n",
      "I0815 20:30:22.018080 140472255838080 basic_session_run_hooks.py:260] loss = 0.22917855, step = 301 (70.477 sec)\n",
      "I0815 20:31:32.814396 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41245\n",
      "I0815 20:31:32.816786 140472255838080 basic_session_run_hooks.py:260] loss = 0.16769926, step = 401 (70.799 sec)\n",
      "I0815 20:32:43.278905 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41915\n",
      "I0815 20:32:43.281415 140472255838080 basic_session_run_hooks.py:260] loss = 0.18310887, step = 501 (70.465 sec)\n",
      "I0815 20:33:54.100418 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.412\n",
      "I0815 20:33:54.103153 140472255838080 basic_session_run_hooks.py:260] loss = 0.1577654, step = 601 (70.822 sec)\n",
      "I0815 20:35:04.886196 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41271\n",
      "I0815 20:35:04.888698 140472255838080 basic_session_run_hooks.py:260] loss = 0.16407181, step = 701 (70.786 sec)\n",
      "I0815 20:36:15.477115 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41661\n",
      "I0815 20:36:15.479835 140472255838080 basic_session_run_hooks.py:260] loss = 0.13980536, step = 801 (70.591 sec)\n",
      "I0815 20:36:50.062203 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 851 into Estimator_swish//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:37:29.249824 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.35551\n",
      "I0815 20:37:29.252386 140472255838080 basic_session_run_hooks.py:260] loss = 0.099542886, step = 901 (73.773 sec)\n",
      "I0815 20:38:39.158654 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into Estimator_swish//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:38:42.052130 140472255838080 estimator.py:368] Loss for final step: 0.153059.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1d95aad30>"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "or46d4qZUUfk"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "97YQOXjkUUfl",
    "outputId": "187728a5-cdfa-4703-ef6f-5bd04465df1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:38:42.086427 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 20:38:42.211327 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:38:42.239934 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T20:38:42Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:38:42.331986 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:38:42.336645 140472255838080 saver.py:1280] Restoring parameters from Estimator_swish//actfn_convnet_model/model.ckpt-1001\n",
      "I0815 20:38:42.627715 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:38:42.639764 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:39:30.872519 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-20:39:30\n",
      "I0815 20:39:30.873707 140472255838080 estimator.py:2039] Saving dict for global step 1001: accuracy = 0.9473106, global_step = 1001, loss = 0.14577803\n",
      "I0815 20:39:30.915112 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1001: Estimator_swish//actfn_convnet_model/model.ckpt-1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9473106, 'loss': 0.14577803, 'global_step': 1001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5JtZ3K4Qx0sf",
    "outputId": "ec14cdc7-d273-4487-8f25-6d0f754d0055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565900795.0\n",
      "Model execution end Time: 1565901571.0\n",
      "Model execution Time: 12.93 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZbxDAjgUUfn"
   },
   "source": [
    "## <span style=\"color:#b80f0f\"> Swish-Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywUsDN9yUUfo"
   },
   "source": [
    "<img src=\"Presentation/swish_1.png\" width=\"500\" height=\"200\" align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YE3yTKUWUUfo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTQx8X2TyF7n"
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZRNv0lJUUfo"
   },
   "source": [
    "#### Set a activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "CwL7Em_FUUfp",
    "outputId": "26ffb70a-14b5-44bd-a6c9-ff684366d171"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:39:30.959508 140472255838080 estimator.py:1790] Using default config.\n",
      "I0815 20:39:30.960918 140472255838080 estimator.py:209] Using config: {'_model_dir': 'Estimator_swish_beta//actfn_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0d2f96860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function sigmoid at 0x7fc1f9181620>\n"
     ]
    }
   ],
   "source": [
    "act_func_global=tf.nn.sigmoid\n",
    "actfn_classifier=estimator_path('swish_beta')\n",
    "\n",
    "print(act_func_global)\n",
    "is_Swish = False\n",
    "is_SwishBeta = True\n",
    "is_First = False\n",
    "\n",
    "def swish_beta(x):\n",
    "    beta=tf.Variable(initial_value=1.0,trainable=True,name='swish_beta')\n",
    "    print('beta: ',beta)\n",
    "    act_func_global = x*tf.nn.sigmoid(beta*x) #trainable parameter beta\n",
    "    print('act_func_global: ',act_func_global)\n",
    "    return act_func_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr11dqo8UUfr"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Y44lxz3tUUfr",
    "outputId": "aff1422b-ee7f-4474-868b-4b3b401ac257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:39:31.003473 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "beta:  <tf.Variable 'swish_beta:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_1:0\", shape=(500, 150, 150, 3), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_1:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_3:0\", shape=(500, 75, 75, 32), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_2:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_5:0\", shape=(500, 82944), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:39:31.286171 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:39:31.288874 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:39:31.467481 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:39:32.624931 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:39:32.634146 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:39:32.938806 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 0 into Estimator_swish_beta//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:39:36.602213 140472255838080 basic_session_run_hooks.py:262] probabilities = [[0.26994014 0.73005986]\n",
      " [0.28225857 0.71774143]\n",
      " [0.29367465 0.70632535]\n",
      " [0.283928   0.716072  ]\n",
      " [0.28977618 0.7102238 ]\n",
      " [0.28925765 0.71074235]\n",
      " [0.27398807 0.72601193]\n",
      " [0.2672332  0.7327668 ]\n",
      " [0.27708846 0.7229116 ]\n",
      " [0.29164425 0.7083557 ]\n",
      " [0.26095617 0.73904383]\n",
      " [0.27262697 0.72737306]\n",
      " [0.27086768 0.7291323 ]\n",
      " [0.2882773  0.7117227 ]\n",
      " [0.26693293 0.73306704]\n",
      " [0.2705841  0.7294159 ]\n",
      " [0.28114274 0.7188573 ]\n",
      " [0.28032804 0.71967196]\n",
      " [0.27210134 0.7278986 ]\n",
      " [0.2769174  0.7230826 ]\n",
      " [0.27846786 0.7215321 ]\n",
      " [0.27444878 0.7255512 ]\n",
      " [0.269292   0.730708  ]\n",
      " [0.27967384 0.7203262 ]\n",
      " [0.28558213 0.71441793]\n",
      " [0.27852073 0.7214793 ]\n",
      " [0.28534347 0.7146566 ]\n",
      " [0.2741507  0.72584933]\n",
      " [0.27378002 0.72622   ]\n",
      " [0.26482883 0.73517114]\n",
      " [0.2690005  0.73099947]\n",
      " [0.2710713  0.7289287 ]\n",
      " [0.27497688 0.7250231 ]\n",
      " [0.27500895 0.7249911 ]\n",
      " [0.2758597  0.7241402 ]\n",
      " [0.28104165 0.7189584 ]\n",
      " [0.29055473 0.7094453 ]\n",
      " [0.27653113 0.72346884]\n",
      " [0.27270833 0.72729164]\n",
      " [0.28080726 0.71919274]\n",
      " [0.2694291  0.7305709 ]\n",
      " [0.27177832 0.7282217 ]\n",
      " [0.28365237 0.71634763]\n",
      " [0.26379353 0.7362065 ]\n",
      " [0.27752075 0.7224793 ]\n",
      " [0.27662978 0.7233702 ]\n",
      " [0.28367582 0.71632415]\n",
      " [0.2860143  0.7139857 ]\n",
      " [0.27781573 0.7221843 ]\n",
      " [0.27907944 0.72092056]\n",
      " [0.28160316 0.71839684]\n",
      " [0.28243542 0.7175646 ]\n",
      " [0.27737835 0.7226216 ]\n",
      " [0.2851809  0.7148191 ]\n",
      " [0.28382006 0.71617997]\n",
      " [0.27364495 0.726355  ]\n",
      " [0.2769832  0.7230168 ]\n",
      " [0.27599213 0.7240079 ]\n",
      " [0.2767555  0.7232445 ]\n",
      " [0.28864816 0.7113518 ]\n",
      " [0.28680813 0.7131918 ]\n",
      " [0.2838171  0.7161828 ]\n",
      " [0.26922253 0.7307775 ]\n",
      " [0.27310422 0.7268958 ]\n",
      " [0.2615699  0.7384301 ]\n",
      " [0.2850042  0.7149958 ]\n",
      " [0.28199017 0.7180098 ]\n",
      " [0.2865511  0.7134489 ]\n",
      " [0.278198   0.721802  ]\n",
      " [0.2689532  0.73104674]\n",
      " [0.27284583 0.7271542 ]\n",
      " [0.2755717  0.7244283 ]\n",
      " [0.28605124 0.7139487 ]\n",
      " [0.28518146 0.71481854]\n",
      " [0.2711763  0.7288237 ]\n",
      " [0.27593976 0.7240602 ]\n",
      " [0.2798853  0.72011477]\n",
      " [0.28019035 0.7198096 ]\n",
      " [0.2720944  0.72790563]\n",
      " [0.27776816 0.72223186]\n",
      " [0.28292325 0.7170768 ]\n",
      " [0.27489266 0.7251073 ]\n",
      " [0.26588228 0.7341177 ]\n",
      " [0.2782012  0.7217988 ]\n",
      " [0.28700545 0.7129946 ]\n",
      " [0.2669634  0.73303664]\n",
      " [0.2786178  0.7213822 ]\n",
      " [0.2780767  0.7219233 ]\n",
      " [0.27747416 0.72252584]\n",
      " [0.2659509  0.7340491 ]\n",
      " [0.27313977 0.7268602 ]\n",
      " [0.27148563 0.7285143 ]\n",
      " [0.2863994  0.71360064]\n",
      " [0.28423557 0.7157644 ]\n",
      " [0.2804689  0.71953106]\n",
      " [0.27033892 0.7296611 ]\n",
      " [0.26818588 0.7318141 ]\n",
      " [0.2710234  0.7289766 ]\n",
      " [0.27200183 0.7279982 ]\n",
      " [0.28698522 0.71301484]\n",
      " [0.28200617 0.71799386]\n",
      " [0.27628732 0.7237127 ]\n",
      " [0.27041656 0.7295835 ]\n",
      " [0.27075082 0.7292492 ]\n",
      " [0.27214882 0.7278512 ]\n",
      " [0.28402728 0.7159727 ]\n",
      " [0.28363767 0.71636236]\n",
      " [0.28438503 0.71561503]\n",
      " [0.28108373 0.71891624]\n",
      " [0.2800835  0.71991646]\n",
      " [0.28229755 0.71770245]\n",
      " [0.2722394  0.7277606 ]\n",
      " [0.27036572 0.7296343 ]\n",
      " [0.28079483 0.7192052 ]\n",
      " [0.28177148 0.7182285 ]\n",
      " [0.28328624 0.7167137 ]\n",
      " [0.2858332  0.71416676]\n",
      " [0.27417773 0.72582227]\n",
      " [0.27466607 0.7253339 ]\n",
      " [0.2852698  0.7147302 ]\n",
      " [0.27568677 0.72431326]\n",
      " [0.28153569 0.7184643 ]\n",
      " [0.2882349  0.7117651 ]\n",
      " [0.26447558 0.7355244 ]\n",
      " [0.2835651  0.7164349 ]\n",
      " [0.2727672  0.7272328 ]\n",
      " [0.2783111  0.72168887]\n",
      " [0.27339372 0.7266063 ]\n",
      " [0.29849422 0.70150584]\n",
      " [0.27898592 0.7210141 ]\n",
      " [0.28020346 0.71979654]\n",
      " [0.27396432 0.7260357 ]\n",
      " [0.27765715 0.72234285]\n",
      " [0.27208313 0.7279169 ]\n",
      " [0.27732274 0.7226773 ]\n",
      " [0.27289766 0.72710234]\n",
      " [0.28721634 0.71278363]\n",
      " [0.28654563 0.71345437]\n",
      " [0.27210408 0.7278959 ]\n",
      " [0.28157428 0.7184257 ]\n",
      " [0.2707178  0.7292822 ]\n",
      " [0.27357873 0.72642124]\n",
      " [0.2762706  0.72372943]\n",
      " [0.28044504 0.71955496]\n",
      " [0.28710312 0.7128969 ]\n",
      " [0.27723444 0.72276556]\n",
      " [0.27816728 0.72183275]\n",
      " [0.2729209  0.7270791 ]\n",
      " [0.2775554  0.72244465]\n",
      " [0.2776912  0.7223088 ]\n",
      " [0.27563992 0.7243601 ]\n",
      " [0.2794936  0.72050637]\n",
      " [0.27497855 0.7250214 ]\n",
      " [0.28052482 0.7194752 ]\n",
      " [0.2697406  0.7302594 ]\n",
      " [0.2817903  0.71820974]\n",
      " [0.2692997  0.73070025]\n",
      " [0.27719918 0.7228008 ]\n",
      " [0.27116218 0.72883785]\n",
      " [0.28058994 0.7194101 ]\n",
      " [0.27359444 0.72640556]\n",
      " [0.2747475  0.72525245]\n",
      " [0.28294387 0.7170561 ]\n",
      " [0.27128115 0.7287189 ]\n",
      " [0.2755692  0.7244308 ]\n",
      " [0.27783117 0.72216886]\n",
      " [0.27984056 0.7201594 ]\n",
      " [0.28572318 0.71427685]\n",
      " [0.27567676 0.7243233 ]\n",
      " [0.28243783 0.7175622 ]\n",
      " [0.2733014  0.72669864]\n",
      " [0.27994832 0.7200517 ]\n",
      " [0.27619252 0.72380745]\n",
      " [0.28869987 0.71130013]\n",
      " [0.27605125 0.7239488 ]\n",
      " [0.27060026 0.72939974]\n",
      " [0.2771876  0.7228124 ]\n",
      " [0.28320572 0.7167943 ]\n",
      " [0.27749994 0.7225001 ]\n",
      " [0.26885188 0.73114806]\n",
      " [0.28668886 0.7133112 ]\n",
      " [0.26360005 0.73639995]\n",
      " [0.28367677 0.71632326]\n",
      " [0.27566826 0.72433174]\n",
      " [0.2806     0.7194    ]\n",
      " [0.27250624 0.7274937 ]\n",
      " [0.28473184 0.7152682 ]\n",
      " [0.27947956 0.72052044]\n",
      " [0.27314296 0.72685707]\n",
      " [0.27157748 0.72842246]\n",
      " [0.27915367 0.7208463 ]\n",
      " [0.2644482  0.73555183]\n",
      " [0.27601615 0.7239838 ]\n",
      " [0.27375144 0.72624856]\n",
      " [0.27503088 0.7249691 ]\n",
      " [0.27166206 0.72833794]\n",
      " [0.28004527 0.7199547 ]\n",
      " [0.27497315 0.72502685]\n",
      " [0.27219212 0.72780794]\n",
      " [0.27444544 0.7255546 ]\n",
      " [0.27134928 0.72865075]\n",
      " [0.27101177 0.7289883 ]\n",
      " [0.27916092 0.720839  ]\n",
      " [0.29101592 0.7089841 ]\n",
      " [0.27868786 0.72131217]\n",
      " [0.28652188 0.71347815]\n",
      " [0.27064124 0.72935873]\n",
      " [0.28130877 0.71869123]\n",
      " [0.2807739  0.71922606]\n",
      " [0.2749442  0.72505575]\n",
      " [0.27074027 0.7292598 ]\n",
      " [0.2841728  0.71582717]\n",
      " [0.27151492 0.7284851 ]\n",
      " [0.27864835 0.7213516 ]\n",
      " [0.2838815  0.7161185 ]\n",
      " [0.2674459  0.7325541 ]\n",
      " [0.28259468 0.7174053 ]\n",
      " [0.27922538 0.72077465]\n",
      " [0.27760705 0.7223929 ]\n",
      " [0.2796165  0.7203835 ]\n",
      " [0.28097838 0.7190216 ]\n",
      " [0.28495258 0.7150474 ]\n",
      " [0.28221616 0.71778387]\n",
      " [0.27668786 0.72331214]\n",
      " [0.27458632 0.7254136 ]\n",
      " [0.27179298 0.728207  ]\n",
      " [0.2707701  0.72922987]\n",
      " [0.28582653 0.7141735 ]\n",
      " [0.269555   0.730445  ]\n",
      " [0.27995557 0.7200444 ]\n",
      " [0.26377445 0.7362255 ]\n",
      " [0.2893678  0.7106322 ]\n",
      " [0.26906982 0.7309302 ]\n",
      " [0.27945173 0.7205483 ]\n",
      " [0.27888635 0.7211137 ]\n",
      " [0.26926994 0.73073006]\n",
      " [0.28156772 0.7184323 ]\n",
      " [0.2747625  0.7252375 ]\n",
      " [0.27831048 0.7216895 ]\n",
      " [0.27810577 0.7218942 ]\n",
      " [0.28168064 0.71831936]\n",
      " [0.27297464 0.72702533]\n",
      " [0.27507147 0.7249285 ]\n",
      " [0.2677456  0.7322544 ]\n",
      " [0.28726292 0.71273714]\n",
      " [0.2764342  0.7235658 ]\n",
      " [0.28034687 0.7196531 ]\n",
      " [0.27127412 0.72872585]\n",
      " [0.28036344 0.7196366 ]\n",
      " [0.28721586 0.7127842 ]\n",
      " [0.2923848  0.70761526]\n",
      " [0.27789852 0.72210145]\n",
      " [0.2795872  0.72041285]\n",
      " [0.274222   0.725778  ]\n",
      " [0.27525836 0.7247417 ]\n",
      " [0.27399588 0.7260041 ]\n",
      " [0.2835591  0.71644086]\n",
      " [0.27901486 0.7209851 ]\n",
      " [0.29128477 0.70871526]\n",
      " [0.27961558 0.7203844 ]\n",
      " [0.2792317  0.72076833]\n",
      " [0.2651164  0.7348836 ]\n",
      " [0.28206664 0.7179334 ]\n",
      " [0.27195984 0.72804016]\n",
      " [0.2761571  0.72384286]\n",
      " [0.27316818 0.72683185]\n",
      " [0.30085677 0.6991432 ]\n",
      " [0.27655646 0.7234435 ]\n",
      " [0.2711496  0.72885036]\n",
      " [0.27866742 0.72133255]\n",
      " [0.2963633  0.7036367 ]\n",
      " [0.28809163 0.7119084 ]\n",
      " [0.296212   0.703788  ]\n",
      " [0.2765395  0.72346044]\n",
      " [0.2719     0.72810006]\n",
      " [0.27959985 0.72040015]\n",
      " [0.2806478  0.71935225]\n",
      " [0.28149953 0.7185005 ]\n",
      " [0.27110797 0.72889197]\n",
      " [0.26698595 0.733014  ]\n",
      " [0.27367368 0.72632635]\n",
      " [0.26963738 0.7303626 ]\n",
      " [0.28664008 0.71335995]\n",
      " [0.2720557  0.7279444 ]\n",
      " [0.28436604 0.7156339 ]\n",
      " [0.27949193 0.72050804]\n",
      " [0.27915984 0.72084016]\n",
      " [0.2790399  0.7209601 ]\n",
      " [0.27306265 0.7269373 ]\n",
      " [0.27811748 0.72188246]\n",
      " [0.27257037 0.7274296 ]\n",
      " [0.27313507 0.72686493]\n",
      " [0.27407026 0.72592974]\n",
      " [0.27708927 0.7229107 ]\n",
      " [0.28832978 0.7116702 ]\n",
      " [0.2603842  0.73961574]\n",
      " [0.26828274 0.7317172 ]\n",
      " [0.2792707  0.72072923]\n",
      " [0.27240783 0.7275922 ]\n",
      " [0.28252444 0.71747553]\n",
      " [0.26034492 0.7396551 ]\n",
      " [0.27965063 0.7203494 ]\n",
      " [0.28606054 0.7139394 ]\n",
      " [0.29216343 0.70783657]\n",
      " [0.27680343 0.7231965 ]\n",
      " [0.278709   0.72129095]\n",
      " [0.27083516 0.7291648 ]\n",
      " [0.27359185 0.7264082 ]\n",
      " [0.27879617 0.7212038 ]\n",
      " [0.26502767 0.7349723 ]\n",
      " [0.27819028 0.72180974]\n",
      " [0.27857584 0.7214242 ]\n",
      " [0.28360265 0.71639735]\n",
      " [0.28855705 0.71144295]\n",
      " [0.28645003 0.71355003]\n",
      " [0.27906358 0.72093636]\n",
      " [0.27563766 0.7243624 ]\n",
      " [0.28341714 0.7165829 ]\n",
      " [0.28316462 0.7168354 ]\n",
      " [0.27734718 0.72265285]\n",
      " [0.26800296 0.731997  ]\n",
      " [0.28479525 0.7152048 ]\n",
      " [0.27753684 0.7224632 ]\n",
      " [0.28544185 0.7145581 ]\n",
      " [0.27480802 0.725192  ]\n",
      " [0.27314895 0.72685105]\n",
      " [0.27133977 0.7286603 ]\n",
      " [0.27044132 0.72955865]\n",
      " [0.27784854 0.72215146]\n",
      " [0.27606642 0.7239336 ]\n",
      " [0.2690705  0.7309295 ]\n",
      " [0.27539948 0.72460055]\n",
      " [0.27830687 0.7216931 ]\n",
      " [0.27381453 0.72618544]\n",
      " [0.28457654 0.7154234 ]\n",
      " [0.26694056 0.7330594 ]\n",
      " [0.29118648 0.7088135 ]\n",
      " [0.2701982  0.72980183]\n",
      " [0.2735111  0.7264889 ]\n",
      " [0.26512247 0.7348775 ]\n",
      " [0.27646863 0.72353137]\n",
      " [0.2767381  0.72326183]\n",
      " [0.27040017 0.7295999 ]\n",
      " [0.2904358  0.70956415]\n",
      " [0.27679685 0.7232032 ]\n",
      " [0.26881197 0.731188  ]\n",
      " [0.28473774 0.7152623 ]\n",
      " [0.27879342 0.7212066 ]\n",
      " [0.28358784 0.7164122 ]\n",
      " [0.2774891  0.7225109 ]\n",
      " [0.27657446 0.7234255 ]\n",
      " [0.2760535  0.7239465 ]\n",
      " [0.27750254 0.72249746]\n",
      " [0.27040505 0.7295949 ]\n",
      " [0.27913526 0.7208648 ]\n",
      " [0.2757333  0.7242667 ]\n",
      " [0.278878   0.72112197]\n",
      " [0.2786762  0.72132385]\n",
      " [0.27380767 0.72619236]\n",
      " [0.27868757 0.7213124 ]\n",
      " [0.27882656 0.7211734 ]\n",
      " [0.26393038 0.7360696 ]\n",
      " [0.27389032 0.7261096 ]\n",
      " [0.2727329  0.727267  ]\n",
      " [0.2790343  0.72096574]\n",
      " [0.27072847 0.7292715 ]\n",
      " [0.2883362  0.71166384]\n",
      " [0.2742901  0.72570986]\n",
      " [0.2741601  0.7258399 ]\n",
      " [0.2826082  0.7173917 ]\n",
      " [0.2717294  0.7282706 ]\n",
      " [0.26186603 0.738134  ]\n",
      " [0.28490818 0.7150918 ]\n",
      " [0.27213973 0.7278603 ]\n",
      " [0.27565867 0.72434133]\n",
      " [0.2773336  0.7226664 ]\n",
      " [0.28219774 0.7178022 ]\n",
      " [0.2816748  0.7183252 ]\n",
      " [0.28693455 0.71306545]\n",
      " [0.2717051  0.7282949 ]\n",
      " [0.27676037 0.7232396 ]\n",
      " [0.2739734  0.7260266 ]\n",
      " [0.27471876 0.7252812 ]\n",
      " [0.26492065 0.73507935]\n",
      " [0.27738667 0.72261333]\n",
      " [0.27658203 0.723418  ]\n",
      " [0.27393144 0.7260685 ]\n",
      " [0.27751908 0.7224809 ]\n",
      " [0.2805617  0.7194384 ]\n",
      " [0.2789744  0.7210256 ]\n",
      " [0.28617957 0.71382046]\n",
      " [0.29158822 0.70841175]\n",
      " [0.2728348  0.72716516]\n",
      " [0.2837581  0.7162419 ]\n",
      " [0.28075716 0.7192428 ]\n",
      " [0.28127936 0.7187206 ]\n",
      " [0.27982536 0.7201746 ]\n",
      " [0.28807616 0.71192384]\n",
      " [0.27541065 0.72458935]\n",
      " [0.27275395 0.727246  ]\n",
      " [0.27163142 0.7283686 ]\n",
      " [0.2731343  0.7268657 ]\n",
      " [0.27545917 0.7245408 ]\n",
      " [0.280149   0.719851  ]\n",
      " [0.27928683 0.7207132 ]\n",
      " [0.28043175 0.71956825]\n",
      " [0.27699077 0.7230093 ]\n",
      " [0.27595797 0.72404206]\n",
      " [0.27638644 0.7236136 ]\n",
      " [0.28190863 0.7180914 ]\n",
      " [0.279935   0.72006506]\n",
      " [0.28833663 0.71166337]\n",
      " [0.29318905 0.70681095]\n",
      " [0.2740484  0.7259516 ]\n",
      " [0.27385578 0.72614425]\n",
      " [0.28855395 0.71144605]\n",
      " [0.28785557 0.71214443]\n",
      " [0.28456202 0.715438  ]\n",
      " [0.28029138 0.71970856]\n",
      " [0.28252122 0.7174788 ]\n",
      " [0.2795703  0.72042966]\n",
      " [0.2701069  0.7298931 ]\n",
      " [0.28704828 0.7129517 ]\n",
      " [0.28038093 0.71961904]\n",
      " [0.28015113 0.71984893]\n",
      " [0.28164858 0.7183514 ]\n",
      " [0.27171618 0.7282838 ]\n",
      " [0.273653   0.726347  ]\n",
      " [0.28016108 0.7198389 ]\n",
      " [0.2750351  0.7249649 ]\n",
      " [0.27890843 0.72109157]\n",
      " [0.28679252 0.7132075 ]\n",
      " [0.28045258 0.71954745]\n",
      " [0.27237797 0.7276221 ]\n",
      " [0.2810966  0.71890336]\n",
      " [0.27544183 0.7245581 ]\n",
      " [0.27723932 0.7227607 ]\n",
      " [0.27563202 0.7243679 ]\n",
      " [0.27678326 0.7232167 ]\n",
      " [0.27150077 0.72849923]\n",
      " [0.27975497 0.72024506]\n",
      " [0.27567944 0.7243206 ]\n",
      " [0.28152606 0.7184739 ]\n",
      " [0.2810356  0.71896434]\n",
      " [0.29541886 0.70458114]\n",
      " [0.28525987 0.71474016]\n",
      " [0.2703247  0.7296753 ]\n",
      " [0.27552807 0.7244719 ]\n",
      " [0.26679206 0.73320794]\n",
      " [0.27871683 0.72128314]\n",
      " [0.27667695 0.7233231 ]\n",
      " [0.28088874 0.7191112 ]\n",
      " [0.26977506 0.73022497]\n",
      " [0.28233105 0.7176689 ]\n",
      " [0.27323747 0.72676253]\n",
      " [0.28577697 0.714223  ]\n",
      " [0.27752954 0.72247046]\n",
      " [0.27854785 0.7214522 ]\n",
      " [0.27100664 0.72899336]\n",
      " [0.27330345 0.72669655]\n",
      " [0.28071496 0.7192851 ]\n",
      " [0.28955734 0.71044266]\n",
      " [0.2806218  0.71937823]\n",
      " [0.2744157  0.7255843 ]\n",
      " [0.27273083 0.7272692 ]\n",
      " [0.27066192 0.72933805]\n",
      " [0.2759985  0.72400147]\n",
      " [0.27271846 0.7272816 ]\n",
      " [0.26542282 0.7345771 ]\n",
      " [0.2877302  0.7122698 ]\n",
      " [0.2716731  0.72832686]\n",
      " [0.28398037 0.71601963]\n",
      " [0.27485567 0.7251444 ]\n",
      " [0.2693474  0.73065263]\n",
      " [0.2879688  0.7120312 ]\n",
      " [0.28256452 0.7174355 ]\n",
      " [0.2644417  0.7355583 ]\n",
      " [0.2727347  0.7272653 ]\n",
      " [0.27550554 0.7244945 ]\n",
      " [0.27118766 0.72881234]\n",
      " [0.28349817 0.71650183]\n",
      " [0.28013435 0.7198656 ]\n",
      " [0.27544618 0.7245539 ]\n",
      " [0.27058402 0.72941595]\n",
      " [0.26959658 0.7304034 ]\n",
      " [0.2841053  0.7158947 ]\n",
      " [0.27085167 0.7291483 ]\n",
      " [0.28415975 0.7158402 ]\n",
      " [0.27473584 0.7252642 ]\n",
      " [0.28191411 0.71808594]\n",
      " [0.29190305 0.708097  ]\n",
      " [0.2869067  0.7130933 ]\n",
      " [0.2719688  0.7280312 ]\n",
      " [0.28129816 0.7187019 ]\n",
      " [0.27497038 0.72502965]\n",
      " [0.28126916 0.7187308 ]\n",
      " [0.27975565 0.72024435]\n",
      " [0.27947035 0.7205297 ]\n",
      " [0.27347746 0.72652256]\n",
      " [0.26583487 0.73416513]]\n",
      "I0815 20:39:36.604431 140472255838080 basic_session_run_hooks.py:262] loss = 0.7715259, step = 0\n",
      "I0815 20:39:36.606243 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_swish_beta//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:39:40.264182 140472255838080 estimator.py:368] Loss for final step: 0.7715259.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1cb649898>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=b_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "actfn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "ZF9-bMMnUUfu",
    "outputId": "979eb5f6-c298-4048-e836-6801699f0979",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:39:40.300664 140472255838080 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "beta:  <tf.Variable 'swish_beta:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_1:0\", shape=(500, 150, 150, 3), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_1:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_3:0\", shape=(500, 75, 75, 32), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_2:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_5:0\", shape=(500, 82944), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:39:40.798097 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:39:40.801275 140472255838080 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0815 20:39:40.933348 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:39:40.939355 140472255838080 saver.py:1280] Restoring parameters from Estimator_swish_beta//actfn_convnet_model/model.ckpt-1\n",
      "I0815 20:39:41.346256 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:39:41.356544 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:39:41.670698 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1 into Estimator_swish_beta//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:39:45.628330 140472255838080 basic_session_run_hooks.py:262] loss = 0.6948604, step = 1\n",
      "I0815 20:40:56.704508 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.40693\n",
      "I0815 20:40:56.707003 140472255838080 basic_session_run_hooks.py:260] loss = 0.4131463, step = 101 (71.079 sec)\n",
      "I0815 20:42:07.197049 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41859\n",
      "I0815 20:42:07.200371 140472255838080 basic_session_run_hooks.py:260] loss = 0.19015169, step = 201 (70.493 sec)\n",
      "I0815 20:43:17.563406 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.42113\n",
      "I0815 20:43:17.565828 140472255838080 basic_session_run_hooks.py:260] loss = 0.20718192, step = 301 (70.365 sec)\n",
      "I0815 20:44:27.916410 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.4214\n",
      "I0815 20:44:27.920904 140472255838080 basic_session_run_hooks.py:260] loss = 0.17846455, step = 401 (70.355 sec)\n",
      "I0815 20:45:38.413438 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.4185\n",
      "I0815 20:45:38.415846 140472255838080 basic_session_run_hooks.py:260] loss = 0.13831607, step = 501 (70.495 sec)\n",
      "I0815 20:46:49.089306 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41491\n",
      "I0815 20:46:49.091868 140472255838080 basic_session_run_hooks.py:260] loss = 0.13651294, step = 601 (70.676 sec)\n",
      "I0815 20:47:59.966723 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41089\n",
      "I0815 20:47:59.969347 140472255838080 basic_session_run_hooks.py:260] loss = 0.11352971, step = 701 (70.877 sec)\n",
      "I0815 20:49:10.762632 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.41251\n",
      "I0815 20:49:10.765206 140472255838080 basic_session_run_hooks.py:260] loss = 0.12601912, step = 801 (70.796 sec)\n",
      "I0815 20:49:44.999636 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 850 into Estimator_swish_beta//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:50:24.647583 140472255838080 basic_session_run_hooks.py:692] global_step/sec: 1.35346\n",
      "I0815 20:50:24.650367 140472255838080 basic_session_run_hooks.py:260] loss = 0.10958152, step = 901 (73.885 sec)\n",
      "I0815 20:51:34.482802 140472255838080 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into Estimator_swish_beta//actfn_convnet_model/model.ckpt.\n",
      "I0815 20:51:37.280264 140472255838080 estimator.py:368] Loss for final step: 0.11498886.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc1cb649898>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actfn_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHH3eFQtUUfv"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "ludankhhUUfv",
    "outputId": "cea3f4a3-2fd5-483b-c1cc-6a8af14d50c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:51:37.314202 140472255838080 estimator.py:1145] Calling model_fn.\n",
      "I0815 20:51:37.452859 140472255838080 estimator.py:1147] Done calling model_fn.\n",
      "I0815 20:51:37.479614 140472255838080 evaluation.py:255] Starting evaluation at 2019-08-15T20:51:37Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_func_global:  <function sigmoid at 0x7fc1f9181620>\n",
      "beta:  <tf.Variable 'swish_beta:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_1:0\", shape=(?, 150, 150, 3), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_1:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_3:0\", shape=(?, 75, 75, 32), dtype=float32)\n",
      "beta:  <tf.Variable 'swish_beta_2:0' shape=() dtype=float32_ref>\n",
      "act_func_global:  Tensor(\"mul_5:0\", shape=(?, 82944), dtype=float32)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 20:51:37.575989 140472255838080 monitored_session.py:240] Graph was finalized.\n",
      "I0815 20:51:37.581452 140472255838080 saver.py:1280] Restoring parameters from Estimator_swish_beta//actfn_convnet_model/model.ckpt-1001\n",
      "I0815 20:51:37.827801 140472255838080 session_manager.py:500] Running local_init_op.\n",
      "I0815 20:51:37.840230 140472255838080 session_manager.py:502] Done running local_init_op.\n",
      "I0815 20:52:26.111456 140472255838080 evaluation.py:275] Finished evaluation at 2019-08-15-20:52:26\n",
      "I0815 20:52:26.113333 140472255838080 estimator.py:2039] Saving dict for global step 1001: accuracy = 0.96377605, global_step = 1001, loss = 0.12295562\n",
      "I0815 20:52:26.152776 140472255838080 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1001: Estimator_swish_beta//actfn_convnet_model/model.ckpt-1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.96377605, 'loss': 0.12295562, 'global_step': 1001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = actfn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5wnaoALnUUfz",
    "outputId": "e7150f19-51ff-40b9-daaf-9a97d9a298a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution start Time: 1565901571.0\n",
      "Model execution end Time: 1565902346.0\n",
      "Model execution Time: 12.92 minutes\n"
     ]
    }
   ],
   "source": [
    "model_end_time = time.time()\n",
    "Execute_Time(model_start_time,model_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCXo7D1DUUf4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1b6RwksEUUf5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "IuZ8CrIyUUef"
   ],
   "machine_shape": "hm",
   "name": "ADS Project - Implementing Activation functions & Swish.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
